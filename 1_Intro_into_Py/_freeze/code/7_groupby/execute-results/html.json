{
  "hash": "0364bdf50b4e3d5a90306e46289d8c35",
  "result": {
    "markdown": "# Grouping data\n\nSometimes we want to select data based on groups and understand aggregated data on a group level. We have seen that even though Pandas allows us to iterate over every row in a dataframe, it is generally very slow to do so. Fortunately Pandas has a groupby() function to speed up such task. \n\n The idea behind the groupby() function is that it takes some dataframe, splits it into chunks based on some key values, applies computation on those chunks, then combines the results back together into another dataframe. In pandas this is referred to as the split-apply-combine pattern.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\n```\n:::\n\n\nLet's prepare some data to work with:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n#read in census data\ndf = pd.read_csv('../data/week3/census.csv')\n\n#remove state level data\ndf = df[df['SUMLEV'] ==50 ]\n\n#view df\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SUMLEV</th>\n      <th>REGION</th>\n      <th>DIVISION</th>\n      <th>STATE</th>\n      <th>COUNTY</th>\n      <th>STNAME</th>\n      <th>CTYNAME</th>\n      <th>CENSUS2010POP</th>\n      <th>ESTIMATESBASE2010</th>\n      <th>POPESTIMATE2010</th>\n      <th>...</th>\n      <th>RDOMESTICMIG2011</th>\n      <th>RDOMESTICMIG2012</th>\n      <th>RDOMESTICMIG2013</th>\n      <th>RDOMESTICMIG2014</th>\n      <th>RDOMESTICMIG2015</th>\n      <th>RNETMIG2011</th>\n      <th>RNETMIG2012</th>\n      <th>RNETMIG2013</th>\n      <th>RNETMIG2014</th>\n      <th>RNETMIG2015</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Alabama</td>\n      <td>Autauga County</td>\n      <td>54571</td>\n      <td>54571</td>\n      <td>54660</td>\n      <td>...</td>\n      <td>7.242091</td>\n      <td>-2.915927</td>\n      <td>-3.012349</td>\n      <td>2.265971</td>\n      <td>-2.530799</td>\n      <td>7.606016</td>\n      <td>-2.626146</td>\n      <td>-2.722002</td>\n      <td>2.592270</td>\n      <td>-2.187333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Alabama</td>\n      <td>Baldwin County</td>\n      <td>182265</td>\n      <td>182265</td>\n      <td>183193</td>\n      <td>...</td>\n      <td>14.832960</td>\n      <td>17.647293</td>\n      <td>21.845705</td>\n      <td>19.243287</td>\n      <td>17.197872</td>\n      <td>15.844176</td>\n      <td>18.559627</td>\n      <td>22.727626</td>\n      <td>20.317142</td>\n      <td>18.293499</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>5</td>\n      <td>Alabama</td>\n      <td>Barbour County</td>\n      <td>27457</td>\n      <td>27457</td>\n      <td>27341</td>\n      <td>...</td>\n      <td>-4.728132</td>\n      <td>-2.500690</td>\n      <td>-7.056824</td>\n      <td>-3.904217</td>\n      <td>-10.543299</td>\n      <td>-4.874741</td>\n      <td>-2.758113</td>\n      <td>-7.167664</td>\n      <td>-3.978583</td>\n      <td>-10.543299</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>7</td>\n      <td>Alabama</td>\n      <td>Bibb County</td>\n      <td>22915</td>\n      <td>22919</td>\n      <td>22861</td>\n      <td>...</td>\n      <td>-5.527043</td>\n      <td>-5.068871</td>\n      <td>-6.201001</td>\n      <td>-0.177537</td>\n      <td>0.177258</td>\n      <td>-5.088389</td>\n      <td>-4.363636</td>\n      <td>-5.403729</td>\n      <td>0.754533</td>\n      <td>1.107861</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>9</td>\n      <td>Alabama</td>\n      <td>Blount County</td>\n      <td>57322</td>\n      <td>57322</td>\n      <td>57373</td>\n      <td>...</td>\n      <td>1.807375</td>\n      <td>-1.177622</td>\n      <td>-1.748766</td>\n      <td>-2.062535</td>\n      <td>-1.369970</td>\n      <td>1.859511</td>\n      <td>-0.848580</td>\n      <td>-1.402476</td>\n      <td>-1.577232</td>\n      <td>-0.884411</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 100 columns</p>\n</div>\n```\n:::\n:::\n\n\nIn the first example for groupby() I want to use the census date. Let's get a list of the unique states, then we can iterate over all the states and for each state we reduce the data frame and calculate the average.\n\nLet's run such task for 3 times and time it. For this we'll use the cell magic function %%timeit:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n#%%timeit -n 3\n\nfor state in df['STNAME']:\n    calculate the average using np\n    avg = np.average(df.where(df['STNAME']==state).dropna()['CENSUS2010POP'])\n    print('Countries in state' + state + ' have an avg pop of:' + str(avg))\n\nprint('')\n```\n:::\n\n\nIf you scroll down to the bottom of that output you can see it takes a fair bit of time to finish. I.e. in the jupyter notebook it takes 1.07s per loop. Now let's try another approach using groupby().\n \n You'll notice there are two values we set here. groupby() returns a tuple, where:\n - the first value is the value of the key we were trying to group by, in this case a specific state name\n - the second one is projected dataframe that was found for that group\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n#%%timeit -n 3\n\n# For this method, we start by telling pandas we're interested in grouping by state name, this is the \"split\":\nfor group, frame in df.groupby('STNAME'):\n        # Now we include our logic in the \"apply\" step, which is to calculate an average of the census2010pop\n        avg = np.average(frame['CENSUS2010POP'])\n        print('Counties in state ' + group + \n          ' have an average population of ' + str(avg))\n\nprint('')\n```\n:::\n\n\nThis one would take 4.71 m to run in jupyter. \n\n\n## Grouping multiple columns\n\nNow, 99% of the time, you'll use group by on one or more columns. But you can also provide a function to group by and use that to segment your data.\n\nThis is a bit of a fabricated example but lets say that you have a big batch job with lots of processing and you want to work on only a third or so of the states at a given time. We could create some function which returns a number between zero and two based on the first character of the state name. Then we can tell group by to use this function to split up our data frame. \n\nIt's important to note that in order to do this you need to set the index of the data frame to be the column that you want to group by first.\n\nWe'll create some new function called set_batch_number and if the first letter of the parameter is a capital M we'll return a 0. If it's a capital Q we'll return a 1 and otherwise we'll return a 2. Then we'll pass this function to the data frame:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndf = df.set_index('STNAME')\n\ndef set_batch_number(item):\n    if item[0] < 'M':\n        return 0\n    if item[0] < 'Q':\n        return 1\n    return 2\n```\n:::\n\n\nThe dataframe is supposed to be grouped by according to the batch number And we will loop through each batch group:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfor group, frame in df.groupby(set_batch_number):\n    print('There are ' + str(len(frame)) + ' records in group ' + str(group) + ' for processing.')\n\nprint('')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThere are 1177 records in group 0 for processing.\nThere are 1134 records in group 1 for processing.\nThere are 831 records in group 2 for processing.\n\n```\n:::\n:::\n\n\nNotice that this time I didn't pass in a column name to groupby(). Instead, I set the index of the dataframe to be STNAME, and if **no column identifier is passed groupby() will automatically use the index**.\n \nLet's take one more look at an example of how we might group data. In this example, I want to use a dataset of housing from airbnb. In this dataset there are two columns of interest, one is the cancellation_policy and the other is the review_scores_value:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndf = pd.read_csv('../data/week3/listings.csv')\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>listing_url</th>\n      <th>scrape_id</th>\n      <th>last_scraped</th>\n      <th>name</th>\n      <th>summary</th>\n      <th>space</th>\n      <th>description</th>\n      <th>experiences_offered</th>\n      <th>neighborhood_overview</th>\n      <th>...</th>\n      <th>review_scores_value</th>\n      <th>requires_license</th>\n      <th>license</th>\n      <th>jurisdiction_names</th>\n      <th>instant_bookable</th>\n      <th>cancellation_policy</th>\n      <th>require_guest_profile_picture</th>\n      <th>require_guest_phone_verification</th>\n      <th>calculated_host_listings_count</th>\n      <th>reviews_per_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12147973</td>\n      <td>https://www.airbnb.com/rooms/12147973</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Sunny Bungalow in the City</td>\n      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n      <td>The house has an open and cozy feel at the sam...</td>\n      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n      <td>none</td>\n      <td>Roslindale is quiet, convenient and friendly. ...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>moderate</td>\n      <td>f</td>\n      <td>f</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3075044</td>\n      <td>https://www.airbnb.com/rooms/3075044</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Charming room in pet friendly apt</td>\n      <td>Charming and quiet room in a second floor 1910...</td>\n      <td>Small but cozy and quite room with a full size...</td>\n      <td>Charming and quiet room in a second floor 1910...</td>\n      <td>none</td>\n      <td>The room is in Roslindale, a diverse and prima...</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>t</td>\n      <td>moderate</td>\n      <td>f</td>\n      <td>f</td>\n      <td>1</td>\n      <td>1.30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6976</td>\n      <td>https://www.airbnb.com/rooms/6976</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Mexican Folk Art Haven in Boston</td>\n      <td>Come stay with a friendly, middle-aged guy in ...</td>\n      <td>Come stay with a friendly, middle-aged guy in ...</td>\n      <td>Come stay with a friendly, middle-aged guy in ...</td>\n      <td>none</td>\n      <td>The LOCATION: Roslindale is a safe and diverse...</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>moderate</td>\n      <td>t</td>\n      <td>f</td>\n      <td>1</td>\n      <td>0.47</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1436513</td>\n      <td>https://www.airbnb.com/rooms/1436513</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Spacious Sunny Bedroom Suite in Historic Home</td>\n      <td>Come experience the comforts of home away from...</td>\n      <td>Most places you find in Boston are small howev...</td>\n      <td>Come experience the comforts of home away from...</td>\n      <td>none</td>\n      <td>Roslindale is a lovely little neighborhood loc...</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>moderate</td>\n      <td>f</td>\n      <td>f</td>\n      <td>1</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7651065</td>\n      <td>https://www.airbnb.com/rooms/7651065</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Come Home to Boston</td>\n      <td>My comfy, clean and relaxing home is one block...</td>\n      <td>Clean, attractive, private room, one block fro...</td>\n      <td>My comfy, clean and relaxing home is one block...</td>\n      <td>none</td>\n      <td>I love the proximity to downtown, the neighbor...</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>flexible</td>\n      <td>f</td>\n      <td>f</td>\n      <td>1</td>\n      <td>2.25</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 95 columns</p>\n</div>\n```\n:::\n:::\n\n\nSo, how would I group by both of these columns? A first approach might be to promote them to a multiindex and just call groupby().\n\nWhen we have a multiindex we need to pass in the levels we are interested in grouping by:\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndf = df.set_index(['cancellation_policy', 'review_scores_value'])\n\nfor group, frame in df.groupby(level=(0,1)):\n    print(group)\n\nprint('')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n('flexible', 2.0)\n('flexible', 4.0)\n('flexible', 5.0)\n('flexible', 6.0)\n('flexible', 7.0)\n('flexible', 8.0)\n('flexible', 9.0)\n('flexible', 10.0)\n('moderate', 2.0)\n('moderate', 4.0)\n('moderate', 6.0)\n('moderate', 7.0)\n('moderate', 8.0)\n('moderate', 9.0)\n('moderate', 10.0)\n('strict', 2.0)\n('strict', 3.0)\n('strict', 4.0)\n('strict', 5.0)\n('strict', 6.0)\n('strict', 7.0)\n('strict', 8.0)\n('strict', 9.0)\n('strict', 10.0)\n('super_strict_30', 6.0)\n('super_strict_30', 7.0)\n('super_strict_30', 8.0)\n('super_strict_30', 9.0)\n('super_strict_30', 10.0)\n\n```\n:::\n:::\n\n\nWhat if we wanted to group by the cancelation policy and review scores, but separate out all the 10's from those under ten? In this case, we could use a function to manage the groupings.\n \nIn this function, we want to check the \"review_scores_value\" portion of the index. item is in the tuple format: (cancellation_policy,review_scores_value):\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndef grouping_fun(item):\n    if item[1] == 10.0:\n        return (item[0], \"10.0\")\n    else:\n        return (item[0], \"not 10.0\")\n\nfor group, frame in df.groupby(by=grouping_fun):\n    print(group)\n\nprint('')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n('flexible', '10.0')\n('flexible', 'not 10.0')\n('moderate', '10.0')\n('moderate', 'not 10.0')\n('strict', '10.0')\n('strict', 'not 10.0')\n('super_strict_30', '10.0')\n('super_strict_30', 'not 10.0')\n\n```\n:::\n:::\n\n\n## Aggregation and .agg()\n\nTo this point we have applied very simple processing to our data after splitting, really just outputting some print statements to demonstrate how the splitting works. The pandas developers have three broad categories of data processing to happen during the apply step: \n\n- Aggregation of group data\n- Transformation of group data\n- Filtration of group data\n\nThe most straight forward apply step is the aggregation of data, and uses the method **agg()** on the groupby object. The agg() method allows you to apply a function or a list of function names to be executed along one of the axis of the DataFrame, default 0, which is the index (row) axis.\n\nThus far we have only iterated through the groupby object, unpacking it into a label (the group name) and a dataframe. But with agg we can pass in a dictionary of the columns we are interested in aggregating along with the function we are looking to apply to aggregate.\n\nLet's reset the index for our airbnb data:\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ndf = df.reset_index()\n\n#group by cancellation policy and find the avg review scores\ndf.groupby('cancellation_policy').agg({'review_scores_value' : np.average})\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_scores_value</th>\n    </tr>\n    <tr>\n      <th>cancellation_policy</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>flexible</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>moderate</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>strict</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>super_strict_30</th>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThat didn't seem to work at all. Just a bunch of not a numbers. The issue is actually in the function that we sent to aggregate. np.average does not ignore nans! However, there is a function we can use for this:\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ndf.groupby('cancellation_policy').agg({'review_scores_value': np.nanmean})\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_scores_value</th>\n    </tr>\n    <tr>\n      <th>cancellation_policy</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>flexible</th>\n      <td>9.237421</td>\n    </tr>\n    <tr>\n      <th>moderate</th>\n      <td>9.307398</td>\n    </tr>\n    <tr>\n      <th>strict</th>\n      <td>9.081441</td>\n    </tr>\n    <tr>\n      <th>super_strict_30</th>\n      <td>8.537313</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe can just extend this dictionary to aggregate by multiple functions or multiple columns.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndf.groupby('cancellation_policy').agg({'review_scores_value': (np.nanmean, np.nanstd),\n'reviews_per_month' : np.nanmean})\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">review_scores_value</th>\n      <th>reviews_per_month</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>nanmean</th>\n      <th>nanstd</th>\n      <th>nanmean</th>\n    </tr>\n    <tr>\n      <th>cancellation_policy</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>flexible</th>\n      <td>9.237421</td>\n      <td>1.096271</td>\n      <td>1.829210</td>\n    </tr>\n    <tr>\n      <th>moderate</th>\n      <td>9.307398</td>\n      <td>0.859859</td>\n      <td>2.391922</td>\n    </tr>\n    <tr>\n      <th>strict</th>\n      <td>9.081441</td>\n      <td>1.040531</td>\n      <td>1.873467</td>\n    </tr>\n    <tr>\n      <th>super_strict_30</th>\n      <td>8.537313</td>\n      <td>0.840785</td>\n      <td>0.340143</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n- First we're doing a group by on the dataframe object by the column \"cancellation_policy\". This creates a new GroupBy object.\n- Then we are invoking the agg() function on that object. The agg function is going to apply one or more functions we specify to the group dataframes and return a single row per dataframe/group. \n- When we called this function we sent it two dictionary entries, each with the key indicating which column we wanted functions applied to. \n- For the first column we actually supplied a tuple of two functions. Note that these are not function invocations, like np.nanmean(), or function names, like \"nanmean\" they are references to functions which will return single values. The group by object will recognize the tuple and call each function in order on the same column. \n- The results will be in a hierarchical index, but since they are columns they don't show as an index per se. Then we indicated another column and a single function we wanted to run.\n\n\n## Transformation\n\nTransformation is different from aggregation. \n\nWhere agg() returns a single value per column, so one row per group, **transform()** returns an object that is the same size as the group.\n\nEssentially, it broadcasts the function you supply over the grouped dataframe, returning a new dataframe. This makes combining data later easy.\n\nFor instance, suppose we want to include the average rating values in a given group by cancellation policy, but preserve the dataframe shape so that we could generate a difference between an individual observation and the sum.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n#define what columns we are interested in\ncols = ['cancellation_policy', 'review_scores_value']\n\n#transform the data and store it in a new df\ntransform_df = df[cols].groupby('cancellation_policy').transform(np.nanmean)\ntransform_df.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_scores_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9.307398</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.307398</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.307398</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.307398</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9.237421</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nSo we can see that the index here is actually the same as the original dataframe. So lets just join this in. Before we do that, lets rename the column in the transformed version:\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ntransform_df.rename({'review_scores_value':'mean_review_scores'}, axis = 'columns', inplace = True)\n\ndf = df.merge(transform_df, left_index = True, right_index = True)\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cancellation_policy</th>\n      <th>review_scores_value</th>\n      <th>id</th>\n      <th>listing_url</th>\n      <th>scrape_id</th>\n      <th>last_scraped</th>\n      <th>name</th>\n      <th>summary</th>\n      <th>space</th>\n      <th>description</th>\n      <th>...</th>\n      <th>review_scores_location</th>\n      <th>requires_license</th>\n      <th>license</th>\n      <th>jurisdiction_names</th>\n      <th>instant_bookable</th>\n      <th>require_guest_profile_picture</th>\n      <th>require_guest_phone_verification</th>\n      <th>calculated_host_listings_count</th>\n      <th>reviews_per_month</th>\n      <th>mean_review_scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>moderate</td>\n      <td>NaN</td>\n      <td>12147973</td>\n      <td>https://www.airbnb.com/rooms/12147973</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Sunny Bungalow in the City</td>\n      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n      <td>The house has an open and cozy feel at the sam...</td>\n      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>9.307398</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>moderate</td>\n      <td>9.0</td>\n      <td>3075044</td>\n      <td>https://www.airbnb.com/rooms/3075044</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Charming room in pet friendly apt</td>\n      <td>Charming and quiet room in a second floor 1910...</td>\n      <td>Small but cozy and quite room with a full size...</td>\n      <td>Charming and quiet room in a second floor 1910...</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>t</td>\n      <td>f</td>\n      <td>f</td>\n      <td>1</td>\n      <td>1.30</td>\n      <td>9.307398</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>moderate</td>\n      <td>10.0</td>\n      <td>6976</td>\n      <td>https://www.airbnb.com/rooms/6976</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Mexican Folk Art Haven in Boston</td>\n      <td>Come stay with a friendly, middle-aged guy in ...</td>\n      <td>Come stay with a friendly, middle-aged guy in ...</td>\n      <td>Come stay with a friendly, middle-aged guy in ...</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>t</td>\n      <td>f</td>\n      <td>1</td>\n      <td>0.47</td>\n      <td>9.307398</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>moderate</td>\n      <td>10.0</td>\n      <td>1436513</td>\n      <td>https://www.airbnb.com/rooms/1436513</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Spacious Sunny Bedroom Suite in Historic Home</td>\n      <td>Come experience the comforts of home away from...</td>\n      <td>Most places you find in Boston are small howev...</td>\n      <td>Come experience the comforts of home away from...</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>1</td>\n      <td>1.00</td>\n      <td>9.307398</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>flexible</td>\n      <td>10.0</td>\n      <td>7651065</td>\n      <td>https://www.airbnb.com/rooms/7651065</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Come Home to Boston</td>\n      <td>My comfy, clean and relaxing home is one block...</td>\n      <td>Clean, attractive, private room, one block fro...</td>\n      <td>My comfy, clean and relaxing home is one block...</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>1</td>\n      <td>2.25</td>\n      <td>9.237421</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 96 columns</p>\n</div>\n```\n:::\n:::\n\n\nGreat, we can see that our new column is in place, the mean_review_scores. So now we could create, for instance, the difference between a given row and it's group (the cancellation policy) means:\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\ndf['mean_dff'] = np.absolute(df['review_scores_value'] - df['mean_review_scores'])\ndf['mean_dff'].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n0         NaN\n1    0.307398\n2    0.692602\n3    0.692602\n4    0.762579\nName: mean_dff, dtype: float64\n```\n:::\n:::\n\n\nNumpy absolute value calculates the absolute value of the values in a Numpy array. The absolute value (or modulus) | x | of a real number x is the non-negative value of x without regard to its sign.\n\n\n## Filtering\n\nThe GroupBy object has build in support for filtering groups as well. It's often that you'll want to group by some feature, then make some transformation to the groups, then drop certain groups as part of your cleaning routines. \n\nThe filter() function takes in a function which it applies to each group dataframe and returns either a True or a False, depending upon whether that group should be included in the results.\n\nFor instance, if we only want those groups which have a mean rating above 9 included in our results:\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ndf.groupby('cancellation_policy').filter(lambda x: np.nanmean(x['review_scores_value']) > 9.2).head()\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cancellation_policy</th>\n      <th>review_scores_value</th>\n      <th>id</th>\n      <th>listing_url</th>\n      <th>scrape_id</th>\n      <th>last_scraped</th>\n      <th>name</th>\n      <th>summary</th>\n      <th>space</th>\n      <th>description</th>\n      <th>...</th>\n      <th>requires_license</th>\n      <th>license</th>\n      <th>jurisdiction_names</th>\n      <th>instant_bookable</th>\n      <th>require_guest_profile_picture</th>\n      <th>require_guest_phone_verification</th>\n      <th>calculated_host_listings_count</th>\n      <th>reviews_per_month</th>\n      <th>mean_review_scores</th>\n      <th>mean_dff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>moderate</td>\n      <td>NaN</td>\n      <td>12147973</td>\n      <td>https://www.airbnb.com/rooms/12147973</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Sunny Bungalow in the City</td>\n      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n      <td>The house has an open and cozy feel at the sam...</td>\n      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n      <td>...</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>9.307398</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>moderate</td>\n      <td>9.0</td>\n      <td>3075044</td>\n      <td>https://www.airbnb.com/rooms/3075044</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Charming room in pet friendly apt</td>\n      <td>Charming and quiet room in a second floor 1910...</td>\n      <td>Small but cozy and quite room with a full size...</td>\n      <td>Charming and quiet room in a second floor 1910...</td>\n      <td>...</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>t</td>\n      <td>f</td>\n      <td>f</td>\n      <td>1</td>\n      <td>1.30</td>\n      <td>9.307398</td>\n      <td>0.307398</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>moderate</td>\n      <td>10.0</td>\n      <td>6976</td>\n      <td>https://www.airbnb.com/rooms/6976</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Mexican Folk Art Haven in Boston</td>\n      <td>Come stay with a friendly, middle-aged guy in ...</td>\n      <td>Come stay with a friendly, middle-aged guy in ...</td>\n      <td>Come stay with a friendly, middle-aged guy in ...</td>\n      <td>...</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>t</td>\n      <td>f</td>\n      <td>1</td>\n      <td>0.47</td>\n      <td>9.307398</td>\n      <td>0.692602</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>moderate</td>\n      <td>10.0</td>\n      <td>1436513</td>\n      <td>https://www.airbnb.com/rooms/1436513</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Spacious Sunny Bedroom Suite in Historic Home</td>\n      <td>Come experience the comforts of home away from...</td>\n      <td>Most places you find in Boston are small howev...</td>\n      <td>Come experience the comforts of home away from...</td>\n      <td>...</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>1</td>\n      <td>1.00</td>\n      <td>9.307398</td>\n      <td>0.692602</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>flexible</td>\n      <td>10.0</td>\n      <td>7651065</td>\n      <td>https://www.airbnb.com/rooms/7651065</td>\n      <td>20160906204935</td>\n      <td>2016-09-07</td>\n      <td>Come Home to Boston</td>\n      <td>My comfy, clean and relaxing home is one block...</td>\n      <td>Clean, attractive, private room, one block fro...</td>\n      <td>My comfy, clean and relaxing home is one block...</td>\n      <td>...</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>1</td>\n      <td>2.25</td>\n      <td>9.237421</td>\n      <td>0.762579</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 97 columns</p>\n</div>\n```\n:::\n:::\n\n\nNotice that the results are still indexed, but that any of the results which were in a group with a mean review score of less than or equal to 9.2 were not copied over.\n\n\n## Applying\n\nBy far the most common operation I invoke on groupby objects is the apply() function. This allows you to apply an arbitrary function to each group, and stitch the results back for each apply() into a single dataframe where the index is preserved.\n\nLets look at an example using our airbnb data, I'm going to get a clean copy of the dataframe:\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ndf=pd.read_csv(\"../data/week3/listings.csv\")\n\n# And lets just include some of the columns we were interested in previously\ndf = df[['cancellation_policy','review_scores_value']]\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cancellation_policy</th>\n      <th>review_scores_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>moderate</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>moderate</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>moderate</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>moderate</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>flexible</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nIn previous work we wanted to find the average review score of a listing and its deviation from the group mean. This was a two step process, first we used transform() on the groupby object and then we had to broadcast to create a new column. With apply() we could wrap this logic in one place:\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\ndef calc_mean_review_scores(group):\n    # group is a dataframe just of whatever we have grouped by, e.g. cancellation policy,     \n    #so we can treat this as the complete dataframe\n    avg = np.nanmean(group['review_scores_value'])\n    \n    #now braodcast our formula and create a new column\n    group['review_scores_mean_diff'] = np.abs(avg - group['review_scores_value'])\n    return group\n\n#now we apply this to all the groups\ndf.groupby('cancellation_policy').apply(calc_mean_review_scores).head()\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cancellation_policy</th>\n      <th>review_scores_value</th>\n      <th>review_scores_mean_diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>moderate</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>moderate</td>\n      <td>9.0</td>\n      <td>0.307398</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>moderate</td>\n      <td>10.0</td>\n      <td>0.692602</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>moderate</td>\n      <td>10.0</td>\n      <td>0.692602</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>flexible</td>\n      <td>10.0</td>\n      <td>0.762579</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nUsing apply can be slower than using some of the specialized functions, especially agg(). But, if your dataframes are not huge, it's a solid general purpose approach.\n\n",
    "supporting": [
      "7_groupby_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}