{
  "hash": "a70de54e7e0ac81157962d8bd8acc766",
  "result": {
    "markdown": "# Pandas \n\n## Series data structure\n\nThe series is one of the core data structures in pandas. You think of it a cross between a list and a dictionary. The items are all stored in an order and there's labels with which you can retrieve them. An easy way to visualize this is two columns of data. The first is the special index, a lot like keys in a dictionary. While the second is your actual data. It's important to note that the data column has a label of its own and can be retrieved using the `.name` attribute. This is different than with dictionaries and is useful when it comes to merging multiple columns of data. \n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport timeit\n```\n:::\n\n\nYou can create a series by passing in a list of values. When you do this, Pandas automatically assigns an index starting with zero and sets the name of the series to None. \nOne of the easiest ways to create a series is to use an array-like object, like a list. \n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nstudents = ['Alice', 'Jack', 'Molly']\n```\n:::\n\n\nNow we just call the Series function in pandas and pass in the students:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\npd.Series(students)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n0    Alice\n1     Jack\n2    Molly\ndtype: object\n```\n:::\n:::\n\n\nThe result is a Series object which is nicely rendered to the screen. \n\nWe see here that  the pandas has automatically identified the type of data in this Series as \"object\" and set the dytpe parameter as appropriate. We see that the values are indexed with integers, starting at zero.\n\nWe don't have to use strings. If we passed in a list of whole numbers, for instance, we could see that panda sets the type to int64. Underneath panda stores series values in a  typed array using the Numpy library. This offers significant speedup when processing data  versus traditional python lists.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nnumbers = [1,2,3]\npd.Series(numbers)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n0    1\n1    2\n2    3\ndtype: int64\n```\n:::\n:::\n\n\nAnd we see on my architecture that the result is a dtype of int64 objects\n\n## Missing data\n\nThere's some other typing details that exist for performance that are important to know. The most important is how Numpy and thus pandas handle **missing data**. \n\nIn Python, we have the none type to indicate a lack of data. But what do we do if we want  to have a typed list like we do in the series object?\n\nUnderneath, pandas does some type conversion. If we create a list of strings and we have  one element, a None type, pandas inserts it as a None and uses the type object for the underlying array. \n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nstudents = ['Alice', 'Jack', None]\npd.Series(students)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n0    Alice\n1     Jack\n2     None\ndtype: object\n```\n:::\n:::\n\n\nHowever, if we create a list of numbers, integers or floats, and put in the None type, pandas automatically converts this to a special floating point value designated as NaN, which stands for \"Not a Number\".\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nnumbers = [1,2,None]\npd.Series(numbers)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n0    1.0\n1    2.0\n2    NaN\ndtype: float64\n```\n:::\n:::\n\n\nYou'll notice a couple of things:\n\n- First, NaN is a different value. \n- Second, pandas set the dytpe of this series to floating point numbers instead of object or ints. That's maybe a bit of a surprise - why not just leave this as an integer?\n\nUnderneath, pandas represents NaN as a floating point number, and because integers can be typecast to floats, pandas went and converted our integers to floats. So when you're wondering why the list of integers you put into a Series is not floats, it's probably because there is some missing data.\n\nIt is important to stress that None and NaN might be being used by the data scientist in the same way, to denote missing data, but that underneath these are not represented by pandas in the same way.\n\n**NaN is *NOT* equivilent to None and when we try the equality test, the result is False.**\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nnp.nan == None\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\nFalse\n```\n:::\n:::\n\n\nIt turns out that you actually can't do an equality test of NAN to itself. When you do, the answer is always False. \n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nnp.nan == np.nan\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nFalse\n```\n:::\n:::\n\n\nInstead, you need to use special functions to test for the presence of not a number, such as the Numpy library `isnan()`.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nnp.isnan(np.nan)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nTrue\n```\n:::\n:::\n\n\nSo keep in mind when you see NaN, it's meaning is similar to None, but it's a numeric value and treated differently for efficiency reasons.\n\n\n## Creating Series from dictionaries\n\nA series can be created directly from dictionary data. If you do this, the index is automatically assigned to the keys of the dictionary that you provided and not just incrementing integers.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nstudents_scores = {'Alice': 'Physics',\n                   'Jack': 'Chemistry',\n                   'Molly': 'English'}\ns = pd.Series(students_scores)\ns\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\nAlice      Physics\nJack     Chemistry\nMolly      English\ndtype: object\n```\n:::\n:::\n\n\nWe see that, since it was string data, pandas set the data type of the series to \"object\". We see that the index, the first column, is also a list of strings.\n\nOnce the series has been created, we can get the index object using the index attribute.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ns.index\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\nIndex(['Alice', 'Jack', 'Molly'], dtype='object')\n```\n:::\n:::\n\n\nAs you play more with pandas you'll notice that a lot of things are implemented as numpy arrays, and have the dtype value set. This is true of indicies, and here pandas inferred that we were using objects for the index.\n\nNow, this is kind of interesting. The dtype of object is not just for strings, but for arbitrary objects. Lets create a more complex type of data, say, a list of tuples.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nstudents = [(\"Alice\",\"Brown\"), (\"Jack\", \"White\"), (\"Molly\", \"Green\")]\npd.Series(students)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n0    (Alice, Brown)\n1     (Jack, White)\n2    (Molly, Green)\ndtype: object\n```\n:::\n:::\n\n\nWe see that each of the tuples is stored in the series object, and the type is object.\n\nYou can also separate your index creation from the data by passing in the index as a list explicitly to the series.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ns = pd.Series(['Physics', 'Chemistry', 'English'], index=['Alice', 'Jack', 'Molly'])\ns\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nAlice      Physics\nJack     Chemistry\nMolly      English\ndtype: object\n```\n:::\n:::\n\n\nSo what happens if your list of values in the index object are not aligned with the keys in your dictionary for creating the series? Well, pandas overrides the automatic creation to favor only and all of the indices values that you provided. So it will ignore from your dictionary all keys which are not in your index, and pandas will add None or NaN type values for any index value you provide, which is not in your dictionary key list.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nstudents_scores = {'Alice': 'Physics',\n                   'Jack': 'Chemistry',\n                   'Molly': 'English'}\n\n# When I create the series object though I'll only ask for an index with three students, and I'll exclude Jack\ns = pd.Series(students_scores, index=['Alice', 'Molly', 'Sam'])\ns\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\nAlice    Physics\nMolly    English\nSam          NaN\ndtype: object\n```\n:::\n:::\n\n\n## Querying a Series\n\nA pandas Series can be queried either by the index position or the index label. If you don't give an index to the series when querying, the position and the label are effectively the same values. \n\n- To query by numeric location, starting at zero, use the `iloc` attribute. \n- To query by the index label, you can use the `loc` attribute. \n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nstudents_classes = {'Alice': 'Physics',\n                   'Jack': 'Chemistry',\n                   'Molly': 'English',\n                   'Sam': 'History'}\n\ns = pd.Series(students_classes)\ns\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\nAlice      Physics\nJack     Chemistry\nMolly      English\nSam        History\ndtype: object\n```\n:::\n:::\n\n\nSo, for this series, if you wanted to see the fourth entry we would we would use the iloc attribute with the parameter 3.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ns.iloc[3]\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n'History'\n```\n:::\n:::\n\n\nIf you wanted to see what class Molly has, we would use the loc attribute with a parameter of Molly.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ns.loc['Molly']\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n'English'\n```\n:::\n:::\n\n\nKeep in mind that **iloc and loc are not methods, they are attributes**. So you don't use parentheses to query them, but square brackets instead, which is called the **indexing operator**. \n\nPandas tries to make our code a bit more readable and provides a sort of smart syntax using the indexing operator directly on the series itself. For instance, if you pass in an integer parameter, the operator will behave as if you want it to query via the iloc attribute\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\ns[3]\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n'History'\n```\n:::\n:::\n\n\nIf you pass in an object, it will query as if you wanted to use the label based loc attribute.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\ns['Molly']\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\n'English'\n```\n:::\n:::\n\n\nSo what happens if your index is a list of integers? This is a bit complicated and Pandas can't  determine automatically whether you're intending to query by index position or index label. So you need to be careful when using the indexing operator on the Series itself. The safer option is to be more explicit and use the iloc or loc attributes directly.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nclass_code = {99: 'Physics',\n              100: 'Chemistry',\n              101: 'English',\n              102: 'History'}\ns = pd.Series(class_code)\ns\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\n99       Physics\n100    Chemistry\n101      English\n102      History\ndtype: object\n```\n:::\n:::\n\n\nIf we try and call `s[0]` we get a key error because there's no item in the classes list with an index of zero, instead we have to call iloc explicitly if we want the first item.\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n#s[0]\n```\n:::\n\n\nThe code above will give us a `KeyError: 0`\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\ns.iloc[0]\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\n'Physics'\n```\n:::\n:::\n\n\nNow we know how to get data out of the series, let's talk about working with the data. A common task is to want to consider all of the values inside of a series and do some sort of  operation. This could be trying to find a certain number, or summarizing data or transforming the data in some way.\n\nA typical programmatic approach to this would be to iterate over all the items in the series, and invoke the operation one is interested in. For instance, we could create a Series of integers representing student grades, and just try and get an average grade\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\ngrades = pd.Series([90, 80, 70, 60])\ngrades\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\n0    90\n1    80\n2    70\n3    60\ndtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\ntotal = 0\n\nfor grade in grades:\n    total += grade\n\nprint(total/len(grades))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n75.0\n```\n:::\n:::\n\n\nThis works, but it's slow. Modern computers can do many tasks simultaneously, especially, but not only, tasks involving mathematics.\n\nPandas and the underlying numpy libraries support a method of computation called **vectorization.** Vectorization works with most of the functions in the numpy library, including the sum function.\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\ntotal = np.sum(grades)\nprint(total/len(grades))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n75.0\n```\n:::\n:::\n\n\nNow both of these methods create the same value, but is one actually faster? The Jupyter Notebook has a magic function which can help.\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nnumbers = pd.Series(np.random.randint(0,1000,10000))\n\n#look at the first 5 items\nnumbers.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\n0    881\n1    888\n2    881\n3     79\n4    181\ndtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\n#control length of series\nlen(numbers)\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\n10000\n```\n:::\n:::\n\n\nOk, we're confident now that we have a big series. The ipython interpreter has something called **magic functions** begin with a percentage sign. If we type this sign and then hit the Tab key, you can see a list of the available magic functions. You could write your own magic functions too, but that's a little bit outside of the scope of this course.\n\nHere, we're actually going to use what's called a **cellular magic function**. These start with two percentage signs and wrap the code in the current Jupyter cell. The function we're going to use is called `timeit`. This function will run our code a few times to determine, on average, how long it takes.\n\nLet's run timeit with our original iterative code. You can give timeit the number of loops that  you would like to run. By default, it is 1,000 loops. I'll ask timeit here to use 100 runs because we're recording this. Note that in order to use a cellular magic function, it has to be the first line in the cell\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\n%%timeit -n 100\n\ntotal = 0\nfor number in numbers:\n    total += number\n\ntotal/len(numbers)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.43 ms ± 330 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n```\n:::\n:::\n\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\n%%timeit -n 100\ntotal = np.sum(numbers)\ntotal/len(numbers)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n70.1 µs ± 22.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n```\n:::\n:::\n\n\nThis is a pretty shocking difference in the speed and demonstrates why one should be aware of parallel computing features and start thinking in functional programming terms. \n\nPut more simply, vectorization is the ability for a computer to execute multiple instructions at once, and with high performance chips, especially graphics cards, you can get dramatic speedups. Modern graphics cards can run thousands of instructions in parallel.\n\nA Related feature in pandas and nummy is called **broadcasting.** With broadcasting, you can apply an operation to every value in the series, changing the series. For instance, if we wanted to increase every random variable by 2, we could do so quickly using the += operator directly on the Series object.\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\nnumbers.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\n0    881\n1    888\n2    881\n3     79\n4    181\ndtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\nnumbers += 2\nnumbers.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\n0    883\n1    890\n2    883\n3     81\n4    183\ndtype: int64\n```\n:::\n:::\n\n\nThe procedural way of doing this would be to iterate through all of the items in the series and increase the values directly. Pandas does support iterating through a series much like a dictionary, allowing you to unpack values easily.\n\nWe can use the `iteritems()` function which returns a label and value \n\nPandas.iat(): allows to access a single value for a row/column pair by integer position.\n\nSelection with .at is nearly identical to .loc but it only selects a single 'cell' in your DataFrame/Series. We usually refer to this cell as a scalar value.\n\n- loc: label based, only works on index\n- iloc: position based\n- at: label based, gets scalar values. It's a very fast loc; Cannot operate on array indexers. Can assign new indices and columns\n- iat: position based, gets scalar values. It's a very fast iloc, Cannot work in array indexers. Cannot! assign new indices and columns.\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\nfor label, value in numbers.iteritems():\n    # in the early version of pandas we would use the set_value() function\n    # in the current version, we use the iat() or at() functions,\n    numbers.iat[label] = value + 2\n    #numbers.iloc[label] = value + 2\n\nnumbers.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\n0    885\n1    892\n2    885\n3     83\n4    185\ndtype: int64\n```\n:::\n:::\n\n\nLet's compare the speed:\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\n%%timeit -n 10\n\n# we'll create a blank new series of items to deal with\ns = pd.Series(np.random.randint(0,1000,1000))\n\n# And we'll just rewrite our loop from above.\nfor label, value in s.iteritems():\n    s.loc[label]= value+2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n55.7 ms ± 11.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n```\n:::\n:::\n\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\n%%timeit -n 10\n\n# We need to recreate a series\ns = pd.Series(np.random.randint(0,1000,1000))\n\n# And we just broadcast with +=\ns+=2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe slowest run took 11.68 times longer than the fastest. This could mean that an intermediate result is being cached.\n929 µs ± 807 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n```\n:::\n:::\n\n\nNot only is it significantly faster, but it's more concise and even easier to read too. The typical mathematical operations you would expect are vectorized, and the nump documentation outlines what it takes to create vectorized functions of your own\n\nOne last note on using the indexing operators to access series data. **The .loc attribute lets you not only modify data in place, but also add new data as well((. If the value you pass in as the index doesn't exist, then a new entry is added. And keep in mind, indices can have mixed types.  While it's important to be aware of the typing going on underneath, Pandas will automatically  change the underlying NumPy types as appropriate.\n\n::: {.cell execution_count=35}\n``` {.python .cell-code}\ns = pd.Series([1, 2, 3])\n\n#add a new value\ns.loc['History'] = 102\n\ns\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```\n0            1\n1            2\n2            3\nHistory    102\ndtype: int64\n```\n:::\n:::\n\n\nWe see that mixed types for data values or index labels are no problem for Pandas. Since \n\"History\" is not in the original list of indices, s.loc['History'] essentially creates a \nnew element in the series, with the index named \"History\", and the value of 102\n\nUp until now I've shown only examples of a series where the index values were unique. I want  to end this lecture by showing an example where index values are not unique, and this makes  pandas Series a little different conceptually then, for instance, a relational database.\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\n# Lets create a Series with students and the courses which they have taken\nstudents_classes = pd.Series({'Alice': 'Physics',\n                   'Jack': 'Chemistry',\n                   'Molly': 'English',\n                   'Sam': 'History'})\nstudents_classes\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```\nAlice      Physics\nJack     Chemistry\nMolly      English\nSam        History\ndtype: object\n```\n:::\n:::\n\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\n# Now lets create a Series just for some new student Kelly, which lists all of the courses she has taken.\n#We'll set the index to Kelly, and the data to be the names of courses.\nkelly_classes = pd.Series(['Philosophy', 'Arts', 'Math'], index=['Kelly', 'Kelly', 'Kelly'])\nkelly_classes\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```\nKelly    Philosophy\nKelly          Arts\nKelly          Math\ndtype: object\n```\n:::\n:::\n\n\n## Appending Series\n\nFinally, we can append all of the data in this new Series to the first using the `.append()` function.\n\n::: {.cell execution_count=38}\n``` {.python .cell-code}\nall_students_classes = students_classes.append(kelly_classes)\nall_students_classes\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\nAlice       Physics\nJack      Chemistry\nMolly       English\nSam         History\nKelly    Philosophy\nKelly          Arts\nKelly          Math\ndtype: object\n```\n:::\n:::\n\n\nThere are a couple of important considerations when using append. \n\n- First, Pandas will take the series and try to infer the best data types to use. In this example, everything is a string, so there's no problems here. \n- Second, the append method doesn't actually change the underlying Series objects, it instead returns a new series which is made up of the two appended together. This is a common pattern in pandas - by default returning a new object instead of modifying in place - and one you should come to expect. By printing the original series we can see that that series hasn't changed.\n\n::: {.cell execution_count=39}\n``` {.python .cell-code}\nstudents_classes\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```\nAlice      Physics\nJack     Chemistry\nMolly      English\nSam        History\ndtype: object\n```\n:::\n:::\n\n\nFinally, we see that when we query the appended series for Kelly, we don't get a single value, but a series itself. \n\n::: {.cell execution_count=40}\n``` {.python .cell-code}\nall_students_classes['Kelly']\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```\nKelly    Philosophy\nKelly          Arts\nKelly          Math\ndtype: object\n```\n:::\n:::\n\n\n## Dataframes\n\nThe DataFrame data structure is the heart of the Panda's library. It's a primary object that you'll be working with in data analysis and cleaning tasks.\n\nThe DataFrame is conceptually a two-dimensional series object, where there's an index and multiple columns of content, with each column having a label. In fact, the distinction between a column and a row is really only a conceptual distinction. And you can think of the DataFrame itself as simply a two-axes labeled array.\n\n::: {.cell execution_count=41}\n``` {.python .cell-code}\nrecord1 = pd.Series({'Name': 'Alice',\n                        'Class': 'Physics',\n                        'Score': 85})\nrecord2 = pd.Series({'Name': 'Jack',\n                        'Class': 'Chemistry',\n                        'Score': 82})\nrecord3 = pd.Series({'Name': 'Helen',\n                        'Class': 'Biology',\n                        'Score': 90})\n```\n:::\n\n\nLike a Series, the DataFrame object is index. Here I'll use a group of series, where each series represents a row of data. Just like the Series function, we can pass in our individual items in an array, and we can pass in our index values as a second arguments\n\n::: {.cell execution_count=42}\n``` {.python .cell-code}\ndf = pd.DataFrame([record1, record2, record3],\n    index = ['school1', 'school2', 'school1'])\n    \ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Class</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>Physics</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Jack</td>\n      <td>Chemistry</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>Biology</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nYou'll notice here that Jupyter creates a nice bit of HTML to render the results of the dataframe. So we have the index, which is the leftmost column and is the school name, and then we have the rows of data, where each row has a column header which was given in our initial record dictionaries.\n\nAn alternative method is that you could use a list of dictionaries, where each dictionary represents a row of data.\n\n::: {.cell execution_count=43}\n``` {.python .cell-code}\nstudents = [{'Name': 'Alice',\n              'Class': 'Physics',\n              'Score': 85},\n            {'Name': 'Jack',\n             'Class': 'Chemistry',\n             'Score': 82},\n            {'Name': 'Helen',\n             'Class': 'Biology',\n             'Score': 90}]\n\n# Then we pass this list of dictionaries into the DataFrame function\ndf = pd.DataFrame(students, index=['school1', 'school2', 'school1'])\n# And lets print the head again\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Class</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>Physics</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Jack</td>\n      <td>Chemistry</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>Biology</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nSimilar to the series, we can extract data using the `.iloc` and `.loc` attributes. Because the  DataFrame is two-dimensional, passing a single value to the loc indexing operator will return the series if there's only one row to return.\n\nFor instance, if we wanted to select data associated with school2, we would just query the .loc attribute with one parameter.\n\n::: {.cell execution_count=44}\n``` {.python .cell-code}\ndf.loc['school2']\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```\nName          Jack\nClass    Chemistry\nScore           82\nName: school2, dtype: object\n```\n:::\n:::\n\n\nYou'll note that the name of the series is returned as the index value, while the column \nname is included in the output. We can check the data type of the return using the python type function.\n\n::: {.cell execution_count=45}\n``` {.python .cell-code}\ntype(df.loc['school2'])\n```\n\n::: {.cell-output .cell-output-display execution_count=45}\n```\npandas.core.series.Series\n```\n:::\n:::\n\n\nIt's important to remember that the indices and column names along either axes horizontal or  vertical, could be non-unique. In this example, we see two records for school1 as different rows.\n\nIf we use a single value with the DataFrame lock attribute, multiple rows of the DataFrame will return, not as a new series, but as a new DataFrame.\n\n::: {.cell execution_count=46}\n``` {.python .cell-code}\ndf.loc['school1']\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Class</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>Physics</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>Biology</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=47}\n``` {.python .cell-code}\n# And we can see the the type of this is different too\ntype(df.loc['school1'])\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```\npandas.core.frame.DataFrame\n```\n:::\n:::\n\n\nOne of the powers of the Panda's DataFrame is that you can quickly select data based on multiple axes.For instance, if you wanted to just list the student names for school1, you would supply two parameters to .loc, one being the row index and the other being the column name.\n\n::: {.cell execution_count=48}\n``` {.python .cell-code}\ndf.loc['school1', 'Name']\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```\nschool1    Alice\nschool1    Helen\nName: Name, dtype: object\n```\n:::\n:::\n\n\nRemember, just like the Series, the pandas developers have implemented this using the indexing operator and not as parameters to a function.\n\nWhat would we do if we just wanted to select a single column though? Well, there are a few mechanisms. Firstly, we could transpose the matrix. This pivots all of the rows into columns and all of the columns into rows, and is done with the **T attribute**\n\n::: {.cell execution_count=49}\n``` {.python .cell-code}\ndf.T\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>school1</th>\n      <th>school2</th>\n      <th>school1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Name</th>\n      <td>Alice</td>\n      <td>Jack</td>\n      <td>Helen</td>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <td>Physics</td>\n      <td>Chemistry</td>\n      <td>Biology</td>\n    </tr>\n    <tr>\n      <th>Score</th>\n      <td>85</td>\n      <td>82</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThen we can call .loc on the transpose to get the student names only\n\n::: {.cell execution_count=50}\n``` {.python .cell-code}\ndf.T.loc['Name']\n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```\nschool1    Alice\nschool2     Jack\nschool1    Helen\nName: Name, dtype: object\n```\n:::\n:::\n\n\nHowever, since iloc and loc are used for row selection, Panda reserves the indexing operator  directly on the DataFrame for column selection. In a Panda's DataFrame, columns always have a name. \n\nSo this selection is always label based, and is not as confusing as it was when using the square bracket operator on the series objects. For those familiar with relational databases, this operator is analogous to column projection.\n\n::: {.cell execution_count=51}\n``` {.python .cell-code}\ndf['Name']\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\nschool1    Alice\nschool2     Jack\nschool1    Helen\nName: Name, dtype: object\n```\n:::\n:::\n\n\nIn practice, this works really well since you're often trying to add or drop new columns. However, this also means that you get a key error if you try and use .loc with a column name:\n\n::: {.cell execution_count=52}\n``` {.python .cell-code}\n#this gives an error:\n#df.loc['Name']\n```\n:::\n\n\nNote too that the result of a single column projection is a Series object.\n\n::: {.cell execution_count=53}\n``` {.python .cell-code}\ntype(df['Name'])\n```\n\n::: {.cell-output .cell-output-display execution_count=53}\n```\npandas.core.series.Series\n```\n:::\n:::\n\n\nSince the result of using the indexing operator is either a DataFrame or Series, you can chain  operations together. For instance, we can select all of the rows which related to school1 using .loc, then project the name column from just those rows.\n\n::: {.cell execution_count=54}\n``` {.python .cell-code}\ndf.loc['school1']['Name']\n```\n\n::: {.cell-output .cell-output-display execution_count=54}\n```\nschool1    Alice\nschool1    Helen\nName: Name, dtype: object\n```\n:::\n:::\n\n\nIf you get confused, use type to check the responses from resulting operations\n\n::: {.cell execution_count=55}\n``` {.python .cell-code}\nprint(type(df.loc['school1'])) #should be a DataFrame\nprint(type(df.loc['school1']['Name'])) #should be a Series\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\n<class 'pandas.core.series.Series'>\n```\n:::\n:::\n\n\nChaining, by indexing on the return type of another index, can come with some costs and is best avoided if you can use another approach. In particular, chaining tends to cause Pandas to return a copy of the DataFrame instead of a view on the DataFrame. For selecting data, this is not a big deal, though it might be slower than necessary. If you are changing data though this is an important distinction and can be a source of error.\n\nHere's another approach. As we saw, .loc does row selection, and it can take two parameters, the row index and the list of column names. The .loc attribute also supports slicing.\n\nIf we wanted to select all rows, we can use a colon to indicate a full slice from beginning to end. This is just like slicing characters in a list in python. Then we can add the column name as the second parameter as a string. If we wanted to include multiple columns, we could do so in a list. and Pandas will bring back only the columns we have asked for.\n\n::: {.cell execution_count=56}\n``` {.python .cell-code}\ndf.loc[:,['Name', 'Score']]\n```\n\n::: {.cell-output .cell-output-display execution_count=56}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Jack</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nTake a look at that again. The colon means that we want to get all of the rows, and the list in the second argument position is the list of columns we want to get back.\n\n## Dropping data\n\nBefore we leave the discussion of accessing data in DataFrames, lets talk about dropping data.\n\nIt's easy to delete data in Series and DataFrames, and we can use the **drop function** to do so. This function takes a single parameter, which is the index or row label, to drop. \n\nThis is another tricky place for new users -- the drop function doesn't change the DataFrame by default! Instead,the drop function returns to you a copy of the DataFrame with the given rows removed.\n\n::: {.cell execution_count=57}\n``` {.python .cell-code}\ndf.drop('school1')\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Class</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school2</th>\n      <td>Jack</td>\n      <td>Chemistry</td>\n      <td>82</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=58}\n``` {.python .cell-code}\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=58}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Class</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>Physics</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Jack</td>\n      <td>Chemistry</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>Biology</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nDrop has two interesting optional parameters:\n\n- The first is called inplace, and if it's  set to true, the DataFrame will be updated in place, instead of a copy being returned.  \n- The second parameter is the axes, which should be dropped. By default, this value is 0, indicating the row axis. But you could change it to 1 if you want to drop a column.\n\nFor example, lets make a copy of a DataFrame using **.copy()**:\n\n::: {.cell execution_count=59}\n``` {.python .cell-code}\ncopy_df = df.copy()\n\n#drop the name column of the copy\ncopy_df.drop('Name', inplace = True, axis = 1)\ncopy_df\n```\n\n::: {.cell-output .cell-output-display execution_count=59}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Physics</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Chemistry</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Biology</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=60}\n``` {.python .cell-code}\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=60}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Class</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>Physics</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Jack</td>\n      <td>Chemistry</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>Biology</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThere is a second way to drop a column, and that's directly through the use of the indexing  operator, using the **del keyword**. This way of dropping data, however, takes immediate effect on the DataFrame and does not return a view.\n\n::: {.cell execution_count=61}\n``` {.python .cell-code}\ndel copy_df['Class']\ncopy_df\n```\n\n::: {.cell-output .cell-output-display execution_count=61}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Adding columns to a df\n\nAdding a new column to the DataFrame is as easy as assigning it to some value using the indexing operator. For instance, if we wanted to add a class ranking column with default  value of None, we could do so by using the assignment operator after the square brackets. This broadcasts the default value to the new column immediately.\n\n::: {.cell execution_count=62}\n``` {.python .cell-code}\ndf['ClassRanking'] = None\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=62}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Class</th>\n      <th>Score</th>\n      <th>ClassRanking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>school1</th>\n      <td>Alice</td>\n      <td>Physics</td>\n      <td>85</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>school2</th>\n      <td>Jack</td>\n      <td>Chemistry</td>\n      <td>82</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>school1</th>\n      <td>Helen</td>\n      <td>Biology</td>\n      <td>90</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## DataFrame Indexing and Loading\n\nA common workflow is to read the dataset in, usually from some external file, then begin to clean and manipulate the dataset for analysis. In this lecture I'm going to demonstrate how you can load data from a comma separated file into a DataFrame.\n\nLets just jump right in and talk about comma separated values (csv) files. \n\nNow, I'm going to make a quick aside because it's convenient here. The Jupyter notebooks use ipython as the kernel underneath, which provides convenient ways to integrate lower level shell commands, which are programs run in the underlying operating system. If you're not familiar with the shell don't worry too much about this, but if you are, this is super handy for integration of your data science workflows. \n\nI want to use one shell command here called \"cat\", for \"concatenate\", which just outputs the contents of a file. In ipython if we prepend the line with an exclamation mark it will execute the remainder of the line as a shell command. So lets look at the content of a CSV file.\n\nNotice: Instead of cat, we use head to use head to display the first 10 rows.\n\n::: {.cell execution_count=63}\n``` {.python .cell-code}\n!head ../data/week2/Admission_Predict.csv\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSerial No.,GRE Score,TOEFL Score,University Rating,SOP,LOR ,CGPA,Research,Chance of Admit \r\n1,337,118,4,4.5,4.5,9.65,1,0.92\r\n2,324,107,4,4,4.5,8.87,1,0.76\r\n3,316,104,3,3,3.5,8,1,0.72\r\n4,322,110,3,3.5,2.5,8.67,1,0.8\r\n5,314,103,2,2,3,8.21,0,0.65\r\n6,330,115,5,4.5,3,9.34,1,0.9\r\n7,321,109,3,3,4,8.2,1,0.75\r\n8,308,101,2,3,4,7.9,0,0.68\r\n9,302,102,1,2,1.5,8,0,0.5\r\n```\n:::\n:::\n\n\nWe see from the output that there is a list of columns, and the column identifiers are listed as strings on the first line of the file. Then we have rows of data, all columns separated by commas. We can read in this file using pandas.\n\n::: {.cell execution_count=64}\n``` {.python .cell-code}\nimport pandas as pd\n\n#turn csv into a dataframe\ndf = pd.read_csv('../data/week2/Admission_Predict.csv')\n\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=64}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Serial No.</th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Chance of Admit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>0.65</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe notice that by default index starts with 0 while the students' serial number starts from 1. If you jump back to the CSV output you'll deduce that pandas has create a new index. Instead, we can set the serial no as the index if we want to by using the index_col.\n\n::: {.cell execution_count=65}\n``` {.python .cell-code}\ndf = pd.read_csv('../data/week2/Admission_Predict.csv', index_col=0)\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=65}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Chance of Admit</th>\n    </tr>\n    <tr>\n      <th>Serial No.</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>0.65</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Renaming columns in a df\n\nNotice that we have two columns \"SOP\" and \"LOR\" and probably not everyone knows what they mean So let's change our column names to make it more clear. In Pandas, we can use the **rename() function**.\n\nIt takes a parameter called columns, and we need to pass into a dictionary which the keys are the old column name and the value is the corresponding new column name:\n\n::: {.cell execution_count=66}\n``` {.python .cell-code}\nnew_df=df.rename(columns={'GRE Score':'GRE Score', 'TOEFL Score':'TOEFL Score',\n                   'University Rating':'University Rating', \n                   'SOP': 'Statement of Purpose','LOR': 'Letter of Recommendation',\n                   'CGPA':'CGPA', 'Research':'Research',\n                   'Chance of Admit':'Chance of Admit'})\nnew_df.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=66}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>Statement of Purpose</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Chance of Admit</th>\n    </tr>\n    <tr>\n      <th>Serial No.</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>0.65</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nFrom the output, we can see that only \"SOP\" is changed but not \"LOR\" Why is that? Let's investigate this a bit. First we need to make sure we got all the column names correct. We can use the columns attribute of dataframe to get a list.\n\n::: {.cell execution_count=67}\n``` {.python .cell-code}\nnew_df.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=67}\n```\nIndex(['GRE Score', 'TOEFL Score', 'University Rating', 'Statement of Purpose',\n       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n      dtype='object')\n```\n:::\n:::\n\n\nIf we look at the output closely, we can see that there is actually a space right after \"LOR\" and a space right after \"Chance of Admit\". So this is why our rename dictionary does not work for LOR, because the key we used was just three characters, instead of four characters in \"LOR \"\n\nThere are a couple of ways we could address this. One way would be to change a column by including the space in the name:\n\n::: {.cell execution_count=68}\n``` {.python .cell-code}\nnew_df = new_df.rename(columns = {'LOR ': 'Letter of Recommendation'})\nnew_df.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=68}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>Statement of Purpose</th>\n      <th>Letter of Recommendation</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Chance of Admit</th>\n    </tr>\n    <tr>\n      <th>Serial No.</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>0.65</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nSo that works well, but it's a bit fragile. What if that was a tab instead of a space? Or two spaces?\n\nAnother way is to create some function that does the cleaning and then tell renamed to apply that function across all of the data. Python comes with a handy string function to strip white space called **strip()**. \n\nWhen we pass this in to rename we pass the function as the mapper parameter, and then indicate whether the axis should be columns or index (row labels)\n\n::: {.cell execution_count=69}\n``` {.python .cell-code}\nnew_df=new_df.rename(mapper=str.strip, axis='columns')\n\nnew_df.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=69}\n```\nIndex(['GRE Score', 'TOEFL Score', 'University Rating', 'Statement of Purpose',\n       'Letter of Recommendation', 'CGPA', 'Research', 'Chance of Admit'],\n      dtype='object')\n```\n:::\n:::\n\n\nNow we've got it - both SOP and LOR have been renamed and Chance of Admit has been trimmed up. Remember though that the rename function isn't modifying the dataframe. In this case, df is the same as it always was, there's just a copy in new_df with the changed names.\n\n::: {.cell execution_count=70}\n``` {.python .cell-code}\ndf.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=70}\n```\nIndex(['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA',\n       'Research', 'Chance of Admit '],\n      dtype='object')\n```\n:::\n:::\n\n\nWe can also use the df.columns attribute by assigning to it a list of column names which will directly rename the columns. This will directly modify the original dataframe and is very efficient especially when you have a lot of columns and you only want to change a few. This technique is also not affected by subtle errors in the column names, a problem that we just encountered. With a list, you can use the list index to change a certain value or use list comprehension to change all of the values\n\nAs an example, lets change all of the column names to lower case. First we need to get our list:\n\n::: {.cell execution_count=71}\n``` {.python .cell-code}\n#get a list of our column names\ncols = list(df.columns)\ncols\n```\n\n::: {.cell-output .cell-output-display execution_count=71}\n```\n['GRE Score',\n 'TOEFL Score',\n 'University Rating',\n 'SOP',\n 'LOR ',\n 'CGPA',\n 'Research',\n 'Chance of Admit ']\n```\n:::\n:::\n\n\n::: {.cell execution_count=72}\n``` {.python .cell-code}\n#do some cleanup via list comprehension\ncols = [x.lower().strip() for x in cols]\ncols\n```\n\n::: {.cell-output .cell-output-display execution_count=72}\n```\n['gre score',\n 'toefl score',\n 'university rating',\n 'sop',\n 'lor',\n 'cgpa',\n 'research',\n 'chance of admit']\n```\n:::\n:::\n\n\n::: {.cell execution_count=73}\n``` {.python .cell-code}\n#overwrite the columns in our df\ndf.columns = cols\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=73}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gre score</th>\n      <th>toefl score</th>\n      <th>university rating</th>\n      <th>sop</th>\n      <th>lor</th>\n      <th>cgpa</th>\n      <th>research</th>\n      <th>chance of admit</th>\n    </tr>\n    <tr>\n      <th>Serial No.</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>0.65</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Querying a dataframe\n\nIn this lecture we're going to talk about querying DataFrames. The first step in the process is to understand Boolean masking. Boolean masking is the heart of fast and efficient querying in numpy and pandas, and it's analogous to bit masking used in other areas of computational science.\n\n\n### Boolean masking\n\nA **Boolean mask** is an array which can be of one dimension like a series, or two dimensions like a data frame, where each of the values in the array are either true or false. This array is essentially overlaid on top of the data structure that we're querying. And any cell aligned with the true value will be admitted into our final result, and any cell aligned with a false value will not.\n\n::: {.cell execution_count=74}\n``` {.python .cell-code}\nimport pandas as pd\n\n#read in df\ndf = pd.read_csv('../data/week2/Admission_Predict.csv', index_col = 0)\n\n#do cleanup\ndf.columns = [x.lower().strip() for x in df.columns]\n\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=74}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gre score</th>\n      <th>toefl score</th>\n      <th>university rating</th>\n      <th>sop</th>\n      <th>lor</th>\n      <th>cgpa</th>\n      <th>research</th>\n      <th>chance of admit</th>\n    </tr>\n    <tr>\n      <th>Serial No.</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>0.65</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nBoolean masks are created by applying operators directly to the pandas Series or DataFrame objects. \n\nFor instance, in our graduate admission dataset, we might be interested in seeing only those students that have a chance higher than 0.7 at being admitted.\n\nTo build a Boolean mask for this query, we want to project the chance of admit column using the indexing operator and apply the greater than operator with a comparison value of 0.7. \n\nThis is essentially broadcasting a comparison operator, greater than, with the results being returned as  a Boolean Series. The resultant Series is indexed where the value of each cell is either True or False depending on whether a student has a chance of admit higher than 0.7.\n\n::: {.cell execution_count=75}\n``` {.python .cell-code}\nadmit_mask = df['chance of admit'] > 0.7\nadmit_mask\n```\n\n::: {.cell-output .cell-output-display execution_count=75}\n```\nSerial No.\n1       True\n2       True\n3       True\n4       True\n5      False\n       ...  \n396     True\n397     True\n398     True\n399    False\n400     True\nName: chance of admit, Length: 400, dtype: bool\n```\n:::\n:::\n\n\n**The result of broadcasting a comparison operator is a Boolean mask** - true or false values depending upon the results of the comparison. \n\nUnderneath, pandas is applying the comparison operator you specified through vectorization (so efficiently and in parallel) to all of the values in the array you specified which, in this case, is the chance of admit column of the dataframe. \n\nThe result is a series, since only one column is being operator on, filled with either True or False values, which is what the comparison operator returns.\n\nSo, what do you do with the boolean mask once you have formed it? Well, you can just lay it on top of the data to \"hide\" the data you don't want, which is represented by all of the False values. We do this by using the **.where()** function on the original DataFrame.\n\n::: {.cell execution_count=76}\n``` {.python .cell-code}\ndf.where(admit_mask).head()\n```\n\n::: {.cell-output .cell-output-display execution_count=76}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gre score</th>\n      <th>toefl score</th>\n      <th>university rating</th>\n      <th>sop</th>\n      <th>lor</th>\n      <th>cgpa</th>\n      <th>research</th>\n      <th>chance of admit</th>\n    </tr>\n    <tr>\n      <th>Serial No.</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>337.0</td>\n      <td>118.0</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1.0</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324.0</td>\n      <td>107.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1.0</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>316.0</td>\n      <td>104.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1.0</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322.0</td>\n      <td>110.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1.0</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe see that the resulting data frame keeps the original indexed values, and only data which met  the condition was retained. All of the rows which did not meet the condition have NaN data instead, but these rows were not dropped from our dataset. \n\nThe next step is, if we don't want the NaN data, we use the **dropna()** function:\n\n::: {.cell execution_count=77}\n``` {.python .cell-code}\ndf.where(admit_mask).dropna().head()\n```\n\n::: {.cell-output .cell-output-display execution_count=77}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gre score</th>\n      <th>toefl score</th>\n      <th>university rating</th>\n      <th>sop</th>\n      <th>lor</th>\n      <th>cgpa</th>\n      <th>research</th>\n      <th>chance of admit</th>\n    </tr>\n    <tr>\n      <th>Serial No.</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>337.0</td>\n      <td>118.0</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1.0</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324.0</td>\n      <td>107.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1.0</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>316.0</td>\n      <td>104.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1.0</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322.0</td>\n      <td>110.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1.0</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>330.0</td>\n      <td>115.0</td>\n      <td>5.0</td>\n      <td>4.5</td>\n      <td>3.0</td>\n      <td>9.34</td>\n      <td>1.0</td>\n      <td>0.90</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe returned DataFrame now has all of the NaN rows dropped. Notice the index now includes one through four and six, but not five.\n\nDespite being really handy, where() isn't actually used that often. Instead, the pandas devs created a shorthand syntax which combines where() and dropna(), doing both at once. And, in typical fashion, they just overloaded the indexing operator to do this.\n\n::: {.cell execution_count=78}\n``` {.python .cell-code}\ndf[df['chance of admit'] > 0.7].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=78}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gre score</th>\n      <th>toefl score</th>\n      <th>university rating</th>\n      <th>sop</th>\n      <th>lor</th>\n      <th>cgpa</th>\n      <th>research</th>\n      <th>chance of admit</th>\n    </tr>\n    <tr>\n      <th>Serial No.</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>330</td>\n      <td>115</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>3.0</td>\n      <td>9.34</td>\n      <td>1</td>\n      <td>0.90</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nJust reviewing this indexing operator on DataFrame, it now does three things. First, it can be called with a string parameter to project a single column:\n\n::: {.cell execution_count=79}\n``` {.python .cell-code}\ndf['gre score'].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=79}\n```\nSerial No.\n1    337\n2    324\n3    316\n4    322\n5    314\nName: gre score, dtype: int64\n```\n:::\n:::\n\n\nOr you can send it a list of columns as strings:\n\n::: {.cell execution_count=80}\n``` {.python .cell-code}\ndf[['gre score', 'toefl score']].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=80}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gre score</th>\n      <th>toefl score</th>\n    </tr>\n    <tr>\n      <th>Serial No.</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>337</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324</td>\n      <td>107</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>316</td>\n      <td>104</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322</td>\n      <td>110</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>314</td>\n      <td>103</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nOr you can send it a boolean mask:\n\n::: {.cell execution_count=81}\n``` {.python .cell-code}\ndf[df['gre score'] > 320].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=81}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gre score</th>\n      <th>toefl score</th>\n      <th>university rating</th>\n      <th>sop</th>\n      <th>lor</th>\n      <th>cgpa</th>\n      <th>research</th>\n      <th>chance of admit</th>\n    </tr>\n    <tr>\n      <th>Serial No.</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>330</td>\n      <td>115</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>3.0</td>\n      <td>9.34</td>\n      <td>1</td>\n      <td>0.90</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>321</td>\n      <td>109</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>8.20</td>\n      <td>1</td>\n      <td>0.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAnd each of these is mimicing functionality from either .loc() or .where().dropna().\n\nBefore we leave this, lets talk about combining multiple boolean masks, such as multiple criteria for including. In bitmasking in other places in computer science this is done with \"and\", if both masks must be True for a True value to be in the final mask), or \"or\" if only one needs to be True. Unfortunatly, it doesn't feel quite as natural in pandas. For instance, if you want to take two boolean series and and them together:\n\n::: {.cell execution_count=82}\n``` {.python .cell-code}\n#this gives an error\n#(df['chance of admit'] > 0.7) and (df['chance of admit'] < 0.9)\n```\n:::\n\n\nThe problem is that you have series objects, and python underneath doesn't know how to compare two series using and or or. Instead, the pandas authors have overwritten the pipe | and ampersand & operators to handle this for us:\n\n::: {.cell execution_count=83}\n``` {.python .cell-code}\ndf[(df['chance of admit'] > 0.7) & (df['chance of admit'] < 0.9)].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=83}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gre score</th>\n      <th>toefl score</th>\n      <th>university rating</th>\n      <th>sop</th>\n      <th>lor</th>\n      <th>cgpa</th>\n      <th>research</th>\n      <th>chance of admit</th>\n    </tr>\n    <tr>\n      <th>Serial No.</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>321</td>\n      <td>109</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>8.20</td>\n      <td>1</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>327</td>\n      <td>111</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>9.00</td>\n      <td>1</td>\n      <td>0.84</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nOne thing to watch out for is order of operations! A common error for new pandas users is to try and do boolean comparisons using the & operator but not putting parentheses around the individual terms you are interested in:\n\n```\ndf['chance of admit'] > 0.7 & df['chance of admit'] < 0.9\n```\n\nThe problem is that Python is trying to bitwise `and`, a 0.7 and a pandas dataframe, when you really want to bitwise and the broadcasted dataframes together.\n\nAnother way to do this is to just get rid of the comparison operator completely, and instead use the built in functions which mimic this approach:\n\n::: {.cell execution_count=84}\n``` {.python .cell-code}\ndf['chance of admit'].gt(0.7) & df['chance of admit'].lt(0.9)\n```\n\n::: {.cell-output .cell-output-display execution_count=84}\n```\nSerial No.\n1      False\n2       True\n3       True\n4       True\n5      False\n       ...  \n396     True\n397     True\n398    False\n399    False\n400    False\nName: chance of admit, Length: 400, dtype: bool\n```\n:::\n:::\n\n\nThese functions are build right into the Series and DataFrame objects, so you can chain them too, which results in the same answer and the use of no visual operators. You can decide what looks best for you.\n\n::: {.cell execution_count=85}\n``` {.python .cell-code}\ndf['chance of admit'].gt(0.7).lt(0.9)\n```\n\n::: {.cell-output .cell-output-display execution_count=85}\n```\nSerial No.\n1      False\n2      False\n3      False\n4      False\n5       True\n       ...  \n396    False\n397    False\n398    False\n399     True\n400    False\nName: chance of admit, Length: 400, dtype: bool\n```\n:::\n:::\n\n\nThis only works if your operator, such as less than or greater than, is built into the DataFrame, but I certainly find that last code example much more readable than one with ampersands and parenthesis.\n\n You need to be able to read and write all of these, and understand the implications of the route you are choosing. It's worth really going back and rewatching this lecture to make sure you have it. I would say 50% or more of the work you'll be doing in data cleaning involves querying DataFrames.\n\n\n## Indexing dataframes\n\nAs we've seen, both Series and DataFrames can have indices applied to them. The index is essentially a row level label, and in pandas the rows correspond to axis zero. \n\nIndices can either be either autogenerated, such as when we create a new Series without an index, in which case we get numeric values, or they can be set explicitly, like when we use the dictionary object to create the series, or when we loaded data from the CSV file and set appropriate parameters. \n\nAnother option for setting an index is to use the set_index() function. This function takes a list of columns and promotes those columns to an index. In this lecture we'll explore more about how indexes work in pandas.\n\n::: {.cell execution_count=86}\n``` {.python .cell-code}\nimport pandas as pd\n\ndf = pd.read_csv('../data/week2/Admission_Predict.csv', index_col = 0)\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=86}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Chance of Admit</th>\n    </tr>\n    <tr>\n      <th>Serial No.</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>0.65</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nLet's say that we don't want to index the DataFrame by serial numbers, but instead by the chance of admit. But lets assume we want to keep the serial number for later. So, lets preserve the serial number into a new column. We can do this using the indexing operator on the string that has the column label. Then we can use the set_index to set index of the column to chance of admit:\n\n::: {.cell execution_count=87}\n``` {.python .cell-code}\n#cp the indexed data into its own column\ndf['Serial Number'] = df.index\n\n#set the index to another column\ndf = df.set_index('Chance of Admit ')\n\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=87}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Serial Number</th>\n    </tr>\n    <tr>\n      <th>Chance of Admit</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.92</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0.76</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>0.72</th>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>0.80</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>0.65</th>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nYou'll see that when we create a new index from an existing column the index has a name, which is the original name of the column.\n\nWe can get rid of the index completely by calling the function **reset_index()**. This promotes the index into a column and creates a default numbered index.\n\n::: {.cell execution_count=88}\n``` {.python .cell-code}\ndf = df.reset_index()\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=88}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Chance of Admit</th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Serial Number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.92</td>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.76</td>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.72</td>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.80</td>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.65</td>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nOne nice feature of Pandas is **multi-level indexing**. This is similar to composite keys in relational database systems. To create a multi-level index, we simply call set index and give it a list of columns that we're interested in promoting to an index. Pandas will search through these in order, finding the distinct data and form composite indices.\n\nA good example of this is often found when dealing with geographical data which is sorted by regions or demographics.\n\nLet's change data sets and look at some census data for a better example. This data is stored in the file census.csv and comes from the United States Census Bureau. In particular, this is a breakdown of the population level data at the US county level. It's a great example of how different kinds of data sets might be formatted when you're trying to clean them.\n\n::: {.cell execution_count=89}\n``` {.python .cell-code}\ndf = pd.read_csv('../data/week2/census.csv')\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=89}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SUMLEV</th>\n      <th>REGION</th>\n      <th>DIVISION</th>\n      <th>STATE</th>\n      <th>COUNTY</th>\n      <th>STNAME</th>\n      <th>CTYNAME</th>\n      <th>CENSUS2010POP</th>\n      <th>ESTIMATESBASE2010</th>\n      <th>POPESTIMATE2010</th>\n      <th>...</th>\n      <th>RDOMESTICMIG2011</th>\n      <th>RDOMESTICMIG2012</th>\n      <th>RDOMESTICMIG2013</th>\n      <th>RDOMESTICMIG2014</th>\n      <th>RDOMESTICMIG2015</th>\n      <th>RNETMIG2011</th>\n      <th>RNETMIG2012</th>\n      <th>RNETMIG2013</th>\n      <th>RNETMIG2014</th>\n      <th>RNETMIG2015</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Alabama</td>\n      <td>Alabama</td>\n      <td>4779736</td>\n      <td>4780127</td>\n      <td>4785161</td>\n      <td>...</td>\n      <td>0.002295</td>\n      <td>-0.193196</td>\n      <td>0.381066</td>\n      <td>0.582002</td>\n      <td>-0.467369</td>\n      <td>1.030015</td>\n      <td>0.826644</td>\n      <td>1.383282</td>\n      <td>1.724718</td>\n      <td>0.712594</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Alabama</td>\n      <td>Autauga County</td>\n      <td>54571</td>\n      <td>54571</td>\n      <td>54660</td>\n      <td>...</td>\n      <td>7.242091</td>\n      <td>-2.915927</td>\n      <td>-3.012349</td>\n      <td>2.265971</td>\n      <td>-2.530799</td>\n      <td>7.606016</td>\n      <td>-2.626146</td>\n      <td>-2.722002</td>\n      <td>2.592270</td>\n      <td>-2.187333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Alabama</td>\n      <td>Baldwin County</td>\n      <td>182265</td>\n      <td>182265</td>\n      <td>183193</td>\n      <td>...</td>\n      <td>14.832960</td>\n      <td>17.647293</td>\n      <td>21.845705</td>\n      <td>19.243287</td>\n      <td>17.197872</td>\n      <td>15.844176</td>\n      <td>18.559627</td>\n      <td>22.727626</td>\n      <td>20.317142</td>\n      <td>18.293499</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>5</td>\n      <td>Alabama</td>\n      <td>Barbour County</td>\n      <td>27457</td>\n      <td>27457</td>\n      <td>27341</td>\n      <td>...</td>\n      <td>-4.728132</td>\n      <td>-2.500690</td>\n      <td>-7.056824</td>\n      <td>-3.904217</td>\n      <td>-10.543299</td>\n      <td>-4.874741</td>\n      <td>-2.758113</td>\n      <td>-7.167664</td>\n      <td>-3.978583</td>\n      <td>-10.543299</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>7</td>\n      <td>Alabama</td>\n      <td>Bibb County</td>\n      <td>22915</td>\n      <td>22919</td>\n      <td>22861</td>\n      <td>...</td>\n      <td>-5.527043</td>\n      <td>-5.068871</td>\n      <td>-6.201001</td>\n      <td>-0.177537</td>\n      <td>0.177258</td>\n      <td>-5.088389</td>\n      <td>-4.363636</td>\n      <td>-5.403729</td>\n      <td>0.754533</td>\n      <td>1.107861</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 100 columns</p>\n</div>\n```\n:::\n:::\n\n\nIn this data set there are two summarized levels (SUMLEV), one that contains summary data for the whole country. And one that contains summary data for each state. \n\nI want to see a list of all the unique values in a given column. In this DataFrame, we see that the possible values for the sum level are using the unique function on the DataFrame. This is similar to the SQL distinct operator.\n\nHere we can run **unique()** on the sum level of our current DataFrame :\n\n::: {.cell execution_count=90}\n``` {.python .cell-code}\ndf['SUMLEV'].unique()\n```\n\n::: {.cell-output .cell-output-display execution_count=90}\n```\narray([40, 50])\n```\n:::\n:::\n\n\nWe see that there are only two different values, 40 and 50.\n\nLet's exclude all of the rows that are summaries at the state level and just keep the county data.\n\n::: {.cell execution_count=91}\n``` {.python .cell-code}\ndf = df[df['SUMLEV'] ==  50]\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=91}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SUMLEV</th>\n      <th>REGION</th>\n      <th>DIVISION</th>\n      <th>STATE</th>\n      <th>COUNTY</th>\n      <th>STNAME</th>\n      <th>CTYNAME</th>\n      <th>CENSUS2010POP</th>\n      <th>ESTIMATESBASE2010</th>\n      <th>POPESTIMATE2010</th>\n      <th>...</th>\n      <th>RDOMESTICMIG2011</th>\n      <th>RDOMESTICMIG2012</th>\n      <th>RDOMESTICMIG2013</th>\n      <th>RDOMESTICMIG2014</th>\n      <th>RDOMESTICMIG2015</th>\n      <th>RNETMIG2011</th>\n      <th>RNETMIG2012</th>\n      <th>RNETMIG2013</th>\n      <th>RNETMIG2014</th>\n      <th>RNETMIG2015</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Alabama</td>\n      <td>Autauga County</td>\n      <td>54571</td>\n      <td>54571</td>\n      <td>54660</td>\n      <td>...</td>\n      <td>7.242091</td>\n      <td>-2.915927</td>\n      <td>-3.012349</td>\n      <td>2.265971</td>\n      <td>-2.530799</td>\n      <td>7.606016</td>\n      <td>-2.626146</td>\n      <td>-2.722002</td>\n      <td>2.592270</td>\n      <td>-2.187333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Alabama</td>\n      <td>Baldwin County</td>\n      <td>182265</td>\n      <td>182265</td>\n      <td>183193</td>\n      <td>...</td>\n      <td>14.832960</td>\n      <td>17.647293</td>\n      <td>21.845705</td>\n      <td>19.243287</td>\n      <td>17.197872</td>\n      <td>15.844176</td>\n      <td>18.559627</td>\n      <td>22.727626</td>\n      <td>20.317142</td>\n      <td>18.293499</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>5</td>\n      <td>Alabama</td>\n      <td>Barbour County</td>\n      <td>27457</td>\n      <td>27457</td>\n      <td>27341</td>\n      <td>...</td>\n      <td>-4.728132</td>\n      <td>-2.500690</td>\n      <td>-7.056824</td>\n      <td>-3.904217</td>\n      <td>-10.543299</td>\n      <td>-4.874741</td>\n      <td>-2.758113</td>\n      <td>-7.167664</td>\n      <td>-3.978583</td>\n      <td>-10.543299</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>7</td>\n      <td>Alabama</td>\n      <td>Bibb County</td>\n      <td>22915</td>\n      <td>22919</td>\n      <td>22861</td>\n      <td>...</td>\n      <td>-5.527043</td>\n      <td>-5.068871</td>\n      <td>-6.201001</td>\n      <td>-0.177537</td>\n      <td>0.177258</td>\n      <td>-5.088389</td>\n      <td>-4.363636</td>\n      <td>-5.403729</td>\n      <td>0.754533</td>\n      <td>1.107861</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>9</td>\n      <td>Alabama</td>\n      <td>Blount County</td>\n      <td>57322</td>\n      <td>57322</td>\n      <td>57373</td>\n      <td>...</td>\n      <td>1.807375</td>\n      <td>-1.177622</td>\n      <td>-1.748766</td>\n      <td>-2.062535</td>\n      <td>-1.369970</td>\n      <td>1.859511</td>\n      <td>-0.848580</td>\n      <td>-1.402476</td>\n      <td>-1.577232</td>\n      <td>-0.884411</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 100 columns</p>\n</div>\n```\n:::\n:::\n\n\nAlso while this data set is interesting for a number of different reasons, let's reduce the data that we're going to look at to just the total population estimates and the total number of births. We can do this by creating a list of column names that we want to keep then project those and assign the resulting DataFrame to our df variable.\n\n::: {.cell execution_count=92}\n``` {.python .cell-code}\ncolumns_to_keep = ['STNAME','CTYNAME','BIRTHS2010','BIRTHS2011','BIRTHS2012','BIRTHS2013',\n                   'BIRTHS2014','BIRTHS2015','POPESTIMATE2010','POPESTIMATE2011',\n                   'POPESTIMATE2012','POPESTIMATE2013','POPESTIMATE2014','POPESTIMATE2015']\ndf = df[columns_to_keep]\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=92}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STNAME</th>\n      <th>CTYNAME</th>\n      <th>BIRTHS2010</th>\n      <th>BIRTHS2011</th>\n      <th>BIRTHS2012</th>\n      <th>BIRTHS2013</th>\n      <th>BIRTHS2014</th>\n      <th>BIRTHS2015</th>\n      <th>POPESTIMATE2010</th>\n      <th>POPESTIMATE2011</th>\n      <th>POPESTIMATE2012</th>\n      <th>POPESTIMATE2013</th>\n      <th>POPESTIMATE2014</th>\n      <th>POPESTIMATE2015</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Alabama</td>\n      <td>Autauga County</td>\n      <td>151</td>\n      <td>636</td>\n      <td>615</td>\n      <td>574</td>\n      <td>623</td>\n      <td>600</td>\n      <td>54660</td>\n      <td>55253</td>\n      <td>55175</td>\n      <td>55038</td>\n      <td>55290</td>\n      <td>55347</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alabama</td>\n      <td>Baldwin County</td>\n      <td>517</td>\n      <td>2187</td>\n      <td>2092</td>\n      <td>2160</td>\n      <td>2186</td>\n      <td>2240</td>\n      <td>183193</td>\n      <td>186659</td>\n      <td>190396</td>\n      <td>195126</td>\n      <td>199713</td>\n      <td>203709</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alabama</td>\n      <td>Barbour County</td>\n      <td>70</td>\n      <td>335</td>\n      <td>300</td>\n      <td>283</td>\n      <td>260</td>\n      <td>269</td>\n      <td>27341</td>\n      <td>27226</td>\n      <td>27159</td>\n      <td>26973</td>\n      <td>26815</td>\n      <td>26489</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alabama</td>\n      <td>Bibb County</td>\n      <td>44</td>\n      <td>266</td>\n      <td>245</td>\n      <td>259</td>\n      <td>247</td>\n      <td>253</td>\n      <td>22861</td>\n      <td>22733</td>\n      <td>22642</td>\n      <td>22512</td>\n      <td>22549</td>\n      <td>22583</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Alabama</td>\n      <td>Blount County</td>\n      <td>183</td>\n      <td>744</td>\n      <td>710</td>\n      <td>646</td>\n      <td>618</td>\n      <td>603</td>\n      <td>57373</td>\n      <td>57711</td>\n      <td>57776</td>\n      <td>57734</td>\n      <td>57658</td>\n      <td>57673</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe US Census data breaks down population estimates by state and county. We can load the data and set the index to be a combination of the state and county values and see how pandas handles it in a DataFrame. \n\nWe do this by creating a list of the column identifiers we want to have indexed. And then calling set index with this list and assigning the output as appropriate. We see here that we have  a dual index, first the state name and second the county name.\n\n::: {.cell execution_count=93}\n``` {.python .cell-code}\ndf = df.set_index(['STNAME', 'CTYNAME'])\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=93}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>BIRTHS2010</th>\n      <th>BIRTHS2011</th>\n      <th>BIRTHS2012</th>\n      <th>BIRTHS2013</th>\n      <th>BIRTHS2014</th>\n      <th>BIRTHS2015</th>\n      <th>POPESTIMATE2010</th>\n      <th>POPESTIMATE2011</th>\n      <th>POPESTIMATE2012</th>\n      <th>POPESTIMATE2013</th>\n      <th>POPESTIMATE2014</th>\n      <th>POPESTIMATE2015</th>\n    </tr>\n    <tr>\n      <th>STNAME</th>\n      <th>CTYNAME</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Alabama</th>\n      <th>Autauga County</th>\n      <td>151</td>\n      <td>636</td>\n      <td>615</td>\n      <td>574</td>\n      <td>623</td>\n      <td>600</td>\n      <td>54660</td>\n      <td>55253</td>\n      <td>55175</td>\n      <td>55038</td>\n      <td>55290</td>\n      <td>55347</td>\n    </tr>\n    <tr>\n      <th>Baldwin County</th>\n      <td>517</td>\n      <td>2187</td>\n      <td>2092</td>\n      <td>2160</td>\n      <td>2186</td>\n      <td>2240</td>\n      <td>183193</td>\n      <td>186659</td>\n      <td>190396</td>\n      <td>195126</td>\n      <td>199713</td>\n      <td>203709</td>\n    </tr>\n    <tr>\n      <th>Barbour County</th>\n      <td>70</td>\n      <td>335</td>\n      <td>300</td>\n      <td>283</td>\n      <td>260</td>\n      <td>269</td>\n      <td>27341</td>\n      <td>27226</td>\n      <td>27159</td>\n      <td>26973</td>\n      <td>26815</td>\n      <td>26489</td>\n    </tr>\n    <tr>\n      <th>Bibb County</th>\n      <td>44</td>\n      <td>266</td>\n      <td>245</td>\n      <td>259</td>\n      <td>247</td>\n      <td>253</td>\n      <td>22861</td>\n      <td>22733</td>\n      <td>22642</td>\n      <td>22512</td>\n      <td>22549</td>\n      <td>22583</td>\n    </tr>\n    <tr>\n      <th>Blount County</th>\n      <td>183</td>\n      <td>744</td>\n      <td>710</td>\n      <td>646</td>\n      <td>618</td>\n      <td>603</td>\n      <td>57373</td>\n      <td>57711</td>\n      <td>57776</td>\n      <td>57734</td>\n      <td>57658</td>\n      <td>57673</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAn immediate question which comes up is how we can query this DataFrame. We saw previously that the loc attribute of the DataFrame can take multiple arguments. And it could query both the row and the columns. \n\nWhen you use a MultiIndex, you must provide the arguments in order by the level you wish to query. Inside of the index, each column is called a level and the outermost column is level zero. \n\nIf we want to see the population results from Washtenaw County in Michigan the state, which is where I live, the first argument would be Michigan and the second would be Washtenaw County:\n\n::: {.cell execution_count=94}\n``` {.python .cell-code}\ndf.loc['Michigan', 'Washtenaw County']\n```\n\n::: {.cell-output .cell-output-display execution_count=94}\n```\nBIRTHS2010            977\nBIRTHS2011           3826\nBIRTHS2012           3780\nBIRTHS2013           3662\nBIRTHS2014           3683\nBIRTHS2015           3709\nPOPESTIMATE2010    345563\nPOPESTIMATE2011    349048\nPOPESTIMATE2012    351213\nPOPESTIMATE2013    354289\nPOPESTIMATE2014    357029\nPOPESTIMATE2015    358880\nName: (Michigan, Washtenaw County), dtype: int64\n```\n:::\n:::\n\n\nIf you are interested in comparing two counties, for example, Washtenaw and Wayne County, we can pass a list of tuples describing the indices we wish to query into loc. Since we have a MultiIndex of two values, the state and the county, we need to provide two values as each element of our filtering list. Each tuple should have two elements, the first element being the first index and the second element being the second index.\n\nTherefore, in this case, we will have a list of two tuples, in each tuple, the first element is Michigan, and the second element is either Washtenaw County or Wayne County\n\n::: {.cell execution_count=95}\n``` {.python .cell-code}\ndf.loc[[('Michigan', 'Washtenaw County'),\n        ('Michigan', 'Wayne County')]]\n```\n\n::: {.cell-output .cell-output-display execution_count=95}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>BIRTHS2010</th>\n      <th>BIRTHS2011</th>\n      <th>BIRTHS2012</th>\n      <th>BIRTHS2013</th>\n      <th>BIRTHS2014</th>\n      <th>BIRTHS2015</th>\n      <th>POPESTIMATE2010</th>\n      <th>POPESTIMATE2011</th>\n      <th>POPESTIMATE2012</th>\n      <th>POPESTIMATE2013</th>\n      <th>POPESTIMATE2014</th>\n      <th>POPESTIMATE2015</th>\n    </tr>\n    <tr>\n      <th>STNAME</th>\n      <th>CTYNAME</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Michigan</th>\n      <th>Washtenaw County</th>\n      <td>977</td>\n      <td>3826</td>\n      <td>3780</td>\n      <td>3662</td>\n      <td>3683</td>\n      <td>3709</td>\n      <td>345563</td>\n      <td>349048</td>\n      <td>351213</td>\n      <td>354289</td>\n      <td>357029</td>\n      <td>358880</td>\n    </tr>\n    <tr>\n      <th>Wayne County</th>\n      <td>5918</td>\n      <td>23819</td>\n      <td>23270</td>\n      <td>23377</td>\n      <td>23607</td>\n      <td>23586</td>\n      <td>1815199</td>\n      <td>1801273</td>\n      <td>1792514</td>\n      <td>1775713</td>\n      <td>1766008</td>\n      <td>1759335</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Missing values\n\nWe've seen a preview of how Pandas handles missing values using the None type and NumPy NaN values. Missing values are pretty common in data cleaning activities. And, missing values can be there for any number of reasons, and I just want to touch on a few here.\n\nFor instance, if you are running a survey and a respondant didn't answer a question the missing value is actually an omission. This kind of missing data is called **Missing at Random** if there are other variables that might be used to predict the variable which is missing. In my work when I delivery surveys I often find that missing data, say the interest in being involved in a follow up study, often has some correlation with another data field, like gender or ethnicity. If there is no relationship to other variables, then we call this data **Missing Completely at Random (MCAR)**.\n\nThese are just two examples of missing data, and there are many more. For instance, data might be missing because it wasn't collected, either by the process responsible for collecting that data, such as a researcher, or because it wouldn't make sense if it were collected. This last example is extremely common when you start joining DataFrames together from multiple sources, such as joining a list of people at a university with a list of offices in the university (students generally don't have offices).\n\nLet's look at some ways of handling missing data in pandas.\n\nPandas is pretty good at detecting missing values directly from underlying data formats, like CSV files. Although most missing valuse are often formatted as NaN, NULL, None, or N/A, sometimes missing values are not labeled so clearly. \n\nFor example, I've worked with social scientists who regularly used the value of 99 in binary categories to indicate a missing value. The pandas `read_csv()` function has a parameter called **na_values** to let us specify the form of missing values. It allows scalar, string, list, or dictionaries to be used.\n\n::: {.cell execution_count=96}\n``` {.python .cell-code}\ndf = pd.read_csv('../data/week2/class_grades.csv')\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=96}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Prefix</th>\n      <th>Assignment</th>\n      <th>Tutorial</th>\n      <th>Midterm</th>\n      <th>TakeHome</th>\n      <th>Final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>57.14</td>\n      <td>34.09</td>\n      <td>64.38</td>\n      <td>51.48</td>\n      <td>52.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>95.05</td>\n      <td>105.49</td>\n      <td>67.50</td>\n      <td>99.07</td>\n      <td>68.33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>83.70</td>\n      <td>83.17</td>\n      <td>NaN</td>\n      <td>63.15</td>\n      <td>48.89</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>49.38</td>\n      <td>105.93</td>\n      <td>80.56</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>91.32</td>\n      <td>93.64</td>\n      <td>95.00</td>\n      <td>107.41</td>\n      <td>73.89</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe can actually use the function **.isnull()** to create a boolean mask of the whole dataframe. This effectively broadcasts the isnull() function to every cell of data.\n\n::: {.cell execution_count=97}\n``` {.python .cell-code}\nmask = df.isnull()\nmask.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=97}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Prefix</th>\n      <th>Assignment</th>\n      <th>Tutorial</th>\n      <th>Midterm</th>\n      <th>TakeHome</th>\n      <th>Final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThis can be useful for processing rows based on certain columns of data. Another useful operation is to be able to drop all of those rows which have any missing data, which can be done with the **dropna()** function.\n\n::: {.cell execution_count=98}\n``` {.python .cell-code}\ndf.dropna().head()\n```\n\n::: {.cell-output .cell-output-display execution_count=98}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Prefix</th>\n      <th>Assignment</th>\n      <th>Tutorial</th>\n      <th>Midterm</th>\n      <th>TakeHome</th>\n      <th>Final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>57.14</td>\n      <td>34.09</td>\n      <td>64.38</td>\n      <td>51.48</td>\n      <td>52.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>95.05</td>\n      <td>105.49</td>\n      <td>67.50</td>\n      <td>99.07</td>\n      <td>68.33</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>91.32</td>\n      <td>93.64</td>\n      <td>95.00</td>\n      <td>107.41</td>\n      <td>73.89</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7</td>\n      <td>95.00</td>\n      <td>92.58</td>\n      <td>93.12</td>\n      <td>97.78</td>\n      <td>68.06</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>8</td>\n      <td>95.05</td>\n      <td>102.99</td>\n      <td>56.25</td>\n      <td>99.07</td>\n      <td>50.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNote how the rows indexed with 2, 3, 7, and 11 are now gone. \n\nOne of the handy functions that Pandas has for working with missing values is the filling function, **fillna()**. This function takes a number or parameters. You could pass in a single value which is called a scalar value to change all of the missing data to one value. This isn't really applicable in this case, but it's a pretty common use case. So, if we wanted to fill all missing values with 0, we would use fillna.\n\n::: {.cell execution_count=99}\n``` {.python .cell-code}\ndf.fillna(0, inplace = True)\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=99}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Prefix</th>\n      <th>Assignment</th>\n      <th>Tutorial</th>\n      <th>Midterm</th>\n      <th>TakeHome</th>\n      <th>Final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>57.14</td>\n      <td>34.09</td>\n      <td>64.38</td>\n      <td>51.48</td>\n      <td>52.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>95.05</td>\n      <td>105.49</td>\n      <td>67.50</td>\n      <td>99.07</td>\n      <td>68.33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>83.70</td>\n      <td>83.17</td>\n      <td>0.00</td>\n      <td>63.15</td>\n      <td>48.89</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>49.38</td>\n      <td>105.93</td>\n      <td>80.56</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>91.32</td>\n      <td>93.64</td>\n      <td>95.00</td>\n      <td>107.41</td>\n      <td>73.89</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNote that the inplace attribute causes pandas to fill the values inline and does not return a copy of the dataframe, but instead modifies the dataframe you have.\n\nWe can also use the **na_filter** option to turn off white space filtering, if white space is an actual value of interest. But in practice, this is pretty rare. In data without any NAs, passing na_filter=False, can improve the performance of reading a large file.\n\nIn addition to rules controlling how missing values might be loaded, it's sometimes useful to consider missing values as actually having information. I'll give an example from my own research.  I often deal with logs from online learning systems. I've looked at video use in lecture capture systems. In these systems it's common for the player for have a heartbeat functionality where playback statistics are sent to the server every so often, maybe every 30 seconds. These heartbeats can get big as they can carry the whole state of the playback system such as where the video play head is at, where the video size is, which video is being rendered to the screen, how loud the volume is.\n\nIf we load the data file log.csv, we can see an example of what this might look like.\n\n::: {.cell execution_count=100}\n``` {.python .cell-code}\ndf = pd.read_csv('../data/week2/log.csv')\ndf.head(n=10)\n```\n\n::: {.cell-output .cell-output-display execution_count=100}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>user</th>\n      <th>video</th>\n      <th>playback position</th>\n      <th>paused</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1469974424</td>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>5</td>\n      <td>False</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1469974454</td>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1469974544</td>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1469974574</td>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1469977514</td>\n      <td>bob</td>\n      <td>intro.html</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1469977544</td>\n      <td>bob</td>\n      <td>intro.html</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1469977574</td>\n      <td>bob</td>\n      <td>intro.html</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1469977604</td>\n      <td>bob</td>\n      <td>intro.html</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1469974604</td>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1469974694</td>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nIn this data the first column is a timestamp in the **Unix epoch format**. The next column is the user name followed by a web page they're visiting and the video that they're playing. Each row of the DataFrame has a playback position. And we can see that as the playback position increases by one, the time stamp increases by about 30 seconds.\n\nExcept for user Bob. It turns out that Bob has paused his playback so as time increases the playbackposition doesn't change. Note too how difficult it is for us to try and derive this knowledge from the data, because it's not sorted by time stamp as one might expect. This is actually not uncommon on systems which have a high degree of parallelism. There are a lot of missing values in the paused and volume columns. It's not efficient to send this information across the network if it hasn't changed. So this articular system just inserts null values into the database if there's no changes.\n\nNext up is the method **parameter()**. The two common fill values are ffill and bfill. **ffill** is for forward filling and it updates an na value for a particular cell with the value from the previous row. \n\n**bfill** is backward filling, which is the opposite of ffill. It fills the missing values with the next valid value.\n\nIt's important to note that your data needs to be sorted in order for this to have the effect you might want. Data which comes from traditional database management systems usually has no order guarantee, justlike this data. So be careful.\n\nIn Pandas we can sort either by index or by values. Here we'll just promote the time stamp to an index then sort on the index.\n\n::: {.cell execution_count=101}\n``` {.python .cell-code}\ndf = df.set_index('time')\ndf = df.sort_index()\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=101}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>video</th>\n      <th>playback position</th>\n      <th>paused</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1469974424</th>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>5</td>\n      <td>False</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1469974424</th>\n      <td>sue</td>\n      <td>advanced.html</td>\n      <td>23</td>\n      <td>False</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1469974454</th>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1469974454</th>\n      <td>sue</td>\n      <td>advanced.html</td>\n      <td>24</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1469974484</th>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nIf we look closely at the output though we'll notice that the index isn't really unique. \n\nTwo users seem to be able to use the system at the same  time. Again, a very common case. Let's reset the index, and use some  multi-level indexing on time AND user together instead,promote the user name to a second level of the index to deal with that issue.\n\n::: {.cell execution_count=102}\n``` {.python .cell-code}\ndf = df.reset_index()\ndf = df.set_index(['time', 'user'])\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=102}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>video</th>\n      <th>playback position</th>\n      <th>paused</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th>user</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1469974424</th>\n      <th>cheryl</th>\n      <td>intro.html</td>\n      <td>5</td>\n      <td>False</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>sue</th>\n      <td>advanced.html</td>\n      <td>23</td>\n      <td>False</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1469974454</th>\n      <th>cheryl</th>\n      <td>intro.html</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>sue</th>\n      <td>advanced.html</td>\n      <td>24</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1469974484</th>\n      <th>cheryl</th>\n      <td>intro.html</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNow that we have the data indexed and sorted appropriately, we can fill the missing datas using ffill. It's good to remember when dealing with missing values so you can deal with individual columns or sets of columns by projecting them. So you don't have to fix all missing values in one command.\n\n::: {.cell execution_count=103}\n``` {.python .cell-code}\ndf = df.fillna(method = 'ffill')\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=103}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>video</th>\n      <th>playback position</th>\n      <th>paused</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th>user</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1469974424</th>\n      <th>cheryl</th>\n      <td>intro.html</td>\n      <td>5</td>\n      <td>False</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>sue</th>\n      <td>advanced.html</td>\n      <td>23</td>\n      <td>False</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1469974454</th>\n      <th>cheryl</th>\n      <td>intro.html</td>\n      <td>6</td>\n      <td>False</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>sue</th>\n      <td>advanced.html</td>\n      <td>24</td>\n      <td>False</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1469974484</th>\n      <th>cheryl</th>\n      <td>intro.html</td>\n      <td>7</td>\n      <td>False</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe can also do customized fill-in to replace values with the **replace()** function. It allows replacement from several approaches: value-to-value, list, dictionary, regex Let's generate a simple example:\n\n::: {.cell execution_count=104}\n``` {.python .cell-code}\ndf = pd.DataFrame({'A': [1, 1, 2, 3, 4],\n                   'B': [3, 6, 3, 8, 9],\n                   'C': ['a', 'b', 'c', 'd', 'e']})\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=104}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>6</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>8</td>\n      <td>d</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>e</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe can replace 1's with 100, let's try the value-to-value approach:\n\n::: {.cell execution_count=105}\n``` {.python .cell-code}\ndf.replace(1,100)\n```\n\n::: {.cell-output .cell-output-display execution_count=105}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>3</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>6</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>8</td>\n      <td>d</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>e</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nHow about changing two values? Let's try the list approach For example, we want to change 1's to 100 and 3's to 300:\n\n::: {.cell execution_count=106}\n``` {.python .cell-code}\ndf.replace([1,3], [100,300])\n```\n\n::: {.cell-output .cell-output-display execution_count=106}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>300</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>6</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>300</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>300</td>\n      <td>8</td>\n      <td>d</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>e</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWhat's really cool about pandas replacement is that it supports regex too! Let's look at our data from the dataset logs again:\n\n::: {.cell execution_count=107}\n``` {.python .cell-code}\ndf = pd.read_csv('../data/week2/log.csv')\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=107}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>user</th>\n      <th>video</th>\n      <th>playback position</th>\n      <th>paused</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1469974424</td>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>5</td>\n      <td>False</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1469974454</td>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1469974544</td>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1469974574</td>\n      <td>cheryl</td>\n      <td>intro.html</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1469977514</td>\n      <td>bob</td>\n      <td>intro.html</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nTo replace using a regex we make the first parameter to replace the regex pattern we want to match, the second parameter the value we want to emit upon match, and then we pass in a third parameter \"regex=True\".\n\nTake a moment to pause this video and think about this problem: imagine we want to detect all html pages in the \"video\" column, lets say that just means they end with \".html\", and we want to overwrite that with the keyword \"webpage\". How could we accomplish this?\n\n::: {.cell execution_count=108}\n``` {.python .cell-code}\ndf.replace(to_replace='.*.html$', value='webpage', regex = True).head()\n```\n\n::: {.cell-output .cell-output-display execution_count=108}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>user</th>\n      <th>video</th>\n      <th>playback position</th>\n      <th>paused</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1469974424</td>\n      <td>cheryl</td>\n      <td>webpage</td>\n      <td>5</td>\n      <td>False</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1469974454</td>\n      <td>cheryl</td>\n      <td>webpage</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1469974544</td>\n      <td>cheryl</td>\n      <td>webpage</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1469974574</td>\n      <td>cheryl</td>\n      <td>webpage</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1469977514</td>\n      <td>bob</td>\n      <td>webpage</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Example: Manipulating a dataframe\n\nIn this lecture I'm going to walk through a basic data cleaning process with you and introduce you to a few more pandas API functions.\n\n::: {.cell execution_count=109}\n``` {.python .cell-code}\nimport pandas as pd\n\ndf = pd.read_csv('../data/week2/presidents.csv')\n\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=109}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>President</th>\n      <th>Born</th>\n      <th>Age atstart of presidency</th>\n      <th>Age atend of presidency</th>\n      <th>Post-presidencytimespan</th>\n      <th>Died</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>George Washington</td>\n      <td>Feb 22, 1732[a]</td>\n      <td>57 years, 67 daysApr 30, 1789</td>\n      <td>65 years, 10 daysMar 4, 1797</td>\n      <td>2 years, 285 days</td>\n      <td>Dec 14, 1799</td>\n      <td>67 years, 295 days</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>John Adams</td>\n      <td>Oct 30, 1735[a]</td>\n      <td>61 years, 125 daysMar 4, 1797</td>\n      <td>65 years, 125 daysMar 4, 1801</td>\n      <td>25 years, 122 days</td>\n      <td>Jul 4, 1826</td>\n      <td>90 years, 247 days</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Thomas Jefferson</td>\n      <td>Apr 13, 1743[a]</td>\n      <td>57 years, 325 daysMar 4, 1801</td>\n      <td>65 years, 325 daysMar 4, 1809</td>\n      <td>17 years, 122 days</td>\n      <td>Jul 4, 1826</td>\n      <td>83 years, 82 days</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>James Madison</td>\n      <td>Mar 16, 1751[a]</td>\n      <td>57 years, 353 daysMar 4, 1809</td>\n      <td>65 years, 353 daysMar 4, 1817</td>\n      <td>19 years, 116 days</td>\n      <td>Jun 28, 1836</td>\n      <td>85 years, 104 days</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>James Monroe</td>\n      <td>Apr 28, 1758</td>\n      <td>58 years, 310 daysMar 4, 1817</td>\n      <td>66 years, 310 daysMar 4, 1825</td>\n      <td>6 years, 122 days</td>\n      <td>Jul 4, 1831</td>\n      <td>73 years, 67 days</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nOk, we have some presidents, some dates, I see a bunch of footnotes in the \"Born\" column which might cause issues. Let's start with cleaning up that name into firstname and lastname. \n\nI'm going to tackle this with a regex. So I want to create two new columns and apply a regex to the projection of the \"President\" column.\n\nHere's one solution, we could make a copy of the President column:\n\n::: {.cell execution_count=110}\n``` {.python .cell-code}\ndf['First'] = df['President']\n\n#use replace to extract the first name\ndf['First'] = df['First'].replace('[ ].*', '', regex = True)\n\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=110}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>President</th>\n      <th>Born</th>\n      <th>Age atstart of presidency</th>\n      <th>Age atend of presidency</th>\n      <th>Post-presidencytimespan</th>\n      <th>Died</th>\n      <th>Age</th>\n      <th>First</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>George Washington</td>\n      <td>Feb 22, 1732[a]</td>\n      <td>57 years, 67 daysApr 30, 1789</td>\n      <td>65 years, 10 daysMar 4, 1797</td>\n      <td>2 years, 285 days</td>\n      <td>Dec 14, 1799</td>\n      <td>67 years, 295 days</td>\n      <td>George</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>John Adams</td>\n      <td>Oct 30, 1735[a]</td>\n      <td>61 years, 125 daysMar 4, 1797</td>\n      <td>65 years, 125 daysMar 4, 1801</td>\n      <td>25 years, 122 days</td>\n      <td>Jul 4, 1826</td>\n      <td>90 years, 247 days</td>\n      <td>John</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Thomas Jefferson</td>\n      <td>Apr 13, 1743[a]</td>\n      <td>57 years, 325 daysMar 4, 1801</td>\n      <td>65 years, 325 daysMar 4, 1809</td>\n      <td>17 years, 122 days</td>\n      <td>Jul 4, 1826</td>\n      <td>83 years, 82 days</td>\n      <td>Thomas</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>James Madison</td>\n      <td>Mar 16, 1751[a]</td>\n      <td>57 years, 353 daysMar 4, 1809</td>\n      <td>65 years, 353 daysMar 4, 1817</td>\n      <td>19 years, 116 days</td>\n      <td>Jun 28, 1836</td>\n      <td>85 years, 104 days</td>\n      <td>James</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>James Monroe</td>\n      <td>Apr 28, 1758</td>\n      <td>58 years, 310 daysMar 4, 1817</td>\n      <td>66 years, 310 daysMar 4, 1825</td>\n      <td>6 years, 122 days</td>\n      <td>Jul 4, 1831</td>\n      <td>73 years, 67 days</td>\n      <td>James</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThat works, but it's kind of gross. And it's slow, since we had to make a full copy of a column then go through and update strings. There are a few other ways we can deal with this. Let me show you the most general one first, and that's called the **apply()** function. Let's drop the column we made first:\n\n::: {.cell execution_count=111}\n``` {.python .cell-code}\ndel(df['First'])\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=111}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>President</th>\n      <th>Born</th>\n      <th>Age atstart of presidency</th>\n      <th>Age atend of presidency</th>\n      <th>Post-presidencytimespan</th>\n      <th>Died</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>George Washington</td>\n      <td>Feb 22, 1732[a]</td>\n      <td>57 years, 67 daysApr 30, 1789</td>\n      <td>65 years, 10 daysMar 4, 1797</td>\n      <td>2 years, 285 days</td>\n      <td>Dec 14, 1799</td>\n      <td>67 years, 295 days</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>John Adams</td>\n      <td>Oct 30, 1735[a]</td>\n      <td>61 years, 125 daysMar 4, 1797</td>\n      <td>65 years, 125 daysMar 4, 1801</td>\n      <td>25 years, 122 days</td>\n      <td>Jul 4, 1826</td>\n      <td>90 years, 247 days</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Thomas Jefferson</td>\n      <td>Apr 13, 1743[a]</td>\n      <td>57 years, 325 daysMar 4, 1801</td>\n      <td>65 years, 325 daysMar 4, 1809</td>\n      <td>17 years, 122 days</td>\n      <td>Jul 4, 1826</td>\n      <td>83 years, 82 days</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>James Madison</td>\n      <td>Mar 16, 1751[a]</td>\n      <td>57 years, 353 daysMar 4, 1809</td>\n      <td>65 years, 353 daysMar 4, 1817</td>\n      <td>19 years, 116 days</td>\n      <td>Jun 28, 1836</td>\n      <td>85 years, 104 days</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>James Monroe</td>\n      <td>Apr 28, 1758</td>\n      <td>58 years, 310 daysMar 4, 1817</td>\n      <td>66 years, 310 daysMar 4, 1825</td>\n      <td>6 years, 122 days</td>\n      <td>Jul 4, 1831</td>\n      <td>73 years, 67 days</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe apply() function on a dataframe will take some arbitrary function you have written and apply it to either a Series (a single column) or DataFrame across all rows or columns. Lets write a function which just splits a string into two pieces using a single row of data:\n\n::: {.cell execution_count=112}\n``` {.python .cell-code}\ndef splitname(row):\n    # The row is a single Series object which is a single row indexed by column values\n    # Let's extract the firstname and create a new entry in the series\n    row['First'] = row['President'].split(' ')[0]\n    row['Last'] = row['President'].split(' ')[-1]\n    # Now we just return the row and the pandas .apply() will take of merging them back into a DataFrame\n    return row\n\n# Now if we apply this to the dataframe indicating we want to apply it across columns\ndf = df.apply(splitname, axis = 'columns')\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=112}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>President</th>\n      <th>Born</th>\n      <th>Age atstart of presidency</th>\n      <th>Age atend of presidency</th>\n      <th>Post-presidencytimespan</th>\n      <th>Died</th>\n      <th>Age</th>\n      <th>First</th>\n      <th>Last</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>George Washington</td>\n      <td>Feb 22, 1732[a]</td>\n      <td>57 years, 67 daysApr 30, 1789</td>\n      <td>65 years, 10 daysMar 4, 1797</td>\n      <td>2 years, 285 days</td>\n      <td>Dec 14, 1799</td>\n      <td>67 years, 295 days</td>\n      <td>George</td>\n      <td>Washington</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>John Adams</td>\n      <td>Oct 30, 1735[a]</td>\n      <td>61 years, 125 daysMar 4, 1797</td>\n      <td>65 years, 125 daysMar 4, 1801</td>\n      <td>25 years, 122 days</td>\n      <td>Jul 4, 1826</td>\n      <td>90 years, 247 days</td>\n      <td>John</td>\n      <td>Adams</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Thomas Jefferson</td>\n      <td>Apr 13, 1743[a]</td>\n      <td>57 years, 325 daysMar 4, 1801</td>\n      <td>65 years, 325 daysMar 4, 1809</td>\n      <td>17 years, 122 days</td>\n      <td>Jul 4, 1826</td>\n      <td>83 years, 82 days</td>\n      <td>Thomas</td>\n      <td>Jefferson</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>James Madison</td>\n      <td>Mar 16, 1751[a]</td>\n      <td>57 years, 353 daysMar 4, 1809</td>\n      <td>65 years, 353 daysMar 4, 1817</td>\n      <td>19 years, 116 days</td>\n      <td>Jun 28, 1836</td>\n      <td>85 years, 104 days</td>\n      <td>James</td>\n      <td>Madison</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>James Monroe</td>\n      <td>Apr 28, 1758</td>\n      <td>58 years, 310 daysMar 4, 1817</td>\n      <td>66 years, 310 daysMar 4, 1825</td>\n      <td>6 years, 122 days</td>\n      <td>Jul 4, 1831</td>\n      <td>73 years, 67 days</td>\n      <td>James</td>\n      <td>Monroe</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nPretty questionable as to whether that is less gross, but it achieves the result and I find that I use the apply() function regularly in my work. The pandas series has a couple of other nice convenience functions though, and the next I would like to touch on is called **.extract()**. Lets drop our firstname and lastname.\n\n::: {.cell execution_count=113}\n``` {.python .cell-code}\ndel(df['First'])\ndel(df['Last'])\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=113}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>President</th>\n      <th>Born</th>\n      <th>Age atstart of presidency</th>\n      <th>Age atend of presidency</th>\n      <th>Post-presidencytimespan</th>\n      <th>Died</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>George Washington</td>\n      <td>Feb 22, 1732[a]</td>\n      <td>57 years, 67 daysApr 30, 1789</td>\n      <td>65 years, 10 daysMar 4, 1797</td>\n      <td>2 years, 285 days</td>\n      <td>Dec 14, 1799</td>\n      <td>67 years, 295 days</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>John Adams</td>\n      <td>Oct 30, 1735[a]</td>\n      <td>61 years, 125 daysMar 4, 1797</td>\n      <td>65 years, 125 daysMar 4, 1801</td>\n      <td>25 years, 122 days</td>\n      <td>Jul 4, 1826</td>\n      <td>90 years, 247 days</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Thomas Jefferson</td>\n      <td>Apr 13, 1743[a]</td>\n      <td>57 years, 325 daysMar 4, 1801</td>\n      <td>65 years, 325 daysMar 4, 1809</td>\n      <td>17 years, 122 days</td>\n      <td>Jul 4, 1826</td>\n      <td>83 years, 82 days</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>James Madison</td>\n      <td>Mar 16, 1751[a]</td>\n      <td>57 years, 353 daysMar 4, 1809</td>\n      <td>65 years, 353 daysMar 4, 1817</td>\n      <td>19 years, 116 days</td>\n      <td>Jun 28, 1836</td>\n      <td>85 years, 104 days</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>James Monroe</td>\n      <td>Apr 28, 1758</td>\n      <td>58 years, 310 daysMar 4, 1817</td>\n      <td>66 years, 310 daysMar 4, 1825</td>\n      <td>6 years, 122 days</td>\n      <td>Jul 4, 1831</td>\n      <td>73 years, 67 days</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nExtract takes a regular expression as input and specifically requires you to set capture groups that correspond to the output columns you are interested in. Let's write a regular expression that returned groups and just had the firstname and lastname in it, what would that look like?\n\nHere we match three groups but only return two, the first and the last name. Remember, parenthesis mark groups we want to have returned and `?:` marks a group we do not want to be returned\n\n::: {.cell execution_count=114}\n``` {.python .cell-code}\npattern = '(^[\\w]*)(?:.* )([\\w]*$)'\n```\n:::\n\n\nNow the extract function is built into the str attribute of the Series object, so we can call it using **Series.str.extract(pattern)**:\n\n::: {.cell execution_count=115}\n``` {.python .cell-code}\ndf['President'].str.extract(pattern).head()\n```\n\n::: {.cell-output .cell-output-display execution_count=115}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>George</td>\n      <td>Washington</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>John</td>\n      <td>Adams</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Thomas</td>\n      <td>Jefferson</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>James</td>\n      <td>Madison</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>James</td>\n      <td>Monroe</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nSo that looks pretty nice, other than the column names. But if we name the groups we get named columns out:\n\n::: {.cell execution_count=116}\n``` {.python .cell-code}\npattern = '(?P<First>^[\\w]*)(?:.* )(?P<Last>[\\w]*$)'\n\nnames = df['President'].str.extract(pattern)\nnames.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=116}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>First</th>\n      <th>Last</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>George</td>\n      <td>Washington</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>John</td>\n      <td>Adams</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Thomas</td>\n      <td>Jefferson</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>James</td>\n      <td>Madison</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>James</td>\n      <td>Monroe</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAnd we can just copy these into our main dataframe if we want to:\n\n::: {.cell execution_count=117}\n``` {.python .cell-code}\ndf[\"First\"]=names[\"First\"]\ndf[\"Last\"]=names[\"Last\"]\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=117}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>President</th>\n      <th>Born</th>\n      <th>Age atstart of presidency</th>\n      <th>Age atend of presidency</th>\n      <th>Post-presidencytimespan</th>\n      <th>Died</th>\n      <th>Age</th>\n      <th>First</th>\n      <th>Last</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>George Washington</td>\n      <td>Feb 22, 1732[a]</td>\n      <td>57 years, 67 daysApr 30, 1789</td>\n      <td>65 years, 10 daysMar 4, 1797</td>\n      <td>2 years, 285 days</td>\n      <td>Dec 14, 1799</td>\n      <td>67 years, 295 days</td>\n      <td>George</td>\n      <td>Washington</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>John Adams</td>\n      <td>Oct 30, 1735[a]</td>\n      <td>61 years, 125 daysMar 4, 1797</td>\n      <td>65 years, 125 daysMar 4, 1801</td>\n      <td>25 years, 122 days</td>\n      <td>Jul 4, 1826</td>\n      <td>90 years, 247 days</td>\n      <td>John</td>\n      <td>Adams</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Thomas Jefferson</td>\n      <td>Apr 13, 1743[a]</td>\n      <td>57 years, 325 daysMar 4, 1801</td>\n      <td>65 years, 325 daysMar 4, 1809</td>\n      <td>17 years, 122 days</td>\n      <td>Jul 4, 1826</td>\n      <td>83 years, 82 days</td>\n      <td>Thomas</td>\n      <td>Jefferson</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>James Madison</td>\n      <td>Mar 16, 1751[a]</td>\n      <td>57 years, 353 daysMar 4, 1809</td>\n      <td>65 years, 353 daysMar 4, 1817</td>\n      <td>19 years, 116 days</td>\n      <td>Jun 28, 1836</td>\n      <td>85 years, 104 days</td>\n      <td>James</td>\n      <td>Madison</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>James Monroe</td>\n      <td>Apr 28, 1758</td>\n      <td>58 years, 310 daysMar 4, 1817</td>\n      <td>66 years, 310 daysMar 4, 1825</td>\n      <td>6 years, 122 days</td>\n      <td>Jul 4, 1831</td>\n      <td>73 years, 67 days</td>\n      <td>James</td>\n      <td>Monroe</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nIt's worth looking at the pandas str module for other functions which have been written specifically to clean up strings in DataFrames, and you can find that in the docs in the Working with Text section: https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html\n\nNow lets move on to clean up that Born column. First, let's get rid of anything that isn't in the pattern of Month Day and Year:\n\n::: {.cell execution_count=118}\n``` {.python .cell-code}\ndf['Born'] = df['Born'].str.extract('([\\w]{3} [\\w]{1,2}, [\\w]{4})')\ndf['Born'].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=118}\n```\n0    Feb 22, 1732\n1    Oct 30, 1735\n2    Apr 13, 1743\n3    Mar 16, 1751\n4    Apr 28, 1758\nName: Born, dtype: object\n```\n:::\n:::\n\n\nSo, that cleans up the date format. But I'm going to foreshadow something else here - the type of this column is object, and we know that's what pandas uses when it is dealing with string. But pandas actually has really interesting date/time features - in fact, that's one of the reasons Wes McKinney put his efforts into the library, to deal with financial transactions. So if I were building this out, I would actually update this column to the write data type as well:\n\n::: {.cell execution_count=119}\n``` {.python .cell-code}\ndf['Born'] = pd.to_datetime(df['Born'])\ndf['Born'].head()\n```\n\n::: {.cell-output .cell-output-display execution_count=119}\n```\n0   1732-02-22\n1   1735-10-30\n2   1743-04-13\n3   1751-03-16\n4   1758-04-28\nName: Born, dtype: datetime64[ns]\n```\n:::\n:::\n\n\n## DataFrame Manipulation\n\nNow that you know the basics of what makes up a pandas dataframe, lets look at how we might actually clean some messy data. Now, there are many different approaches you can take to clean data, so this lecture is just one example of how you might tackle a problem.\n\n::: {.cell execution_count=120}\n``` {.python .cell-code}\nimport pandas as pd\ndfs=pd.read_html(\"https://en.wikipedia.org/wiki/College_admissions_in_the_United_States\")\nlen(dfs)\n```\n\n::: {.cell-output .cell-output-display execution_count=120}\n```\n11\n```\n:::\n:::\n\n\n::: {.cell execution_count=121}\n``` {.python .cell-code}\ndfs[10]\n```\n\n::: {.cell-output .cell-output-display execution_count=121}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>College</th>\n      <th>Wait list offers Class of 2021</th>\n      <th>Wait list admits Class of 2021</th>\n      <th>Wait list offers Class of 2022</th>\n      <th>Wait list admits Class of 2022</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Stanford</td>\n      <td>842</td>\n      <td>36</td>\n      <td>870</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Princeton</td>\n      <td>1168</td>\n      <td>101</td>\n      <td>1125</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dartmouth</td>\n      <td>2021</td>\n      <td>0</td>\n      <td>1925</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>UPenn</td>\n      <td>3457</td>\n      <td>58</td>\n      <td>3535</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CMC</td>\n      <td>723</td>\n      <td>1</td>\n      <td>1037</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Tulane</td>\n      <td>5596</td>\n      <td>0</td>\n      <td>10384</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Michigan</td>\n      <td>11094</td>\n      <td>468</td>\n      <td>14893</td>\n      <td>415</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>UNC</td>\n      <td>5097</td>\n      <td>35</td>\n      <td>4977</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Wesleyan</td>\n      <td>2267</td>\n      <td>108</td>\n      <td>1965</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>CMU</td>\n      <td>5609</td>\n      <td>4</td>\n      <td>3677</td>\n      <td>109</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Macalester</td>\n      <td>356</td>\n      <td>104</td>\n      <td>426</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Cal Poly SLO</td>\n      <td>3168</td>\n      <td>15</td>\n      <td>6643</td>\n      <td>2436</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>UC Santa Barbara</td>\n      <td>6650</td>\n      <td>960</td>\n      <td>7856</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>UC Riverside</td>\n      <td>5499</td>\n      <td>321</td>\n      <td>11058</td>\n      <td>1143</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Holy Cross</td>\n      <td>1109</td>\n      <td>0</td>\n      <td>1581</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Oregon</td>\n      <td>134</td>\n      <td>73</td>\n      <td>264</td>\n      <td>69</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nA sort of sub-language within Python, Pandas has its own set of idioms. We've alluded to some of these already, such as using vectorization whenever possible, and not using iterative loops if you don't need to. Several developers and users within the Panda's community have used the term pandorable for these idioms. I think it's a great term. So, I wanted to share with you a couple of key features of how you can make your code pandorable.\n\n::: {.cell execution_count=122}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport timeit\n\ndf = pd.read_csv('../data/week2/census.csv')\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=122}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SUMLEV</th>\n      <th>REGION</th>\n      <th>DIVISION</th>\n      <th>STATE</th>\n      <th>COUNTY</th>\n      <th>STNAME</th>\n      <th>CTYNAME</th>\n      <th>CENSUS2010POP</th>\n      <th>ESTIMATESBASE2010</th>\n      <th>POPESTIMATE2010</th>\n      <th>...</th>\n      <th>RDOMESTICMIG2011</th>\n      <th>RDOMESTICMIG2012</th>\n      <th>RDOMESTICMIG2013</th>\n      <th>RDOMESTICMIG2014</th>\n      <th>RDOMESTICMIG2015</th>\n      <th>RNETMIG2011</th>\n      <th>RNETMIG2012</th>\n      <th>RNETMIG2013</th>\n      <th>RNETMIG2014</th>\n      <th>RNETMIG2015</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Alabama</td>\n      <td>Alabama</td>\n      <td>4779736</td>\n      <td>4780127</td>\n      <td>4785161</td>\n      <td>...</td>\n      <td>0.002295</td>\n      <td>-0.193196</td>\n      <td>0.381066</td>\n      <td>0.582002</td>\n      <td>-0.467369</td>\n      <td>1.030015</td>\n      <td>0.826644</td>\n      <td>1.383282</td>\n      <td>1.724718</td>\n      <td>0.712594</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Alabama</td>\n      <td>Autauga County</td>\n      <td>54571</td>\n      <td>54571</td>\n      <td>54660</td>\n      <td>...</td>\n      <td>7.242091</td>\n      <td>-2.915927</td>\n      <td>-3.012349</td>\n      <td>2.265971</td>\n      <td>-2.530799</td>\n      <td>7.606016</td>\n      <td>-2.626146</td>\n      <td>-2.722002</td>\n      <td>2.592270</td>\n      <td>-2.187333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Alabama</td>\n      <td>Baldwin County</td>\n      <td>182265</td>\n      <td>182265</td>\n      <td>183193</td>\n      <td>...</td>\n      <td>14.832960</td>\n      <td>17.647293</td>\n      <td>21.845705</td>\n      <td>19.243287</td>\n      <td>17.197872</td>\n      <td>15.844176</td>\n      <td>18.559627</td>\n      <td>22.727626</td>\n      <td>20.317142</td>\n      <td>18.293499</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>5</td>\n      <td>Alabama</td>\n      <td>Barbour County</td>\n      <td>27457</td>\n      <td>27457</td>\n      <td>27341</td>\n      <td>...</td>\n      <td>-4.728132</td>\n      <td>-2.500690</td>\n      <td>-7.056824</td>\n      <td>-3.904217</td>\n      <td>-10.543299</td>\n      <td>-4.874741</td>\n      <td>-2.758113</td>\n      <td>-7.167664</td>\n      <td>-3.978583</td>\n      <td>-10.543299</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>7</td>\n      <td>Alabama</td>\n      <td>Bibb County</td>\n      <td>22915</td>\n      <td>22919</td>\n      <td>22861</td>\n      <td>...</td>\n      <td>-5.527043</td>\n      <td>-5.068871</td>\n      <td>-6.201001</td>\n      <td>-0.177537</td>\n      <td>0.177258</td>\n      <td>-5.088389</td>\n      <td>-4.363636</td>\n      <td>-5.403729</td>\n      <td>0.754533</td>\n      <td>1.107861</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 100 columns</p>\n</div>\n```\n:::\n:::\n\n\nThe first of these is called **method chaining**.\n\nThe general idea behind method chaining is that every method on an object returns a reference to that object. The beauty of this is that you can condense many different operations on a DataFrame, for instance, into one line or at least one statement of code.\n\nHere's an example of two pieces of code in pandas using our census data.\n\nThe first is the pandorable way to write the code with method chaining. In this code, there's no in place flag being used and you can see that when we first run a where query, then a dropna, then a set_index, and then a rename. You might wonder why the whole statement is enclosed in parentheses and that's just to make the statement more readable.\n\n::: {.cell execution_count=123}\n``` {.python .cell-code}\n(df.where(df['SUMLEV']==50) \\\n    .dropna() \\\n    .set_index(['STNAME', 'CTYNAME']) \\\n    .rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'}))\n```\n\n::: {.cell-output .cell-output-display execution_count=123}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>SUMLEV</th>\n      <th>REGION</th>\n      <th>DIVISION</th>\n      <th>STATE</th>\n      <th>COUNTY</th>\n      <th>CENSUS2010POP</th>\n      <th>Estimates Base 2010</th>\n      <th>POPESTIMATE2010</th>\n      <th>POPESTIMATE2011</th>\n      <th>POPESTIMATE2012</th>\n      <th>...</th>\n      <th>RDOMESTICMIG2011</th>\n      <th>RDOMESTICMIG2012</th>\n      <th>RDOMESTICMIG2013</th>\n      <th>RDOMESTICMIG2014</th>\n      <th>RDOMESTICMIG2015</th>\n      <th>RNETMIG2011</th>\n      <th>RNETMIG2012</th>\n      <th>RNETMIG2013</th>\n      <th>RNETMIG2014</th>\n      <th>RNETMIG2015</th>\n    </tr>\n    <tr>\n      <th>STNAME</th>\n      <th>CTYNAME</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Alabama</th>\n      <th>Autauga County</th>\n      <td>50.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>54571.0</td>\n      <td>54571.0</td>\n      <td>54660.0</td>\n      <td>55253.0</td>\n      <td>55175.0</td>\n      <td>...</td>\n      <td>7.242091</td>\n      <td>-2.915927</td>\n      <td>-3.012349</td>\n      <td>2.265971</td>\n      <td>-2.530799</td>\n      <td>7.606016</td>\n      <td>-2.626146</td>\n      <td>-2.722002</td>\n      <td>2.592270</td>\n      <td>-2.187333</td>\n    </tr>\n    <tr>\n      <th>Baldwin County</th>\n      <td>50.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>182265.0</td>\n      <td>182265.0</td>\n      <td>183193.0</td>\n      <td>186659.0</td>\n      <td>190396.0</td>\n      <td>...</td>\n      <td>14.832960</td>\n      <td>17.647293</td>\n      <td>21.845705</td>\n      <td>19.243287</td>\n      <td>17.197872</td>\n      <td>15.844176</td>\n      <td>18.559627</td>\n      <td>22.727626</td>\n      <td>20.317142</td>\n      <td>18.293499</td>\n    </tr>\n    <tr>\n      <th>Barbour County</th>\n      <td>50.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>27457.0</td>\n      <td>27457.0</td>\n      <td>27341.0</td>\n      <td>27226.0</td>\n      <td>27159.0</td>\n      <td>...</td>\n      <td>-4.728132</td>\n      <td>-2.500690</td>\n      <td>-7.056824</td>\n      <td>-3.904217</td>\n      <td>-10.543299</td>\n      <td>-4.874741</td>\n      <td>-2.758113</td>\n      <td>-7.167664</td>\n      <td>-3.978583</td>\n      <td>-10.543299</td>\n    </tr>\n    <tr>\n      <th>Bibb County</th>\n      <td>50.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>22915.0</td>\n      <td>22919.0</td>\n      <td>22861.0</td>\n      <td>22733.0</td>\n      <td>22642.0</td>\n      <td>...</td>\n      <td>-5.527043</td>\n      <td>-5.068871</td>\n      <td>-6.201001</td>\n      <td>-0.177537</td>\n      <td>0.177258</td>\n      <td>-5.088389</td>\n      <td>-4.363636</td>\n      <td>-5.403729</td>\n      <td>0.754533</td>\n      <td>1.107861</td>\n    </tr>\n    <tr>\n      <th>Blount County</th>\n      <td>50.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>57322.0</td>\n      <td>57322.0</td>\n      <td>57373.0</td>\n      <td>57711.0</td>\n      <td>57776.0</td>\n      <td>...</td>\n      <td>1.807375</td>\n      <td>-1.177622</td>\n      <td>-1.748766</td>\n      <td>-2.062535</td>\n      <td>-1.369970</td>\n      <td>1.859511</td>\n      <td>-0.848580</td>\n      <td>-1.402476</td>\n      <td>-1.577232</td>\n      <td>-0.884411</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Wyoming</th>\n      <th>Sweetwater County</th>\n      <td>50.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>56.0</td>\n      <td>37.0</td>\n      <td>43806.0</td>\n      <td>43806.0</td>\n      <td>43593.0</td>\n      <td>44041.0</td>\n      <td>45104.0</td>\n      <td>...</td>\n      <td>1.072643</td>\n      <td>16.243199</td>\n      <td>-5.339774</td>\n      <td>-14.252889</td>\n      <td>-14.248864</td>\n      <td>1.255221</td>\n      <td>16.243199</td>\n      <td>-5.295460</td>\n      <td>-14.075283</td>\n      <td>-14.070195</td>\n    </tr>\n    <tr>\n      <th>Teton County</th>\n      <td>50.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>56.0</td>\n      <td>39.0</td>\n      <td>21294.0</td>\n      <td>21294.0</td>\n      <td>21297.0</td>\n      <td>21482.0</td>\n      <td>21697.0</td>\n      <td>...</td>\n      <td>-1.589565</td>\n      <td>0.972695</td>\n      <td>19.525929</td>\n      <td>14.143021</td>\n      <td>-0.564849</td>\n      <td>0.654527</td>\n      <td>2.408578</td>\n      <td>21.160658</td>\n      <td>16.308671</td>\n      <td>1.520747</td>\n    </tr>\n    <tr>\n      <th>Uinta County</th>\n      <td>50.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>56.0</td>\n      <td>41.0</td>\n      <td>21118.0</td>\n      <td>21118.0</td>\n      <td>21102.0</td>\n      <td>20912.0</td>\n      <td>20989.0</td>\n      <td>...</td>\n      <td>-17.755986</td>\n      <td>-4.916350</td>\n      <td>-6.902954</td>\n      <td>-14.215862</td>\n      <td>-12.127022</td>\n      <td>-18.136812</td>\n      <td>-5.536861</td>\n      <td>-7.521840</td>\n      <td>-14.740608</td>\n      <td>-12.606351</td>\n    </tr>\n    <tr>\n      <th>Washakie County</th>\n      <td>50.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>56.0</td>\n      <td>43.0</td>\n      <td>8533.0</td>\n      <td>8533.0</td>\n      <td>8545.0</td>\n      <td>8469.0</td>\n      <td>8443.0</td>\n      <td>...</td>\n      <td>-11.637475</td>\n      <td>-0.827815</td>\n      <td>-2.013502</td>\n      <td>-17.781491</td>\n      <td>1.682288</td>\n      <td>-11.990126</td>\n      <td>-1.182592</td>\n      <td>-2.250385</td>\n      <td>-18.020168</td>\n      <td>1.441961</td>\n    </tr>\n    <tr>\n      <th>Weston County</th>\n      <td>50.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>56.0</td>\n      <td>45.0</td>\n      <td>7208.0</td>\n      <td>7208.0</td>\n      <td>7181.0</td>\n      <td>7114.0</td>\n      <td>7065.0</td>\n      <td>...</td>\n      <td>-11.752361</td>\n      <td>-8.040059</td>\n      <td>12.372583</td>\n      <td>1.533635</td>\n      <td>6.935294</td>\n      <td>-12.032179</td>\n      <td>-8.040059</td>\n      <td>12.372583</td>\n      <td>1.533635</td>\n      <td>6.935294</td>\n    </tr>\n  </tbody>\n</table>\n<p>3142 rows × 98 columns</p>\n</div>\n```\n:::\n:::\n\n\nThe second example is a more traditional way of writing code.\n\nThere's nothing wrong with this code in the functional sense, you might even be able to understand it better as a new person to the language. It's just not as pandorable as the first example.\n\n::: {.cell execution_count=124}\n``` {.python .cell-code}\ndf = df[df['SUMLEV']==50]\ndf.set_index(['STNAME','CTYNAME']).rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'})\n```\n\n::: {.cell-output .cell-output-display execution_count=124}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>SUMLEV</th>\n      <th>REGION</th>\n      <th>DIVISION</th>\n      <th>STATE</th>\n      <th>COUNTY</th>\n      <th>CENSUS2010POP</th>\n      <th>Estimates Base 2010</th>\n      <th>POPESTIMATE2010</th>\n      <th>POPESTIMATE2011</th>\n      <th>POPESTIMATE2012</th>\n      <th>...</th>\n      <th>RDOMESTICMIG2011</th>\n      <th>RDOMESTICMIG2012</th>\n      <th>RDOMESTICMIG2013</th>\n      <th>RDOMESTICMIG2014</th>\n      <th>RDOMESTICMIG2015</th>\n      <th>RNETMIG2011</th>\n      <th>RNETMIG2012</th>\n      <th>RNETMIG2013</th>\n      <th>RNETMIG2014</th>\n      <th>RNETMIG2015</th>\n    </tr>\n    <tr>\n      <th>STNAME</th>\n      <th>CTYNAME</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Alabama</th>\n      <th>Autauga County</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>54571</td>\n      <td>54571</td>\n      <td>54660</td>\n      <td>55253</td>\n      <td>55175</td>\n      <td>...</td>\n      <td>7.242091</td>\n      <td>-2.915927</td>\n      <td>-3.012349</td>\n      <td>2.265971</td>\n      <td>-2.530799</td>\n      <td>7.606016</td>\n      <td>-2.626146</td>\n      <td>-2.722002</td>\n      <td>2.592270</td>\n      <td>-2.187333</td>\n    </tr>\n    <tr>\n      <th>Baldwin County</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>3</td>\n      <td>182265</td>\n      <td>182265</td>\n      <td>183193</td>\n      <td>186659</td>\n      <td>190396</td>\n      <td>...</td>\n      <td>14.832960</td>\n      <td>17.647293</td>\n      <td>21.845705</td>\n      <td>19.243287</td>\n      <td>17.197872</td>\n      <td>15.844176</td>\n      <td>18.559627</td>\n      <td>22.727626</td>\n      <td>20.317142</td>\n      <td>18.293499</td>\n    </tr>\n    <tr>\n      <th>Barbour County</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>5</td>\n      <td>27457</td>\n      <td>27457</td>\n      <td>27341</td>\n      <td>27226</td>\n      <td>27159</td>\n      <td>...</td>\n      <td>-4.728132</td>\n      <td>-2.500690</td>\n      <td>-7.056824</td>\n      <td>-3.904217</td>\n      <td>-10.543299</td>\n      <td>-4.874741</td>\n      <td>-2.758113</td>\n      <td>-7.167664</td>\n      <td>-3.978583</td>\n      <td>-10.543299</td>\n    </tr>\n    <tr>\n      <th>Bibb County</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>7</td>\n      <td>22915</td>\n      <td>22919</td>\n      <td>22861</td>\n      <td>22733</td>\n      <td>22642</td>\n      <td>...</td>\n      <td>-5.527043</td>\n      <td>-5.068871</td>\n      <td>-6.201001</td>\n      <td>-0.177537</td>\n      <td>0.177258</td>\n      <td>-5.088389</td>\n      <td>-4.363636</td>\n      <td>-5.403729</td>\n      <td>0.754533</td>\n      <td>1.107861</td>\n    </tr>\n    <tr>\n      <th>Blount County</th>\n      <td>50</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1</td>\n      <td>9</td>\n      <td>57322</td>\n      <td>57322</td>\n      <td>57373</td>\n      <td>57711</td>\n      <td>57776</td>\n      <td>...</td>\n      <td>1.807375</td>\n      <td>-1.177622</td>\n      <td>-1.748766</td>\n      <td>-2.062535</td>\n      <td>-1.369970</td>\n      <td>1.859511</td>\n      <td>-0.848580</td>\n      <td>-1.402476</td>\n      <td>-1.577232</td>\n      <td>-0.884411</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Wyoming</th>\n      <th>Sweetwater County</th>\n      <td>50</td>\n      <td>4</td>\n      <td>8</td>\n      <td>56</td>\n      <td>37</td>\n      <td>43806</td>\n      <td>43806</td>\n      <td>43593</td>\n      <td>44041</td>\n      <td>45104</td>\n      <td>...</td>\n      <td>1.072643</td>\n      <td>16.243199</td>\n      <td>-5.339774</td>\n      <td>-14.252889</td>\n      <td>-14.248864</td>\n      <td>1.255221</td>\n      <td>16.243199</td>\n      <td>-5.295460</td>\n      <td>-14.075283</td>\n      <td>-14.070195</td>\n    </tr>\n    <tr>\n      <th>Teton County</th>\n      <td>50</td>\n      <td>4</td>\n      <td>8</td>\n      <td>56</td>\n      <td>39</td>\n      <td>21294</td>\n      <td>21294</td>\n      <td>21297</td>\n      <td>21482</td>\n      <td>21697</td>\n      <td>...</td>\n      <td>-1.589565</td>\n      <td>0.972695</td>\n      <td>19.525929</td>\n      <td>14.143021</td>\n      <td>-0.564849</td>\n      <td>0.654527</td>\n      <td>2.408578</td>\n      <td>21.160658</td>\n      <td>16.308671</td>\n      <td>1.520747</td>\n    </tr>\n    <tr>\n      <th>Uinta County</th>\n      <td>50</td>\n      <td>4</td>\n      <td>8</td>\n      <td>56</td>\n      <td>41</td>\n      <td>21118</td>\n      <td>21118</td>\n      <td>21102</td>\n      <td>20912</td>\n      <td>20989</td>\n      <td>...</td>\n      <td>-17.755986</td>\n      <td>-4.916350</td>\n      <td>-6.902954</td>\n      <td>-14.215862</td>\n      <td>-12.127022</td>\n      <td>-18.136812</td>\n      <td>-5.536861</td>\n      <td>-7.521840</td>\n      <td>-14.740608</td>\n      <td>-12.606351</td>\n    </tr>\n    <tr>\n      <th>Washakie County</th>\n      <td>50</td>\n      <td>4</td>\n      <td>8</td>\n      <td>56</td>\n      <td>43</td>\n      <td>8533</td>\n      <td>8533</td>\n      <td>8545</td>\n      <td>8469</td>\n      <td>8443</td>\n      <td>...</td>\n      <td>-11.637475</td>\n      <td>-0.827815</td>\n      <td>-2.013502</td>\n      <td>-17.781491</td>\n      <td>1.682288</td>\n      <td>-11.990126</td>\n      <td>-1.182592</td>\n      <td>-2.250385</td>\n      <td>-18.020168</td>\n      <td>1.441961</td>\n    </tr>\n    <tr>\n      <th>Weston County</th>\n      <td>50</td>\n      <td>4</td>\n      <td>8</td>\n      <td>56</td>\n      <td>45</td>\n      <td>7208</td>\n      <td>7208</td>\n      <td>7181</td>\n      <td>7114</td>\n      <td>7065</td>\n      <td>...</td>\n      <td>-11.752361</td>\n      <td>-8.040059</td>\n      <td>12.372583</td>\n      <td>1.533635</td>\n      <td>6.935294</td>\n      <td>-12.032179</td>\n      <td>-8.040059</td>\n      <td>12.372583</td>\n      <td>1.533635</td>\n      <td>6.935294</td>\n    </tr>\n  </tbody>\n</table>\n<p>3142 rows × 98 columns</p>\n</div>\n```\n:::\n:::\n\n\nNow, the key with any good idiom is to understand when it isn't helping you. In this case, you can actually time both methods and see which one runs faster.\n\nWe can put the approach into a function and pass the function into the timeit function to count the time the parameter number allows us to choose how many times we want to run the function. Here we will just set it to 1:\n\n::: {.cell execution_count=125}\n``` {.python .cell-code}\ndef first_approach():\n    global df\n    return (df.where(df['SUMLEV']==50)\n             .dropna()\n             .set_index(['STNAME','CTYNAME'])\n             .rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'}))\n    \ntimeit.timeit(first_approach, number=1)\n```\n\n::: {.cell-output .cell-output-display execution_count=125}\n```\n0.02009883099999854\n```\n:::\n:::\n\n\nNow let's test the second approach. As we notice, we use our global variable df in the function. However, changing a global variable inside a function will modify the variable even in a global scope and we do not want that to happen in this case. Therefore, for selecting summary levels of 50 only, I create a new dataframe for those records.\n\nLet's run this for once and see how fast it is:\n\n::: {.cell execution_count=126}\n``` {.python .cell-code}\ndef second_approach():\n    global df\n    new_df = df[df['SUMLEV']==50]\n    new_df.set_index(['STNAME','CTYNAME'], inplace=True)\n    return new_df.rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'})\ntimeit.timeit(second_approach, number=1)\n```\n\n::: {.cell-output .cell-output-display execution_count=126}\n```\n0.00573362499999952\n```\n:::\n:::\n\n\nAs you can see, the second approach is much faster! So, this is a particular example of a classic time readability trade off.\n \nHere's another pandas idiom. Python has a wonderful function called **map**, which is sort of a basis for functional programming in the language. When you want to use map in Python, you pass it some function you want called, and some iterable, like a list, that you want the function to be applied to. The results are that the function is called against each item in the list,and there's a resulting list of all of the evaluations of that function.\n\nPython has a similar function called **applymap**. In applymap, you provide some function which should operate on each cell of a DataFrame, and the return set is itself a DataFrame. Now I think applymap is fine, but I actually rarely use it. Instead, I find myself often wanting to  map across all of the rows in a DataFrame. And pandas has a function that I  use heavily there, called **apply**. Let's look at an example.\n\nLet's take our census DataFrame. In this DataFrame, we have five columns for population estimates. Each column corresponding with one year of estimates. It's quite reasonable to want to create some new columns for minimum or maximum values, and the apply function is an easy way to do this.\n\nFirst, we need to write a function which takes in a particular row of data, finds a minimum and maximum values, and returns a new row of data nd returns a new row of data.  We'll call this function min_max, this is pretty straight forward. We can create some small slice of a row by projecting the population columns. Then use the NumPy min and max functions, and create a new series with a label values represent the new values we want to apply.\n\n::: {.cell execution_count=127}\n``` {.python .cell-code}\ndef min_max(row):\n    data = row[[\n        'POPESTIMATE2010',\n        'POPESTIMATE2011',\n        'POPESTIMATE2012',\n        'POPESTIMATE2013',\n        'POPESTIMATE2014',\n        'POPESTIMATE2015']]\n    return pd.Series({'min': np.min(data), 'max': np.max(data)})\n```\n:::\n\n\nThen we just need to call apply on the DataFrame. \n\nApply takes the function and the axis on which to operate as parameters. Now, we have to be a bit careful, we've talked about axis zero being the rows of the DataFrame in the past. But this parameter is really the parameter of the index to use. So, to apply across all rows, which is applying on all columns, you pass axis equal to one.\n\n::: {.cell execution_count=128}\n``` {.python .cell-code}\n#df.apply(min_max, axis = 1)\n```\n:::\n\n\n Of course there's no need to limit yourself to returning a new series object. \n\nIf you're doing this as part of data cleaning your likely to find yourself wanting to add new data to the existing DataFrame. In that case you just take the row values and add in new columns indicating the max and minimum scores.\n\nThis is a regular part of my workflow when bringing in data and building summary or descriptive statistics. And is often used heavily with the merging of DataFrames.\n\nHere we have a revised version of the function min_max. Instead of returning a separate series to display the min and max. We add two new columns in the original dataframe to store min and max:\n\n::: {.cell execution_count=129}\n``` {.python .cell-code}\ndef min_max(row):\n    data = row[['POPESTIMATE2010',\n                'POPESTIMATE2011',\n                'POPESTIMATE2012',\n                'POPESTIMATE2013',\n                'POPESTIMATE2014',\n                'POPESTIMATE2015']]\n    row['max'] = np.max(data)\n    row['min'] = np.min(data)\n    return row\n\n#df.apply(min_max, axis=1)\n```\n:::\n\n\nApply is an extremely important tool in your toolkit. The reason I introduced apply here is because you rarely see it used with large function definitions, like we did. Instead, you typically see it used with **lambdas**. To get the most of the discussions you'll see online, you're going to need to know how to  at least read lambdas. \n\nHere's You can imagine how you might chain several apply calls with lambdas together to create a readable yet succinct data manipulation script. One line example of how you might calculate the max of the columns using the apply function.\n\n::: {.cell execution_count=130}\n``` {.python .cell-code}\nrows = ['POPESTIMATE2010',\n        'POPESTIMATE2011',\n        'POPESTIMATE2012',\n        'POPESTIMATE2013',\n        'POPESTIMATE2014',\n        'POPESTIMATE2015']\n\n#df.apply(lambda x: np.max(x[rows]), axis = 1)\n```\n:::\n\n\nThe beauty of the apply function is that it allows flexibility in doing whatever manipulation that you desire, and the function you pass into apply can be any customized function that you write. \n\nLet's say we want to divide the states into four categories: Northeast, Midwest, South, and West. We can write a customized function that returns the region based on the state the state regions information is obtained from Wikipedia:\n\n::: {.cell execution_count=131}\n``` {.python .cell-code}\ndef get_state_region(x):\n    northeast = ['Connecticut', 'Maine', 'Massachusetts', 'New Hampshire', \n                 'Rhode Island','Vermont','New York','New Jersey','Pennsylvania']\n    midwest = ['Illinois','Indiana','Michigan','Ohio','Wisconsin','Iowa',\n               'Kansas','Minnesota','Missouri','Nebraska','North Dakota',\n               'South Dakota']\n    south = ['Delaware','Florida','Georgia','Maryland','North Carolina',\n             'South Carolina','Virginia','District of Columbia','West Virginia',\n             'Alabama','Kentucky','Mississippi','Tennessee','Arkansas',\n             'Louisiana','Oklahoma','Texas']\n    west = ['Arizona','Colorado','Idaho','Montana','Nevada','New Mexico','Utah',\n            'Wyoming','Alaska','California','Hawaii','Oregon','Washington']\n    \n    if x in northeast:\n        return \"Northeast\"\n    elif x in midwest:\n        return \"Midwest\"\n    elif x in south:\n        return \"South\"\n    else:\n        return \"West\"\n```\n:::\n\n\nNow we have the customized function, let's say we want to create a new column called Region, which shows the state's region, we can use the customized function and the apply function to do so. The customized function is supposed to work on the state name column STNAME. So we will set the apply function on the state name column and pass the customized function into the apply function:\n\n::: {.cell execution_count=132}\n``` {.python .cell-code}\n#df['state_region'] = df['STNAME'].apply(lambda x: get_state_region(x))\n```\n:::\n\n\n::: {.cell execution_count=133}\n``` {.python .cell-code}\n#df.head()\n```\n:::\n\n\n",
    "supporting": [
      "4_pandas_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}