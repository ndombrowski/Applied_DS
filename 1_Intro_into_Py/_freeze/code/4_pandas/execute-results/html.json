{
  "hash": "acf456ececdfe58c59020d65a44413d0",
  "result": {
    "markdown": "# Pandas \n\n## Series data structure\n\nThe series is one of the core data structures in pandas. You think of it a cross between a list and a dictionary. The items are all stored in an order and there's labels with which you can retrieve them. An easy way to visualize this is two columns of data. The first is the special index, a lot like keys in a dictionary. While the second is your actual data. It's important to note that the data column has a label of its own and can be retrieved using the `.name` attribute. This is different than with dictionaries and is useful when it comes to merging multiple columns of data. \n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\n```\n:::\n\n\nYou can create a series by passing in a list of values. When you do this, Pandas automatically assigns an index starting with zero and sets the name of the series to None. \nOne of the easiest ways to create a series is to use an array-like object, like a list. \n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nstudents = ['Alice', 'Jack', 'Molly']\n```\n:::\n\n\nNow we just call the Series function in pandas and pass in the students:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\npd.Series(students)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n0    Alice\n1     Jack\n2    Molly\ndtype: object\n```\n:::\n:::\n\n\nThe result is a Series object which is nicely rendered to the screen. \n\nWe see here that  the pandas has automatically identified the type of data in this Series as \"object\" and set the dytpe parameter as appropriate. We see that the values are indexed with integers, starting at zero.\n\nWe don't have to use strings. If we passed in a list of whole numbers, for instance, we could see that panda sets the type to int64. Underneath panda stores series values in a  typed array using the Numpy library. This offers significant speedup when processing data  versus traditional python lists.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nnumbers = [1,2,3]\npd.Series(numbers)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n0    1\n1    2\n2    3\ndtype: int64\n```\n:::\n:::\n\n\nAnd we see on my architecture that the result is a dtype of int64 objects\n\n## Missing data\n\nThere's some other typing details that exist for performance that are important to know. The most important is how Numpy and thus pandas handle **missing data**. \n\nIn Python, we have the none type to indicate a lack of data. But what do we do if we want  to have a typed list like we do in the series object?\n\nUnderneath, pandas does some type conversion. If we create a list of strings and we have  one element, a None type, pandas inserts it as a None and uses the type object for the underlying array. \n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nstudents = ['Alice', 'Jack', None]\npd.Series(students)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n0    Alice\n1     Jack\n2     None\ndtype: object\n```\n:::\n:::\n\n\nHowever, if we create a list of numbers, integers or floats, and put in the None type, pandas automatically converts this to a special floating point value designated as NaN, which stands for \"Not a Number\".\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nnumbers = [1,2,None]\npd.Series(numbers)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n0    1.0\n1    2.0\n2    NaN\ndtype: float64\n```\n:::\n:::\n\n\nYou'll notice a couple of things:\n\n- First, NaN is a different value. \n- Second, pandas set the dytpe of this series to floating point numbers instead of object or ints. That's maybe a bit of a surprise - why not just leave this as an integer?\n\nUnderneath, pandas represents NaN as a floating point number, and because integers can be typecast to floats, pandas went and converted our integers to floats. So when you're wondering why the list of integers you put into a Series is not floats, it's probably because there is some missing data.\n\nIt is important to stress that None and NaN might be being used by the data scientist in the same way, to denote missing data, but that underneath these are not represented by pandas in the same way.\n\n**NaN is *NOT* equivilent to None and when we try the equality test, the result is False.**\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nnp.nan == None\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\nFalse\n```\n:::\n:::\n\n\nIt turns out that you actually can't do an equality test of NAN to itself. When you do, the answer is always False. \n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nnp.nan == np.nan\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nFalse\n```\n:::\n:::\n\n\nInstead, you need to use special functions to test for the presence of not a number, such as the Numpy library `isnan()`.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nnp.isnan(np.nan)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nTrue\n```\n:::\n:::\n\n\nSo keep in mind when you see NaN, it's meaning is similar to None, but it's a numeric value and treated differently for efficiency reasons.\n\n\n## Creating Series from dictionaries\n\nA series can be created directly from dictionary data. If you do this, the index is automatically assigned to the keys of the dictionary that you provided and not just incrementing integers.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nstudents_scores = {'Alice': 'Physics',\n                   'Jack': 'Chemistry',\n                   'Molly': 'English'}\ns = pd.Series(students_scores)\ns\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\nAlice      Physics\nJack     Chemistry\nMolly      English\ndtype: object\n```\n:::\n:::\n\n\nWe see that, since it was string data, pandas set the data type of the series to \"object\". We see that the index, the first column, is also a list of strings.\n\nOnce the series has been created, we can get the index object using the index attribute.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ns.index\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\nIndex(['Alice', 'Jack', 'Molly'], dtype='object')\n```\n:::\n:::\n\n\nAs you play more with pandas you'll notice that a lot of things are implemented as numpy arrays, and have the dtype value set. This is true of indicies, and here pandas inferred that we were using objects for the index.\n\nNow, this is kind of interesting. The dtype of object is not just for strings, but for arbitrary objects. Lets create a more complex type of data, say, a list of tuples.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nstudents = [(\"Alice\",\"Brown\"), (\"Jack\", \"White\"), (\"Molly\", \"Green\")]\npd.Series(students)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n0    (Alice, Brown)\n1     (Jack, White)\n2    (Molly, Green)\ndtype: object\n```\n:::\n:::\n\n\nWe see that each of the tuples is stored in the series object, and the type is object.\n\nYou can also separate your index creation from the data by passing in the index as a list explicitly to the series.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ns = pd.Series(['Physics', 'Chemistry', 'English'], index=['Alice', 'Jack', 'Molly'])\ns\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nAlice      Physics\nJack     Chemistry\nMolly      English\ndtype: object\n```\n:::\n:::\n\n\nSo what happens if your list of values in the index object are not aligned with the keys in your dictionary for creating the series? Well, pandas overrides the automatic creation to favor only and all of the indices values that you provided. So it will ignore from your dictionary all keys which are not in your index, and pandas will add None or NaN type values for any index value you provide, which is not in your dictionary key list.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nstudents_scores = {'Alice': 'Physics',\n                   'Jack': 'Chemistry',\n                   'Molly': 'English'}\n\n# When I create the series object though I'll only ask for an index with three students, and I'll exclude Jack\ns = pd.Series(students_scores, index=['Alice', 'Molly', 'Sam'])\ns\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\nAlice    Physics\nMolly    English\nSam          NaN\ndtype: object\n```\n:::\n:::\n\n\n## Querying a Series\n\nA pandas Series can be queried either by the index position or the index label. If you don't give an index to the series when querying, the position and the label are effectively the same values. \n\n- To query by numeric location, starting at zero, use the `iloc` attribute. \n- To query by the index label, you can use the `loc` attribute. \n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nstudents_classes = {'Alice': 'Physics',\n                   'Jack': 'Chemistry',\n                   'Molly': 'English',\n                   'Sam': 'History'}\n\ns = pd.Series(students_classes)\ns\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\nAlice      Physics\nJack     Chemistry\nMolly      English\nSam        History\ndtype: object\n```\n:::\n:::\n\n\nSo, for this series, if you wanted to see the fourth entry we would we would use the iloc attribute with the parameter 3.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ns.iloc[3]\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n'History'\n```\n:::\n:::\n\n\nIf you wanted to see what class Molly has, we would use the loc attribute with a parameter of Molly.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ns.loc['Molly']\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n'English'\n```\n:::\n:::\n\n\nKeep in mind that **iloc and loc are not methods, they are attributes**. So you don't use parentheses to query them, but square brackets instead, which is called the **indexing operator**. \n\nPandas tries to make our code a bit more readable and provides a sort of smart syntax using the indexing operator directly on the series itself. For instance, if you pass in an integer parameter, the operator will behave as if you want it to query via the iloc attribute\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\ns[3]\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```\n'History'\n```\n:::\n:::\n\n\nIf you pass in an object, it will query as if you wanted to use the label based loc attribute.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\ns['Molly']\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\n'English'\n```\n:::\n:::\n\n\nSo what happens if your index is a list of integers? This is a bit complicated and Pandas can't  determine automatically whether you're intending to query by index position or index label. So you need to be careful when using the indexing operator on the Series itself. The safer option is to be more explicit and use the iloc or loc attributes directly.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nclass_code = {99: 'Physics',\n              100: 'Chemistry',\n              101: 'English',\n              102: 'History'}\ns = pd.Series(class_code)\ns\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\n99       Physics\n100    Chemistry\n101      English\n102      History\ndtype: object\n```\n:::\n:::\n\n\nIf we try and call `s[0]` we get a key error because there's no item in the classes list with an index of zero, instead we have to call iloc explicitly if we want the first item.\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n#s[0]\n```\n:::\n\n\nThe code above will give us a `KeyError: 0`\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\ns.iloc[0]\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\n'Physics'\n```\n:::\n:::\n\n\nNow we know how to get data out of the series, let's talk about working with the data. A common task is to want to consider all of the values inside of a series and do some sort of  operation. This could be trying to find a certain number, or summarizing data or transforming the data in some way.\n\nA typical programmatic approach to this would be to iterate over all the items in the series, and invoke the operation one is interested in. For instance, we could create a Series of integers representing student grades, and just try and get an average grade\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\ngrades = pd.Series([90, 80, 70, 60])\ngrades\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\n0    90\n1    80\n2    70\n3    60\ndtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\ntotal = 0\n\nfor grade in grades:\n    total += grade\n\nprint(total/len(grades))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n75.0\n```\n:::\n:::\n\n\nThis works, but it's slow. Modern computers can do many tasks simultaneously, especially, but not only, tasks involving mathematics.\n\nPandas and the underlying numpy libraries support a method of computation called **vectorization.** Vectorization works with most of the functions in the numpy library, including the sum function.\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\ntotal = np.sum(grades)\nprint(total/len(grades))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n75.0\n```\n:::\n:::\n\n\nNow both of these methods create the same value, but is one actually faster? The Jupyter Notebook has a magic function which can help.\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nnumbers = pd.Series(np.random.randint(0,1000,10000))\n\n#look at the first 5 items\nnumbers.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\n0     17\n1    515\n2    501\n3    945\n4    671\ndtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\n#control length of series\nlen(numbers)\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\n10000\n```\n:::\n:::\n\n\nOk, we're confident now that we have a big series. The ipython interpreter has something called **magic functions** begin with a percentage sign. If we type this sign and then hit the Tab key, you can see a list of the available magic functions. You could write your own magic functions too, but that's a little bit outside of the scope of this course.\n\nHere, we're actually going to use what's called a **cellular magic function**. These start with two percentage signs and wrap the code in the current Jupyter cell. The function we're going to use is called `timeit`. This function will run our code a few times to determine, on average, how long it takes.\n\nLet's run timeit with our original iterative code. You can give timeit the number of loops that  you would like to run. By default, it is 1,000 loops. I'll ask timeit here to use 100 runs because we're recording this. Note that in order to use a cellular magic function, it has to be the first line in the cell\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\n%%timeit -n 100\n\ntotal = 0\nfor number in numbers:\n    total += number\n\ntotal/len(numbers)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.28 ms ± 202 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n```\n:::\n:::\n\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\n%%timeit -n 100\ntotal = np.sum(numbers)\ntotal/len(numbers)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n58.2 µs ± 10.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n```\n:::\n:::\n\n\nThis is a pretty shocking difference in the speed and demonstrates why one should be aware of parallel computing features and start thinking in functional programming terms. \n\nPut more simply, vectorization is the ability for a computer to execute multiple instructions at once, and with high performance chips, especially graphics cards, you can get dramatic speedups. Modern graphics cards can run thousands of instructions in parallel.\n\nA Related feature in pandas and nummy is called **broadcasting.** With broadcasting, you can apply an operation to every value in the series, changing the series. For instance, if we wanted to increase every random variable by 2, we could do so quickly using the += operator directly on the Series object.\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\nnumbers.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\n0     17\n1    515\n2    501\n3    945\n4    671\ndtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\nnumbers += 2\nnumbers.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\n0     19\n1    517\n2    503\n3    947\n4    673\ndtype: int64\n```\n:::\n:::\n\n\nThe procedural way of doing this would be to iterate through all of the items in the series and increase the values directly. Pandas does support iterating through a series much like a dictionary, allowing you to unpack values easily.\n\nWe can use the `iteritems()` function which returns a label and value \n\nPandas.iat(): allows to access a single value for a row/column pair by integer position.\n\nSelection with .at is nearly identical to .loc but it only selects a single 'cell' in your DataFrame/Series. We usually refer to this cell as a scalar value.\n\n- loc: label based, only works on index\n- iloc: position based\n- at: label based, gets scalar values. It's a very fast loc; Cannot operate on array indexers. Can assign new indices and columns\n- iat: position based, gets scalar values. It's a very fast iloc, Cannot work in array indexers. Cannot! assign new indices and columns.\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\nfor label, value in numbers.iteritems():\n    # in the early version of pandas we would use the set_value() function\n    # in the current version, we use the iat() or at() functions,\n    numbers.iat[label] = value + 2\n    #numbers.iloc[label] = value + 2\n\nnumbers.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\n0     21\n1    519\n2    505\n3    949\n4    675\ndtype: int64\n```\n:::\n:::\n\n\nLet's compare the speed:\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\n%%timeit -n 10\n\n# we'll create a blank new series of items to deal with\ns = pd.Series(np.random.randint(0,1000,1000))\n\n# And we'll just rewrite our loop from above.\nfor label, value in s.iteritems():\n    s.loc[label]= value+2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n48.1 ms ± 15.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n```\n:::\n:::\n\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\n%%timeit -n 10\n\n# We need to recreate a series\ns = pd.Series(np.random.randint(0,1000,1000))\n\n# And we just broadcast with +=\ns+=2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n235 µs ± 76.8 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n```\n:::\n:::\n\n\nNot only is it significantly faster, but it's more concise and even easier to read too. The typical mathematical operations you would expect are vectorized, and the nump documentation outlines what it takes to create vectorized functions of your own\n\nOne last note on using the indexing operators to access series data. **The .loc attribute lets you not only modify data in place, but also add new data as well((. If the value you pass in as the index doesn't exist, then a new entry is added. And keep in mind, indices can have mixed types.  While it's important to be aware of the typing going on underneath, Pandas will automatically  change the underlying NumPy types as appropriate.\n\n::: {.cell execution_count=35}\n``` {.python .cell-code}\ns = pd.Series([1, 2, 3])\n\n#add a new value\ns.loc['History'] = 102\n\ns\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```\n0            1\n1            2\n2            3\nHistory    102\ndtype: int64\n```\n:::\n:::\n\n\nWe see that mixed types for data values or index labels are no problem for Pandas. Since \n\"History\" is not in the original list of indices, s.loc['History'] essentially creates a \nnew element in the series, with the index named \"History\", and the value of 102\n\nUp until now I've shown only examples of a series where the index values were unique. I want  to end this lecture by showing an example where index values are not unique, and this makes  pandas Series a little different conceptually then, for instance, a relational database.\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\n# Lets create a Series with students and the courses which they have taken\nstudents_classes = pd.Series({'Alice': 'Physics',\n                   'Jack': 'Chemistry',\n                   'Molly': 'English',\n                   'Sam': 'History'})\nstudents_classes\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```\nAlice      Physics\nJack     Chemistry\nMolly      English\nSam        History\ndtype: object\n```\n:::\n:::\n\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\n# Now lets create a Series just for some new student Kelly, which lists all of the courses she has taken.\n#We'll set the index to Kelly, and the data to be the names of courses.\nkelly_classes = pd.Series(['Philosophy', 'Arts', 'Math'], index=['Kelly', 'Kelly', 'Kelly'])\nkelly_classes\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```\nKelly    Philosophy\nKelly          Arts\nKelly          Math\ndtype: object\n```\n:::\n:::\n\n\n## Appending Series\n\nFinally, we can append all of the data in this new Series to the first using the `.append()` function.\n\n::: {.cell execution_count=38}\n``` {.python .cell-code}\nall_students_classes = students_classes.append(kelly_classes)\nall_students_classes\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\nAlice       Physics\nJack      Chemistry\nMolly       English\nSam         History\nKelly    Philosophy\nKelly          Arts\nKelly          Math\ndtype: object\n```\n:::\n:::\n\n\nThere are a couple of important considerations when using append. \n\n- First, Pandas will take the series and try to infer the best data types to use. In this example, everything is a string, so there's no problems here. \n- Second, the append method doesn't actually change the underlying Series objects, it instead returns a new series which is made up of the two appended together. This is a common pattern in pandas - by default returning a new object instead of modifying in place - and one you should come to expect. By printing the original series we can see that that series hasn't changed.\n\n::: {.cell execution_count=39}\n``` {.python .cell-code}\nstudents_classes\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```\nAlice      Physics\nJack     Chemistry\nMolly      English\nSam        History\ndtype: object\n```\n:::\n:::\n\n\nFinally, we see that when we query the appended series for Kelly, we don't get a single value, but a series itself. \n\n::: {.cell execution_count=40}\n``` {.python .cell-code}\nall_students_classes['Kelly']\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```\nKelly    Philosophy\nKelly          Arts\nKelly          Math\ndtype: object\n```\n:::\n:::\n\n\n",
    "supporting": [
      "4_pandas_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}