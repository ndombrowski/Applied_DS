{
  "hash": "d6767d400cca1480af5f8641846e92fd",
  "result": {
    "markdown": "# Scales\n\nWe've already seen that pandas supports a number of different computational data types such as strings, integers, floating point numbers. What this doesn't capture is what we call the scale of the data. \n\nLet's say that we have got a DataFrame of students and their academic levels such as being in grade one, grade two, and grade three. Is the difference between a student in grade one and a student in grade two the same as the difference between a student in grade eight and one grade nine? \n\nAs a data scientist, there's at least four different scales that's worth knowing about:\n\n1. Ratio scales: \n    - Unites are equally spaces\n    - mathematical operations of +-* are valid\n    - I.e. height or weight\n\n2. Interval scale:\n    - Measurement units are equally are spaced\n    - There is no true 0, so mathematical operations are not valid\n    - I.e. temperature in C\n\n3. Ordinal scale:\n    - The order of the units is important but not evenly spaced\n    - Letter grades such as A+, A, B are a good example\n\n4. Nominal scale:\n    - Categories of data, but the categories have no order with respect to each other\n    - Also called categorical data in python\n    - I.e. teams of a sport\n\nPandas has a number of interesting functions to deal with converting between measurement scales.\n\nLets first create a dataframe of letter grades in descending order. We can also set an index value and here we'll just make it some human judgement of how good a student was, like \"excellent\" or \"good\":\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndf=pd.DataFrame(['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'D+', 'D'],\n                index=['excellent', 'excellent', 'excellent', 'good', 'good', 'good', \n                       'ok', 'ok', 'ok', 'poor', 'poor'],\n               columns=[\"Grades\"])\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=tex}\n\\begin{tabular}{ll}\n\\toprule\n{} & Grades \\\\\n\\midrule\nexcellent &     A+ \\\\\nexcellent &      A \\\\\nexcellent &     A- \\\\\ngood      &     B+ \\\\\ngood      &      B \\\\\ngood      &     B- \\\\\nok        &     C+ \\\\\nok        &      C \\\\\nok        &     C- \\\\\npoor      &     D+ \\\\\npoor      &      D \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\nNow, if we check the datatype of this column, we see that it's just an object, since we set string values:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndf.dtypes\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=tex}\n\\begin{tabular}{ll}\n\\toprule\n{} &       0 \\\\\n\\midrule\nGrades &  object \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\nWe can, however, tell pandas that we want to change the type to category, using the **astype()** function:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndf['Grades'].astype('category').head()\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=tex}\n\\begin{tabular}{ll}\n\\toprule\n{} & Grades \\\\\n\\midrule\nexcellent &     A+ \\\\\nexcellent &      A \\\\\nexcellent &     A- \\\\\ngood      &     B+ \\\\\ngood      &      B \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\nWe see now that there are eleven categories, and pandas is aware of what those categories are. More interesting though is that our data isn't just categorical, but that it's ordered. That is, an A- comes after a B+, and B comes before a B+. \n\nWe can tell pandas that the data is ordered by first creating a new categorical data type with the list of the categories (in order) and the `ordered=True` flag:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nmy_categories=pd.CategoricalDtype(categories=['D', 'D+', 'C-', 'C', 'C+', 'B-', 'B', 'B+', 'A-', 'A', 'A+'], ordered=True)\n\n# then we can just pass this to the astype() function\ngrades=df[\"Grades\"].astype(my_categories)\ngrades.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=tex}\n\\begin{tabular}{ll}\n\\toprule\n{} & Grades \\\\\n\\midrule\nexcellent &     A+ \\\\\nexcellent &      A \\\\\nexcellent &     A- \\\\\ngood      &     B+ \\\\\ngood      &      B \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\nNow we see that pandas is not only aware that there are 11 categories, but it is also aware of the order of those categories. \n\nSo, what can you do with this? Well because there is an ordering this can help with comparisons and boolean masking. For instance, if we have a list of our grades and we compare them to a 'C' we see that the lexicographical comparison returns results we were not intending. \n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndf[df['Grades'] > 'C']\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=tex}\n\\begin{tabular}{ll}\n\\toprule\n{} & Grades \\\\\n\\midrule\nok   &     C+ \\\\\nok   &     C- \\\\\npoor &     D+ \\\\\npoor &      D \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\nSo a C+ is great than a C, but a C- and D are not. However, if we broadcast over the dataframe which has the type set to an ordered categorical:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ngrades[grades > 'C']\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=tex}\n\\begin{tabular}{ll}\n\\toprule\n{} & Grades \\\\\n\\midrule\nexcellent &     A+ \\\\\nexcellent &      A \\\\\nexcellent &     A- \\\\\ngood      &     B+ \\\\\ngood      &      B \\\\\ngood      &     B- \\\\\nok        &     C+ \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\nWe see that the operator works as we would expect. We can then use a certain set of mathematical operators, like minimum, maximum, etc., on the ordinal data.\n\nSometimes it is useful to represent categorical values as each being a column with a true or a false as to whether the category applies. This is especially common in feature extraction, which is a topic in the data mining course. Variables with a boolean value are typically called **dummy variables**, and pandas has a built in function called **get_dummies** which will convert the values of a single column into multiple columns of\nzeros and ones indicating the presence of the dummy variable.\n\nThere’s one more common scale-based operation, and that’s on converting a scale from something that is on the interval or ratio scale, like a numeric grade, into one which is categorical. \n\nNow, this might seem a bit counter intuitive to you, since you are losing information about the value. But it’s commonly done in a couple of places. For instance, if you are visualizing the frequencies of categories, this can be an extremely useful approach, and histograms are regularly used with converted interval or ratio data. In addition, if you’re using a machine learning classification approach on data, you need to be using categorical data, so reducing dimensionality may be useful just to apply a given technique. \n\nPandas has a function called **cut** which takes as an argument some array-like structure like a column of a dataframe or a series. It also takes a number of bins to be used, and all bins are kept at equal spacing.\n\nLets go back to our census data for an example. We saw that we could group by state, then aggregate to get a list of the average county size by state. If we further apply cut to this with, say, ten bins, we can see the states listed as categoricals using the average county size.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndf = pd.read_csv('../data/week3/census.csv')\n\n#only work with country data\ndf = df[df['SUMLEV'] == 50]\n\n#work with only a few rows\ndf = df.set_index('STNAME').groupby(level=0)['CENSUS2010POP'].agg(np.average)\n\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=tex}\n\\begin{tabular}{lr}\n\\toprule\n{} &  CENSUS2010POP \\\\\nSTNAME     &                \\\\\n\\midrule\nAlabama    &   71339.343284 \\\\\nAlaska     &   24490.724138 \\\\\nArizona    &  426134.466667 \\\\\nArkansas   &   38878.906667 \\\\\nCalifornia &  642309.586207 \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\nNow if we just want to make \"bins\" of each of these, we can use cut():\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\npd.cut(df,10)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=tex}\n\\begin{tabular}{ll}\n\\toprule\n{} &             CENSUS2010POP \\\\\nSTNAME               &                           \\\\\n\\midrule\nAlabama              &    (11706.087, 75333.413] \\\\\nAlaska               &    (11706.087, 75333.413] \\\\\nArizona              &  (390320.176, 453317.529] \\\\\nArkansas             &    (11706.087, 75333.413] \\\\\nCalifornia           &  (579312.234, 642309.586] \\\\\nColorado             &   (75333.413, 138330.766] \\\\\nConnecticut          &  (390320.176, 453317.529] \\\\\nDelaware             &  (264325.471, 327322.823] \\\\\nDistrict of Columbia &  (579312.234, 642309.586] \\\\\nFlorida              &  (264325.471, 327322.823] \\\\\nGeorgia              &    (11706.087, 75333.413] \\\\\nHawaii               &  (264325.471, 327322.823] \\\\\nIdaho                &    (11706.087, 75333.413] \\\\\nIllinois             &   (75333.413, 138330.766] \\\\\nIndiana              &    (11706.087, 75333.413] \\\\\nIowa                 &    (11706.087, 75333.413] \\\\\nKansas               &    (11706.087, 75333.413] \\\\\nKentucky             &    (11706.087, 75333.413] \\\\\nLouisiana            &    (11706.087, 75333.413] \\\\\nMaine                &   (75333.413, 138330.766] \\\\\nMaryland             &  (201328.118, 264325.471] \\\\\nMassachusetts        &  (453317.529, 516314.881] \\\\\nMichigan             &   (75333.413, 138330.766] \\\\\nMinnesota            &    (11706.087, 75333.413] \\\\\nMississippi          &    (11706.087, 75333.413] \\\\\nMissouri             &    (11706.087, 75333.413] \\\\\nMontana              &    (11706.087, 75333.413] \\\\\nNebraska             &    (11706.087, 75333.413] \\\\\nNevada               &  (138330.766, 201328.118] \\\\\nNew Hampshire        &   (75333.413, 138330.766] \\\\\nNew Jersey           &  (390320.176, 453317.529] \\\\\nNew Mexico           &    (11706.087, 75333.413] \\\\\nNew York             &  (264325.471, 327322.823] \\\\\nNorth Carolina       &   (75333.413, 138330.766] \\\\\nNorth Dakota         &    (11706.087, 75333.413] \\\\\nOhio                 &   (75333.413, 138330.766] \\\\\nOklahoma             &    (11706.087, 75333.413] \\\\\nOregon               &   (75333.413, 138330.766] \\\\\nPennsylvania         &  (138330.766, 201328.118] \\\\\nRhode Island         &  (201328.118, 264325.471] \\\\\nSouth Carolina       &   (75333.413, 138330.766] \\\\\nSouth Dakota         &    (11706.087, 75333.413] \\\\\nTennessee            &    (11706.087, 75333.413] \\\\\nTexas                &   (75333.413, 138330.766] \\\\\nUtah                 &   (75333.413, 138330.766] \\\\\nVermont              &    (11706.087, 75333.413] \\\\\nVirginia             &    (11706.087, 75333.413] \\\\\nWashington           &  (138330.766, 201328.118] \\\\\nWest Virginia        &    (11706.087, 75333.413] \\\\\nWisconsin            &   (75333.413, 138330.766] \\\\\nWyoming              &    (11706.087, 75333.413] \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\nHere we see that states like alabama and alaska fall into the same category, while california and the disctrict of columbia fall in a very different category.\n\nNow, cutting is just one way to build categories from your data, and there are many other methods. For instance, cut gives you interval data, where the spacing between each category is equal sized. But sometimes you want to form categories based on frequency – you want the number of items in each bin to the be the same, instead of the spacing between bins. It really depends on what the shape of your data is, and what you’re planning to do with it.\n\n",
    "supporting": [
      "8_scales_files/figure-pdf"
    ],
    "filters": []
  }
}