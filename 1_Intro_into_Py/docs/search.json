[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Data Science Course 1",
    "section": "",
    "text": "This course will introduce the learner to the basics of the python programming environment, including fundamental python programming techniques such as lambdas, reading and manipulating csv files, and the numpy library. The course will introduce data manipulation and cleaning techniques using the popular python pandas data science library and introduce the abstraction of the Series and DataFrame as the central data structures for data analysis, along with tutorials on how to use functions such as groupby, merge, and pivot tables effectively. By the end of this course, students will be able to take tabular data, clean it, manipulate it, and run basic inferential statistical analyses.\nLink to course material:\nhttps://www.coursera.org/learn/python-data-analysis/ungradedLab/33VUU/your-personal-jupyter-notebook-workspace/lab?path=%2Flab"
  },
  {
    "objectID": "code/1_intro.html",
    "href": "code/1_intro.html",
    "title": "2  Introduction into python",
    "section": "",
    "text": "The syntax for writing a function in python. add_numbers is a function that takes two numbers and adds them together.\n\ndef add_numbers(x, y):\n    return x + y\n\nadd_numbers(1,2)\n\n3\n\n\nWe can easily change this to take 3 arguments instead of 2. we can also make the 3rd parameter optional.\nAll of the optional parameters, the ones that you got default values for, need to come at the end of the function declaration. It also means that you can pass an optional parameters as labeled values.\n\ndef add_numbers(x, y, z=None):\n    if z == None:\n        return x + y\n    else:\n        return x + y + z\n\nprint(add_numbers(1,2))\nprint(add_numbers(1,2,3))\n\n3\n6\n\n\nadd_numbers updated to take an optional flag parameter.\n\ndef add_numbers(x, y, z=None, flag=False):\n    if (flag):\n        print('Flag is true!')\n    if (z == None):\n        return x + y\n    else:\n        return x + y + z\n\n\nprint(add_numbers(1, 2, flag=True))\n\nFlag is true!\n3\n\n\nWe can use this for functions to add different modes of operation, i.e. we can add versus subtract:\n\ndef do_math(a, b, kind=None):\n  if (kind=='add'):\n    return a+b\n  else:\n    return a-b\n\ndo_math(1, 2, kind='add')\n\n3\n\n\nWe can also assign function add_numbers to variable a.\n\ndef add_numbers(x, y):\n    return x + y\n\n\na = add_numbers\na(1, 2)\n\n3"
  },
  {
    "objectID": "code/1_intro.html#python-types-and-sequences",
    "href": "code/1_intro.html#python-types-and-sequences",
    "title": "2  Introduction into python",
    "section": "2.2 Python Types and Sequences",
    "text": "2.2 Python Types and Sequences\nWe identify the type of a variable using the type() function:\n\ntype(add_numbers)\n\nfunction\n\n\n\n2.2.1 Tuples\nTuples are an immutable data structure (cannot be altered). We write tuples using parentheses and we can mix types within a tuple.\n\nx = (1, 'a', 2, 'b')\ntype(x)\n\ntuple\n\n\n\n\n2.2.2 Lists\nLists are a mutable data structure. A list is declared using a squared bracket.\n\nx = [1, 'a', 2, 'b']\ntype(x)\n\nlist\n\n\nWe can change the contents of a list, for example using the append function, which appends new items to the end of a list\n\nx.append(3.3)\nx\n\n[1, 'a', 2, 'b', 3.3]\n\n\n\n\n2.2.3 For loops\nBoth list and tuples are iterable types, so we can write loops to go through every value they hold.\n\nfor item in x:\n    print(item)\n\nprint('')\n\n1\na\n2\nb\n3.3\n\n\n\n\n\n2.2.4 Arrays\nLists and tuples can also be accessed as arrays by using the square bracket operator, which is called the indexing operator.\nThe first item of the list starts at position zero and to get the length of the list, we use the built in len function.\n\ni = 0\n\nwhile (i != len(x)):\n    print(x[i])\n    i = i + 1\n\nprint('')\n\n1\na\n2\nb\n3.3\n\n\n\n\n\n2.2.5 Concatenate lists\n\n[1, 2] + [3, 4]\n\n[1, 2, 3, 4]\n\n\n\n\n2.2.6 Repeat values in a list\n\n[1,2] * 3\n\n[1, 2, 1, 2, 1, 2]\n\n\n\n\n2.2.7 The in operator\nWe use the in operator to check if something is inside a list.\n\n1 in [1,2,3]\n\nTrue\n\n\n\n1 in [0,4,5]\n\nFalse\n\n\n\n\n2.2.8 Slicing\nIn Python, the indexing operator allows you to submit multiple values.\nThe first parameter is the starting location, if this is the only element then one item is return from the list.\nThe second parameter is the end of the slice. It’s an exclusive end so if you slice with the first parameter being zero the next parameter being one, then you only get back one item.\n\nx = 'This is a string'\nprint(x[0])  #first character\nprint(x[0:1])  #first character, but we have explicitly set the end character\nprint(x[0:2])  #first two characters\n\nT\nT\nTh\n\n\nOur index values can also be negative to index from the back of the string.\n\nx[-1]\n\n'g'\n\n\n\n#all characters from the 4th last to the second last\nx[-4:-2]\n\n'ri'\n\n\nStart at the first and going until the 3rd:\n\nx[:3]\n\n'Thi'\n\n\nStart with the fourth character and go to the end of the list\n\nx[4:]\n\n' is a string'\n\n\n\n\n2.2.9 Strings\nA lot of the operations we have done before, we can also do on strings\n\nfirstname = 'Christopher'\nlastname = 'Brooks'\n\n#concatenate two strings\nprint(firstname + ' ' + lastname)\n\n#repeat strings\nprint(firstname *2)\n\n#search for strings\nprint('Chris' in firstname)\n\nChristopher Brooks\nChristopherChristopher\nTrue\n\n\nBefore concatenating strings, we have to make sure to convert objects to strings. i.e. this does not work\n'Chris' + 2\nbut this does:\n\n'Chris' + str(2)\n\n'Chris2'\n\n\n\n\n2.2.10 Split\nsplit breaks up a string and returns a list of all the words in a string, or a list split on a specific character.\nBelow, we split up the string based on the presence of a space character resulting in a list of four elements. We can then use an index operator to choose parts of the list:\n\n# [0] selects the first element of the list\nfirstname = 'Christopher Arthur Hansen Brooks'.split(' ')[0]  \n\n# [-1] selects the last element of the list\nlastname = 'Christopher Arthur Hansen Brooks'.split(' ')[-1]  \n\nprint(firstname)\nprint(lastname)\n\nChristopher\nBrooks"
  },
  {
    "objectID": "code/1_intro.html#dictionaries",
    "href": "code/1_intro.html#dictionaries",
    "title": "2  Introduction into python",
    "section": "2.3 Dictionaries",
    "text": "2.3 Dictionaries\nDictionaries are similar to lists and tuples in that they hold a collection of items, but they’re labeled collections which do not have an ordering. This means that for each value you insert into the dictionary, you must also give a key to get that value out. A dictionary is denoted by curly brackets.\nWe indicate each item of the dictionary when creating it using a pair of values separated by colons.\nWe can retrieve a value for a given label using the indexing operator.\n\nx = {'Christopher Brooks': 'brooksch@umich.edu', 'Bill Gates': 'billg@microsoft.com'}\n\n# Retrieve a value by using the indexing operator\nx['Christopher Brooks']  \n\n'brooksch@umich.edu'\n\n\nWe can also add new items to the dictionary:\n\nx['Kevin Thompson'] = None\nx\n\n{'Christopher Brooks': 'brooksch@umich.edu',\n 'Bill Gates': 'billg@microsoft.com',\n 'Kevin Thompson': None}\n\n\n\n#access the values\nx.values()\n\ndict_values(['brooksch@umich.edu', 'billg@microsoft.com', None])\n\n\n\n#access the key:value pairs\nx.items()\n\ndict_items([('Christopher Brooks', 'brooksch@umich.edu'), ('Bill Gates', 'billg@microsoft.com'), ('Kevin Thompson', None)])\n\n\nWe can iterate through the items in a dictionary, i.e. we can iterate over all the keys:\n\nfor name in x:\n    print(x[name])\n\nprint('')\n\nbrooksch@umich.edu\nbillg@microsoft.com\nNone\n\n\n\nIterate over all the values:\n\nfor email in x.values():\n    print(email)\n\nprint('')    \n\nbrooksch@umich.edu\nbillg@microsoft.com\nNone\n\n\n\nWe can also iterate over all the keys and items in a dictionary:\n\nfor name, email in x.items():\n    print(name)\n    print(email)\n\nprint('')\n\nChristopher Brooks\nbrooksch@umich.edu\nBill Gates\nbillg@microsoft.com\nKevin Thompson\nNone\n\n\n\n\n2.3.1 Unpacking\nIn Python you can have a sequence. That’s a list or a tuple of values, and you can unpack those items into different variables through assignment in one statement.\n\nx = ('Christopher', 'Brooks', 'brooksch@umich.edu')\nfname, lname, email = x\n\nprint(fname)\nprint(lname)\nprint(x)\n\nChristopher\nBrooks\n('Christopher', 'Brooks', 'brooksch@umich.edu')\n\n\nMake sure the number of values you are unpacking matches the number of variables being assigned. I.e. the code below would give an error:\nx = ('Christopher', 'Brooks', 'brooksch@umich.edu', 'Ann Arbor')\nfname, lname, email = x"
  },
  {
    "objectID": "code/1_intro.html#python-more-on-strings",
    "href": "code/1_intro.html#python-more-on-strings",
    "title": "2  Introduction into python",
    "section": "2.4 Python More on Strings",
    "text": "2.4 Python More on Strings\nThe Python string formatting mini language allows you to write a string statement indicating placeholders for variables to be evaluated. You then pass these variables in either named or in order arguments, and Python handles the string manipulation for you.\nWe can write a sales statement string which includes these items using curly brackets.\nWe can then call the format method on that string and pass in the values that we want substituted as appropriate.\n\nsales_record = {\n    'price': 3.24,\n    'num_items': 4,\n    'person': 'Chris'}\n\nsales_statement = '{} bought {} item(s) at a price of {} each for a total of {}'\n\nprint(sales_statement.format(sales_record['person'],\nsales_record['num_items'],\nsales_record['price'],\nsales_record['num_items'] * sales_record['price']))\n\nChris bought 4 item(s) at a price of 3.24 each for a total of 12.96"
  },
  {
    "objectID": "code/1_intro.html#reading-and-writing-csv-files",
    "href": "code/1_intro.html#reading-and-writing-csv-files",
    "title": "2  Introduction into python",
    "section": "2.5 Reading and Writing CSV files",
    "text": "2.5 Reading and Writing CSV files\nLet’s import our datafile ../data/mpg.csv, which contains fuel economy data for 234 cars, using the csv module.\n\nmpg : miles per gallon\nclass : car classification\ncty : city mpg\ncyl : # of cylinders\ndispl : engine displacement in liters\ndrv : f = front-wheel drive, r = rear wheel drive, 4 = 4wd\nfl : fuel (e = ethanol E85, d = diesel, r = regular, p = premium, c = CNG)\nhwy : highway mpg\nmanufacturer : automobile manufacturer\nmodel : model of car\ntrans : type of transmission\nyear : model year\n\n\nimport csv\n\n\nwith open('../data/mpg.csv') as csvfile:\n    #read in data as a dictionary\n    mpg = list(csv.DictReader(csvfile))\n\nmpg[:3]\n\n[OrderedDict([('', '1'),\n              ('manufacturer', 'audi'),\n              ('model', 'a4'),\n              ('displ', '1.8'),\n              ('year', '1999'),\n              ('cyl', '4'),\n              ('trans', 'auto(l5)'),\n              ('drv', 'f'),\n              ('cty', '18'),\n              ('hwy', '29'),\n              ('fl', 'p'),\n              ('class', 'compact')]),\n OrderedDict([('', '2'),\n              ('manufacturer', 'audi'),\n              ('model', 'a4'),\n              ('displ', '1.8'),\n              ('year', '1999'),\n              ('cyl', '4'),\n              ('trans', 'manual(m5)'),\n              ('drv', 'f'),\n              ('cty', '21'),\n              ('hwy', '29'),\n              ('fl', 'p'),\n              ('class', 'compact')]),\n OrderedDict([('', '3'),\n              ('manufacturer', 'audi'),\n              ('model', 'a4'),\n              ('displ', '2'),\n              ('year', '2008'),\n              ('cyl', '4'),\n              ('trans', 'manual(m6)'),\n              ('drv', 'f'),\n              ('cty', '20'),\n              ('hwy', '31'),\n              ('fl', 'p'),\n              ('class', 'compact')])]\n\n\n\n#print the length of our list\nlen(mpg)\n\n234\n\n\nThe length of our list is 234, meaning we have a dictionary for each of the 234 cars in the CSV file.\n\n#print column names\nmpg[0].keys()\n\nodict_keys(['', 'manufacturer', 'model', 'displ', 'year', 'cyl', 'trans', 'drv', 'cty', 'hwy', 'fl', 'class'])\n\n\nFind the average cty fuel economy across all cars. All values in the dictionaries are strings, so we need to convert to float.\n\nsum(float(d['cty']) for d in mpg) / len(mpg)\n\n16.858974358974358\n\n\nFind the average city MPG grouped by the number of cylinders a car has.\nWe use set to return the unique values for the number of cylinders the cars in our dataset have.\n\ncylinders = set(d['cyl'] for d in mpg)\ncylinders\n\n{'4', '5', '6', '8'}\n\n\n\n#create empty list to store our calculations\nCtyMpgByCyl = []\n\n#iterate over all cylinder levels and then over all dics\nfor c in cylinders:\n    summpg = 0\n    cyltypecount = 0\n    #iterate over dics\n    for d in mpg:\n        #if the cylinder type matches add the cty mpg and increment the count\n        if d['cyl'] == c:\n            summpg += float(d['cty'])\n            cyltypecount += 1\n    # append the tuple ('cylinder', 'avg mpg')\n    CtyMpgByCyl.append((c, summpg/cyltypecount))\n\n#sort the list (lambda will be covered a bit later)\nCtyMpgByCyl.sort(key=lambda x: x[0])\nCtyMpgByCyl\n\n[('4', 21.012345679012345),\n ('5', 20.5),\n ('6', 16.21518987341772),\n ('8', 12.571428571428571)]\n\n\nNext, lets find the average highway MPG for the different vehicle classes.\n\n#find the different vehicle classes\nvehicleclass = set(d['class'] for d in mpg)\nvehicleclass\n\n{'2seater', 'compact', 'midsize', 'minivan', 'pickup', 'subcompact', 'suv'}\n\n\n\nHwyMpgByClass = []\n\nfor t in vehicleclass:\n    summpg = 0\n    vclasscount = 0\n    for d in mpg:\n        if d['class'] == t:\n            summpg += float(d['hwy'])\n            vclasscount += 1\n    HwyMpgByClass.append((t, summpg/vclasscount))\n\nHwyMpgByClass.sort(key=lambda x : x[1])\nHwyMpgByClass\n\n[('pickup', 16.87878787878788),\n ('suv', 18.129032258064516),\n ('minivan', 22.363636363636363),\n ('2seater', 24.8),\n ('midsize', 27.29268292682927),\n ('subcompact', 28.142857142857142),\n ('compact', 28.29787234042553)]"
  },
  {
    "objectID": "code/1_intro.html#dates-and-times",
    "href": "code/1_intro.html#dates-and-times",
    "title": "2  Introduction into python",
    "section": "2.6 Dates and Times",
    "text": "2.6 Dates and Times\nOne of the most common legacy methods for storing the date and time in online transactions systems is based on the offset from the epoch, which is January 1, 1970.\nIn Python, you can get the current time since the epoch using the time module. You can then create a time stamp using the from time stamp function on the date time object. When we print this value out, we see that the year, month, day, and so forth are also printed out.\n\nimport datetime as dt\nimport time as tm\n\ntime returns the current time in seconds since the Epoch. (January 1st, 1970)\n\ntm.time()\n\n1671458686.8570611\n\n\nCreate a timestamp:\n\ndtnow = dt.datetime.fromtimestamp(tm.time())\ndtnow\n\ndatetime.datetime(2022, 12, 19, 15, 4, 46, 864421)\n\n\nThe date time object has handy attributes to get the representative hour, day, seconds, etc.\n\n# get year, month, day, etc.from a datetime\ndtnow.year, dtnow.month, dtnow.day, dtnow.hour, dtnow.minute, dtnow.second  \n\n(2022, 12, 19, 15, 4, 46)\n\n\nDate time objects allow for simple math using time deltas. For instance, here, we can create a time delta of 100 days, then do subtraction and comparisons with the date time object.\n\n#create a timedelta of 100 days\ndelta = dt.timedelta(days = 100)\ndelta\n\ndatetime.timedelta(days=100)\n\n\n\n#return the current local date\ntoday = dt.date.today()\ntoday\n\ndatetime.date(2022, 12, 19)\n\n\n\n#extract the data 100 days ago\ntoday - delta\n\ndatetime.date(2022, 9, 10)\n\n\n\n#compare dates\ntoday > today - delta\n\nTrue"
  },
  {
    "objectID": "code/1_intro.html#objects-and-map",
    "href": "code/1_intro.html#objects-and-map",
    "title": "2  Introduction into python",
    "section": "2.7 Objects and map()",
    "text": "2.7 Objects and map()\nWe can define a class using the class keyword.\nClasses in Python are generally named using camel case, which means the first character of each word is capitalized.\nClass variables can also be declared. These are just variables which are shared across all instances. So in this example, we’re saying that the default for all people is at the school of information.\nTo define a method, you just write it as you would have a function. The one change, is that to have access to the instance, which a method is being invoked upon, you must include self, in the method signature. Similarly, if you want to refer to instance variables set on the object, you prepend them with the word self, with a full stop.\nIn this definition of a person, for instance, we have written two methods. Set name and set location. And both change instance bound variables, called name and location respectively\n\nclass Person:\n    #set a class variable\n    department = 'School of Information'\n    \n    #define a method\n    def set_name(self, new_name):\n        self.name = new_name\n    \n    def set_location(self, new_location):\n        self.location = new_location\n    \nperson = Person()\nperson.set_name('Chris Vrooks')\nperson.set_location('Mi, USA')\n\nprint('{} lives in {} and works in the department {}'. format(person.name,\nperson.location, person.department))\n\nChris Vrooks lives in Mi, USA and works in the department School of Information\n\n\nThere are a couple of implications of object-oriented programming in Python:\n\nObjects in Python do not have private or protected members. If you instantiate an object, you have full access to any of the methods or attributes of that object\nThere’s no need for an explicit constructor when creating objects in Python. You can add a constructor if you want to by declaring the __init__ method\n\nThe map function is one of the basis for functional programming in Python, it executes a specified function for each item in an iterable.\nFunctional programming is a programming paradigm in which you explicitly declare all parameters which could change through execution of a given function. Thus functional programming is referred to as being side-effect free, because there is a software contract that describes what can actually change by calling a function.\nThe map built-in function is one example of a functional programming feature of Python, that ties together a number of aspects of the language.\nThe map function signature looks like this: - The first parameters of function that you want executed - The second parameter, and every following parameter, is something which can be iterated upon\nImagine we have two list of numbers, maybe prices from two different stores on exactly the same items. And we wanted to find the minimum that we would have to pay if we bought the cheaper item between the two stores. To do this, we could iterate through each list, comparing items and choosing the cheapest. With map, we can do this comparison in a single statement.\n\nstore1 = [10.00, 11.00, 12.34, 2.34]\nstore2 = [9.00, 11.10, 12.34, 2.01]\n\ncheapest = map(min, store1, store2)\ncheapest\n\n<map at 0x7fae68fef490>\n\n\nWhen we go to print out the map, we see that we get an odd reference value instead of a list of items that we’re expecting. This is called lazy evaluation. In Python, the map function returns to you a map object. It doesn’t actually try and run the function min on two items, until you look inside for a value. This allows us to have very efficient memory management, even though something might be computationally complex.\nMaps are iterable, just like lists and tuples, so we can use a for loop to look at all of the values in the map.\n\nfor item in cheapest:\n    print(item)\n\nprint('')\n\n9.0\n11.0\n12.34\n2.01\n\n\n\nQuestion:\nHere is a list of faculty teaching this MOOC. Can you write a function and apply it using map() to get a list of all faculty titles and last names (e.g. [‘Dr. Brooks’, ‘Dr. Collins-Thompson’, …]) ?\n\npeople = ['Dr. Christopher Brooks', 'Dr. Kevyn Collins-Thompson', 'Dr. VG Vinod Vydiswaran', 'Dr. Daniel Romero']\n\ndef split_title_and_name(person):\n    title = person.split()[0]\n    lastname = person.split()[-1]\n    return '{} {}'.format(title, lastname)\n\nlist(map(split_title_and_name, people))\n\n['Dr. Brooks', 'Dr. Collins-Thompson', 'Dr. Vydiswaran', 'Dr. Romero']"
  },
  {
    "objectID": "code/1_intro.html#advanced-python-lambda-and-list-comprehensions",
    "href": "code/1_intro.html#advanced-python-lambda-and-list-comprehensions",
    "title": "2  Introduction into python",
    "section": "2.8 Advanced Python Lambda and List Comprehensions",
    "text": "2.8 Advanced Python Lambda and List Comprehensions\nLambda’s are Python’s way of creating anonymous functions. These are the same as other functions, but they have no name. The intent is that they’re simple or short lived and it’s easier just to write out the function in one line instead of going to the trouble of creating a named function.\nYou declare a lambda function with the word lambda followed by a list of arguments, followed by a colon and then a single expression. This is key: There’s only one expression to be evaluated in a lambda. The expression value is returned on execution of the lambda.\n\nmy_function = lambda a,b,c: a + b\n\nThe return of a lambda is a function reference. So in the case above, we would execute my_function and pass in three different parameters.\n\nmy_function(4,5,6)\n\n9\n\n\nNote that you can’t have default values for lambda parameters and you can’t have complex logic inside of the lambda itself because you’re limited to a single expression. Therefore, lambdas are more limited than full function definitions.\nAnother example, in which we add 10 to argument a, and return the result:\n\nx = lambda a : a + 10\nprint(x(5))\n\n15\n\n\nYou can apply the function above to an argument by surrounding the function and its argument with parentheses:\n\n(lambda x: x + 1)(5)\n\n6\n\n\nBecause a lambda function is an expression, it can be named. Therefore you could write the previous code as follows:\n\nadd_one = lambda x: x + 1\nadd_one(5)\n\n6\n\n\nExercise\nConvert the code below into a lambda:\n\npeople = ['Dr. Christopher Brooks', 'Dr. Kevyn Collins-Thompson', 'Dr. VG Vinod Vydiswaran', 'Dr. Daniel Romero']\n\ndef split_title_and_name(person):\n    return person.split()[0] + ' ' + person.split()[-1]\n\nlist(map(split_title_and_name, people))\n\n['Dr. Brooks', 'Dr. Collins-Thompson', 'Dr. Vydiswaran', 'Dr. Romero']\n\n\n\n#option 1\nfor person in people:\n    print((lambda x: x.split()[0] + ' ' + x.split()[-1])(person))\n\nprint('')\n\nDr. Brooks\nDr. Collins-Thompson\nDr. Vydiswaran\nDr. Romero\n\n\n\n\n#option 2\nlist(map(lambda person: person.split()[0] + ' ' + person.split()[-1], people))\n\n['Dr. Brooks', 'Dr. Collins-Thompson', 'Dr. Vydiswaran', 'Dr. Romero']\n\n\n\n2.8.1 List comprehensions\nWe’ve learned a lot about sequences and in Python. Tuples, lists, dictionaries and so forth.\nSequences are structures that we can iterate over, and often we create these through loops or by reading in data from a file.\nPython has built in support for creating these collections using a more abbreviated syntax called list comprehensions. The basic syntax looks as follows:\nnewlist = [expression for item in iterable if condition == True]\nLet’s start with how we usually write for loops:\n\nmy_list = []\n\nfor number in range(0,100):\n    #check for evenly dividing numbers\n    if number % 2 == 0:\n        my_list.append(number)\n\nmy_list\n\n[0,\n 2,\n 4,\n 6,\n 8,\n 10,\n 12,\n 14,\n 16,\n 18,\n 20,\n 22,\n 24,\n 26,\n 28,\n 30,\n 32,\n 34,\n 36,\n 38,\n 40,\n 42,\n 44,\n 46,\n 48,\n 50,\n 52,\n 54,\n 56,\n 58,\n 60,\n 62,\n 64,\n 66,\n 68,\n 70,\n 72,\n 74,\n 76,\n 78,\n 80,\n 82,\n 84,\n 86,\n 88,\n 90,\n 92,\n 94,\n 96,\n 98]\n\n\nWe can do the same with a list comprehension. We start the list comprehension with the value we want in the list. In this case, it’s a number. Then we put it in the for-loop, and then finally, we add any condition clauses.\n\nmy_list = [number for number in range(0,100) if number % 2 == 0]\nmy_list\n\n[0,\n 2,\n 4,\n 6,\n 8,\n 10,\n 12,\n 14,\n 16,\n 18,\n 20,\n 22,\n 24,\n 26,\n 28,\n 30,\n 32,\n 34,\n 36,\n 38,\n 40,\n 42,\n 44,\n 46,\n 48,\n 50,\n 52,\n 54,\n 56,\n 58,\n 60,\n 62,\n 64,\n 66,\n 68,\n 70,\n 72,\n 74,\n 76,\n 78,\n 80,\n 82,\n 84,\n 86,\n 88,\n 90,\n 92,\n 94,\n 96,\n 98]\n\n\nAnother example:\n\nfruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\n\nnewlist = [x for x in fruits if \"a\" in x]\n\nprint(newlist)\n\n['apple', 'banana', 'mango']\n\n\nNotice, that the if statement is optional:\n\nnewlist = [x for x in fruits]\nnewlist\n\n['apple', 'banana', 'cherry', 'kiwi', 'mango']\n\n\nThe expression is the current item in the iteration, but it is also the outcome, which you can manipulate before it ends up like a list item in the new list:\n\nnewlist = [x.upper() for x in fruits]\nnewlist\n\n['APPLE', 'BANANA', 'CHERRY', 'KIWI', 'MANGO']\n\n\nThe expression can also contain conditions, not like a filter, but as a way to manipulate the outcome:\n\nnewlist = [x if x != \"banana\" else \"orange\" for x in fruits]\nnewlist\n\n['apple', 'orange', 'cherry', 'kiwi', 'mango']\n\n\nExercise:\nThe function to convert:\n\ndef times_tables():\n    lst = []\n    for i in range(10):\n        for j in range (10):\n            lst.append(i*j)\n    return lst\n\nThe list comprehension:\n\ntimes_tables() == [i*j for i in range(10) for j in range(10)]\n\nTrue\n\n\nQuestion\nMany organizations have user ids which are constrained in some way. Imagine you work at an internet service provider and the user ids are all two letters followed by two numbers (e.g. aa49). Your task at such an organization might be to hold a record on the billing activity for each possible user.\nWrite an initialization line as a single list comprehension which creates a list of all possible user ids. Assume the letters are all lower case.\n\n#lowercase = 'abcdefghijklmnopqrstuvwxyz'\n#digits = '0123456789'\n\nmy_list = []\nlowercase = 'ab'\ndigits = '01'\n\nmy_list = [a+b+c+d for a in lowercase for b in lowercase for c in digits for d in digits]\n\nmy_list[0:4]\n\n['aa00', 'aa01', 'aa10', 'aa11']\n\n\n\nlen(my_list)\n\n16\n\n\nanswer = [???] correct_answer == answer ```"
  },
  {
    "objectID": "code/2_numpy.html",
    "href": "code/2_numpy.html",
    "title": "3  Numpy",
    "section": "",
    "text": "Numpy is the fundamental package for numeric computing with Python. It provides powerful ways to create, store, and/or manipulate data, which makes it able to seamlessly and speedily integrate with a wide variety of databases. This is also the foundation that Pandas is built on, which is a high-performance data-centric package that we will learn later in the course.\nIn this lecture, we will talk about creating array with certain data types, manipulating array, selecting elements from arrays, and loading dataset into array. Such functions are useful for manipulating data and understanding the functionalities of other common Python data packages."
  },
  {
    "objectID": "code/2_numpy.html#array-creation",
    "href": "code/2_numpy.html#array-creation",
    "title": "3  Numpy",
    "section": "3.1 Array creation",
    "text": "3.1 Array creation\n\n# Arrays are displayed as a list or list of lists and can be created through list as well. When creating an\n# array, we pass in a list as an argument in numpy array\na = np.array([1, 2, 3])\nprint(a)\n\n[1 2 3]\n\n\n\n# We can print the number of dimensions of a list using the ndim attribute\nprint(a.ndim)\n\n1\n\n\n\n# If we pass in a list of lists in numpy array, we create a multi-dimensional array, for instance, a matrix\nb = np.array([[1,2,3],[4,5,6]])\nb\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\n\n# We can print out the length of each dimension by calling the shape attribute, which returns a tuple\nb.shape\n\n(2, 3)\n\n\n\n# We can also check the type of items in the array\na.dtype\n\ndtype('int64')\n\n\n\n# Besides integers, floats are also accepted in numpy arrays\nc = np.array([2.2, 5, 1.1])\nc.dtype.name\n\n'float64'\n\n\n\n# Let's look at the data in our array\nc\n\narray([2.2, 5. , 1.1])\n\n\nNote that numpy automatically converts integers, like 5, up to floats, since there is no loss of precision. Numpy will try and give you the best data type format possible to keep your data types homogeneous, which means all the same, in the array.\nSometimes we know the shape of an array that we want to create, but not what we want to be in it. numpy offers several functions to create arrays with initial placeholders, such as zero’s or one’s.\n\n# Lets create two arrays, both the same shape but with different filler values\nd = np.zeros((2,3))\nprint(d)\n\n[[0. 0. 0.]\n [0. 0. 0.]]\n\n\n\ne = np.ones((2,3))\nprint(e)\n\n[[1. 1. 1.]\n [1. 1. 1.]]\n\n\n\n# We can also generate an array with random numbers\nnp.random.rand(2,3)\n\narray([[0.54749485, 0.67006722, 0.39011362],\n       [0.78564183, 0.71416696, 0.73579126]])\n\n\nYou’ll see zeros, ones, and rand used quite often to create example arrays, especially in stack overflow posts and other forums.\nWe can also create a sequence of numbers in an array with the arrange() function:\n\nThe fist argument is the starting bound\nthe second argument is the ending bound\nthe third argument is the difference between each consecutive numbers\n\n\n# Let's create an array of every even number from ten (inclusive) to fifty (exclusive)\nf = np.arange(10, 50, 2)\nf\n\narray([10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42,\n       44, 46, 48])\n\n\nIf we want to generate a sequence of floats, we can use the linspace() function. In this function the third argument isn’t the difference between two numbers, but the total number of items you want to generate\n\n#create 15 numbers from 0 (inclusive) to 2 (inclusive)\nnp.linspace( 0, 2, 15 ) \n\narray([0.        , 0.14285714, 0.28571429, 0.42857143, 0.57142857,\n       0.71428571, 0.85714286, 1.        , 1.14285714, 1.28571429,\n       1.42857143, 1.57142857, 1.71428571, 1.85714286, 2.        ])"
  },
  {
    "objectID": "code/2_numpy.html#array-operations",
    "href": "code/2_numpy.html#array-operations",
    "title": "3  Numpy",
    "section": "3.2 Array operations",
    "text": "3.2 Array operations\nWe can do many things on arrays, such as mathematical manipulation (addition, subtraction, square, exponents) as well as use boolean arrays, which are binary values. We can also do matrix manipulation such as product, transpose, inverse, and so forth.\nArithmetic operators on array apply elementwise.\n\n# Let's create a couple of arrays\na = np.array([10,20,30,40])\nb = np.array([1, 2, 3,4])\n\n# Now let's look at a minus b\nc = a-b\nprint(c)\n\n[ 9 18 27 36]\n\n\n\n# And let's look at a times b\nd = a*b\nprint(d)\n\n[ 10  40  90 160]\n\n\nWith arithmetic manipulation, we can convert current data to the way we want it to be. Here’s a real-world problem I face - I moved down to the United States about 6 years ago from Canada. In Canada we use celcius for temperatures, and my wife still hasn’t converted to the US system which uses farenheit. With numpy I could easily convert a number of farenheit values, say the weather forecase, to ceclius:\n\n# Let's create an array of typical Ann Arbor winter farenheit values\nfarenheit = np.array([0,-10,-5,-15,0])\n\ncelcius = (farenheit - 31) * (5/9)\ncelcius\n\narray([-17.22222222, -22.77777778, -20.        , -25.55555556,\n       -17.22222222])\n\n\nAnother useful and important manipulation is the boolean array. We can apply an operator on an array, and a boolean array will be returned for any element in the original, with True being emitted if it meets the condition and False otherwise. For instance, if we want to get a boolean array to check celcius degrees that are greater than -20 degrees\n\ncelcius > -20\n\narray([ True, False, False, False,  True])\n\n\nHere’s another example, we could use the modulus operator to check numbers in an array to see if they are even. Recall that modulus does division but throws away everything but the remainder (decimal) portion)\n\ncelcius%2 == 0\n\narray([False, False,  True, False, False])\n\n\nBesides element-wise manipulation, it is important to know that numpy supports matrix manipulation. Let’s look at matrix product. if we want to do elementwise product, we use the “*” sign\n\nA = np.array([[1,1],[0,1]])\nB = np.array([[2,0],[3,4]])\nprint(A*B)\n\n[[2 0]\n [0 4]]\n\n\nIf we want to do matrix product, we use the “@” sign or use the dot function\n\nprint(A@B)\n\n[[5 4]\n [3 4]]\n\n\nA few more linear algebra concepts are worth layering in here. You might recall that the product of two matrices is only plausible when the inner dimensions of the two matrices are the same. The dimensions refer to the number of elements both horizontally and vertically in the rendered matrices you’ve seen here. We can use numpy to quickly see the shape of a matrix:\n\nA.shape\n\n(2, 2)\n\n\nWhen manipulating arrays of different types, the type of the resulting array will correspond to the more general of the two types. This is called upcasting.\n\n# Let's create an array of integers\narray1 = np.array([[1, 2, 3], [4, 5, 6]])\nprint(array1.dtype)\n\n# Now let's create an array of floats\narray2 = np.array([[7.1, 8.2, 9.1], [10.4, 11.2, 12.3]])\nprint(array2.dtype)\n\nint64\nfloat64\n\n\nIntegers (int) are whole numbers only, and Floating point numbers (float) can have a whole number portion and a decimal portion. The 64 in this example refers to the number of bits that the operating system is reserving to represent the number, which determines the size (or precision) of the numbers that can be represented.\n\n# Let's do an addition for the two arrays\narray3=array1+array2\nprint(array3)\nprint(array3.dtype)\n\n[[ 8.1 10.2 12.1]\n [14.4 16.2 18.3]]\nfloat64\n\n\nNotice how the items in the resulting array have been upcast into floating point numbers.\nNumpy arrays have many interesting aggregation functions on them, such as sum(), max(), min(), and mean().\n\nprint(array3.sum())\nprint(array3.max())\nprint(array3.min())\nprint(array3.mean())\n\n79.3\n18.3\n8.1\n13.216666666666667\n\n\nFor two dimensional arrays, we can do the same thing for each row or column, let’s create an array with 15 elements, ranging from 1 to 15, with a dimension of 3X5.\n\nb = np.arange(1,16,1).reshape(3,5)\nprint(b)\n\n[[ 1  2  3  4  5]\n [ 6  7  8  9 10]\n [11 12 13 14 15]]\n\n\nNow, we often think about two dimensional arrays being made up of rows and columns, but you can also think of these arrays as just a giant ordered list of numbers, and the shape of the array, the number of rows and columns, is just an abstraction that we have for a particular purpose. Actually, this is exactly how basic images are stored in computer environments.\nLet’s take a look at an example and see how numpy comes into play.\n\n# For this demonstration I'll use the python imaging library (PIL) and a function to display images in the\n# Jupyter notebook\nfrom PIL import Image\nfrom IPython.display import display\n\n# And let's just look at the image I'm talking about\nim = Image.open('../images/chris.tiff')\ndisplay(im)\n\n\n\n\n\n# Now, we can convert this PIL image to a numpy array\narray=np.array(im)\nprint(array.shape)\nprint(array[:1])\n\n(200, 200)\n[[118 117 118 118 112 103  92  82  66  56  45  39  38  40  43  46  53  53\n   53  52  48  43  39  36  19  15  15  16  24  28  33  35  39  34  28  23\n   15   8   8  16  41  60  91 118 135 141 141 141 133 120 103  87  73  68\n   77  91 105 109 117 121 120 114 104  98  84  76  70  72  76  82  94 107\n  113 121 126 132 133 135 137 139 144 145 150 157 166 171 170 168 169 157\n  145 138 130 124 125 134 137 141 145 148 148 143 138 136 134 133 133 133\n  138 142 147 150 146 140 126 108  85  61  44  34  39  49  65  83 104 125\n  143 155 150 155 153 146 135 120  99  80  69  63  65  78  98 116 134 147\n  155 165 170 166 159 154 146 137 125 119 117 122 127 129 131 135 138 142\n  146 150 152 150 148 145 144 141 139 138 139 137 133 129 124 126 128 129\n  129 127 125 123 120 120 124 126 125 122 117 114 115 114 113 108 105 103\n  107 110]]\n\n\n\narray.dtype\n\ndtype('uint8')\n\n\nHere we see that we have a 200x200 array and that the values are all uint8. The uint means that they are unsigned integers (so no negative numbers) and the 8 means 8 bits per byte. This means that each value can be up to 2222222*2=256 in size (well, actually 255, because we start at zero).\nFor black and white images black is stored as 0 and white is stored as 255. So if we just wanted to invert this image we could use the numpy array to do so\n\n# Let's create an array the same shape\nmask=np.full(array.shape,255)\nmask\n\narray([[255, 255, 255, ..., 255, 255, 255],\n       [255, 255, 255, ..., 255, 255, 255],\n       [255, 255, 255, ..., 255, 255, 255],\n       ...,\n       [255, 255, 255, ..., 255, 255, 255],\n       [255, 255, 255, ..., 255, 255, 255],\n       [255, 255, 255, ..., 255, 255, 255]])\n\n\n\n# Now let's subtract that from the modified array\nmodified_array=array-mask\n\n# And lets convert all of the negative values to positive values\nmodified_array=modified_array*-1\n\n# And as a last step, let's tell numpy to set the value of the datatype correctly\nmodified_array=modified_array.astype(np.uint8)\nmodified_array\n\narray([[137, 138, 137, ..., 152, 148, 145],\n       [142, 142, 142, ..., 155, 152, 149],\n       [147, 147, 148, ..., 160, 157, 153],\n       ...,\n       [ 78,  74,  73, ...,  62,  57,  63],\n       [ 77,  73,  72, ...,  62,  54,  66],\n       [ 77,  73,  71, ...,  62,  54,  68]], dtype=uint8)\n\n\nAnd lastly, lets display this new array. We do this by using the fromarray() function in the python imaging library to convert the numpy array into an object jupyter can render\n\ndisplay(Image.fromarray(modified_array))\n\n\n\n\nOk, remember how I started this by talking about how we could just think of this as a giant array of bytes, and that the shape was an abstraction? Well, we could just decide to reshape the array and still try and render it. PIL is interpreting the individual rows as lines, so we can change the number of lines and columns if we want to. What do you think that would look like?\n\nreshaped=np.reshape(modified_array,(100,400))\nprint(reshaped.shape)\ndisplay(Image.fromarray(reshaped))\n\n(100, 400)\n\n\n\n\n\nBy reshaping the array to be only 100 rows high but 400 columns we’ve essentially doubled the image by taking every other line and stacking them out in width. This makes the image look more stretched out too.\nThis isn’t an image manipulation course, but the point was to show you that these numpy arrays are really just abstractions on top of data, and that data has an underlying format (in this case, uint8). But further, we can build abstractions on top of that, such as computer code which renders a byte as either black or white, which has meaning to people."
  },
  {
    "objectID": "code/2_numpy.html#indexing-slicing-iterating",
    "href": "code/2_numpy.html#indexing-slicing-iterating",
    "title": "3  Numpy",
    "section": "3.3 Indexing, Slicing, Iterating",
    "text": "3.3 Indexing, Slicing, Iterating\nIndexing, slicing and iterating are extremely important for data manipulation and analysis because these techniques allow us to select data based on conditions, and copy or update data.\n\n3.3.1 Indexing\nFirst we are going to look at integer indexing. A one-dimensional array, works in similar ways as a list. To get an element in a one-dimensional array, we simply use the offset index.\n\na = np.array([1,3,5,7])\na[2]\n\n5\n\n\nFor multidimensional array, we need to use integer array indexing, let’s create a new multidimensional array:\n\na = np.array([[1,2], [3, 4], [5, 6]])\na\n\narray([[1, 2],\n       [3, 4],\n       [5, 6]])\n\n\nIf we want to select one certain element, we can do so by entering the index, which is comprised of two integers the first being the row, and the second the column.\n\na[1,1]\n\n4\n\n\nIf we want to get multiple elements for example, 1, 4, and 6 and put them into a one-dimensional array we can enter the indices directly into an array function:\n\nnp.array([a[0, 0], a[1, 1], a[2, 1]])\n\narray([1, 4, 6])\n\n\nWe can also do that by using another form of array indexing, which essentially “zips” the first list and the second list up:\n\nprint(a[[0, 1, 2], [0, 1, 1]])\n\n[1 4 6]\n\n\n\n\n3.3.2 Boolean indexing\nBoolean indexing allows us to select arbitrary elements based on conditions. For example, in the matrix we just talked about we want to find elements that are greater than 5 so we set up a conditon a >5 :\n\nprint(a >5)\n\n[[False False]\n [False False]\n [False  True]]\n\n\n\n\n\nThis returns a boolean array showing that if the value at the corresponding index is greater than 5.\nWe can then place this array of booleans like a mask over the original array to return a one-dimensional array relating to the true values.\n\nprint(a[a>5])\n\n[6]\n\n\n\n\n3.3.3 Slicing\nSlicing is a way to create a sub-array based on the original array. For one-dimensional arrays, slicing works in similar ways to a list. To slice, we use the : sign. For instance, if we put :3 in the indexing brackets, we get elements from index 0 to index 3 (excluding index 3)\n\na = np.array([0,1,2,3,4,5])\nprint(a[:3])\n\n[0 1 2]\n\n\nBy putting 2:4 in the bracket, we get elements from index 2 to index 4 (excluding index 4)\n\nprint(a[2:4])\n\n[2 3]\n\n\nFor multi-dimensional arrays, it works similarly, lets see an example\n\na = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\na\n\narray([[ 1,  2,  3,  4],\n       [ 5,  6,  7,  8],\n       [ 9, 10, 11, 12]])\n\n\nFirst, if we put one argument in the array, for example a[:2] then we would get all the elements from the first (0th) and second row (1th)\n\na[:2]\n\narray([[1, 2, 3, 4],\n       [5, 6, 7, 8]])\n\n\nIf we add another argument to the array, for example a[:2, 1:3], we get the first two rows but then the second and third column values only\n\na[:2, 1:3]\n\narray([[2, 3],\n       [6, 7]])\n\n\nSo, in multidimensional arrays, the first argument is for selecting rows, and the second argument is for selecting columns\nIt is important to realize that a slice of an array is a view into the same data. This is called passing by reference. So modifying the sub array will consequently modify the original array\nHere I’ll change the element at position [0, 0], which is 2, to 50, then we can see that the value in the original array is changed to 50 as well\n\na = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\nsub_array = a[:2, 1:3]\nsub_array\n\narray([[2, 3],\n       [6, 7]])\n\n\n\nprint(\"sub array index [0,0] value before change:\", sub_array[0,0])\n\nsub array index [0,0] value before change: 2\n\n\n\nsub_array[0,0] = 50\nsub_array\n\narray([[50,  3],\n       [ 6,  7]])\n\n\n\nprint(\"sub array index [0,0] value after change:\", sub_array[0,0])\nprint(\"original array index [0,1] value after change:\", a[0,1])\n\nsub array index [0,0] value after change: 50\noriginal array index [0,1] value after change: 50"
  },
  {
    "objectID": "code/2_numpy.html#trying-numpy-with-datasets",
    "href": "code/2_numpy.html#trying-numpy-with-datasets",
    "title": "3  Numpy",
    "section": "3.4 Trying numpy with datasets",
    "text": "3.4 Trying numpy with datasets\nNow that we have learned the essentials of Numpy let’s use it on a couple of datasets.\nHere we have a very popular dataset on wine quality, and we are going to only look at red wines. The data fields include: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide,total sulfur dioxide density, pH, sulphates, alcohol, quality.\nTo load a dataset in Numpy, we can use the genfromtxt() function. We can specify data file name, delimiter (which is optional but often used), and number of rows to skip if we have a header row, hence it is 1 here\nThe genfromtxt() function has a parameter called dtype for specifying data types of each column this parameter is optional. Without specifying the types, all types will be casted the same to the more general/precise type.\n\nwines = np.genfromtxt(\"../data/week1/winequality-red.csv\", delimiter=\";\", skip_header=1)\nwines\n\narray([[ 7.4  ,  0.7  ,  0.   , ...,  0.56 ,  9.4  ,  5.   ],\n       [ 7.8  ,  0.88 ,  0.   , ...,  0.68 ,  9.8  ,  5.   ],\n       [ 7.8  ,  0.76 ,  0.04 , ...,  0.65 ,  9.8  ,  5.   ],\n       ...,\n       [ 6.3  ,  0.51 ,  0.13 , ...,  0.75 , 11.   ,  6.   ],\n       [ 5.9  ,  0.645,  0.12 , ...,  0.71 , 10.2  ,  5.   ],\n       [ 6.   ,  0.31 ,  0.47 , ...,  0.66 , 11.   ,  6.   ]])\n\n\nRecall that we can use integer indexing to get a certain column or a row. For example, if we want to select the fixed acidity column, which is the first coluumn, we can do so by entering the index into the array.\nAlso remember that for multidimensional arrays, the first argument refers to the row, and the second argument refers to the column, and if we just give one argument then we’ll get a single dimensional list back.\n\n# So all rows combined but only the first column from them would be\nprint(\"one integer 0 for slicing: \", wines[:, 0])\n\none integer 0 for slicing:  [7.4 7.8 7.8 ... 6.3 5.9 6. ]\n\n\n\n# But if we wanted the same values but wanted to preserve that they sit in their own rows we would write\nprint(\"0 to 1 for slicing: \\n\", wines[:, 0:1])\n\n0 to 1 for slicing: \n [[7.4]\n [7.8]\n [7.8]\n ...\n [6.3]\n [5.9]\n [6. ]]\n\n\nThis is another great example of how the shape of the data is an abstraction which we can layer intentionally on top of the data we are working with.\nIf we want a range of columns in order, say columns 0 through 3 (recall, this means first, second, and third, since we start at zero and don’t include the training index value), we can do that too:\n\nwines[:, 0:3]\n\narray([[7.4  , 0.7  , 0.   ],\n       [7.8  , 0.88 , 0.   ],\n       [7.8  , 0.76 , 0.04 ],\n       ...,\n       [6.3  , 0.51 , 0.13 ],\n       [5.9  , 0.645, 0.12 ],\n       [6.   , 0.31 , 0.47 ]])\n\n\nWhat if we want several non-consecutive columns? We can place the indices of the columns that we want into an array and pass the array as the second argument. Here’s an example:\n\nwines[:, [0,2,4]]\n\narray([[7.4  , 0.   , 0.076],\n       [7.8  , 0.   , 0.098],\n       [7.8  , 0.04 , 0.092],\n       ...,\n       [6.3  , 0.13 , 0.076],\n       [5.9  , 0.12 , 0.075],\n       [6.   , 0.47 , 0.067]])\n\n\nWe can also do some basic summarization of this dataset.\nFor example, if we want to find out the average quality of red wine, we can select the quality column. We could do this in a couple of ways, but the most appropriate is to use the -1 value for the index, as negative numbers mean slicing from the back of the list. We can then call the aggregation functions on this data.\n\nwines[:,-1].mean()\n\n5.6360225140712945\n\n\nLet’s take a look at another dataset, this time on graduate school admissions. It has fields such as GRE score, TOEFL score, university rating, GPA, having research experience or not, and a chance of admission.\nWith this dataset, we can do data manipulation and basic analysis to infer what conditions are associated with higher chance of admission. Let’s take a look.\nWe can specify data field names when using genfromtxt() to load CSV data. Also, we can have numpy try and infer the type of a column by setting the dtype parameter to None:\n\ngraduate_admission = np.genfromtxt('../data/week1/Admission_Predict.csv', dtype=None, delimiter=',', skip_header=1, names=('Serial No','GRE Score', 'TOEFL Score', 'University Rating', 'SOP','LOR','CGPA','Research', 'Chance of Admit'))\n\ngraduate_admission[:2]\n\narray([(1, 337, 118, 4, 4.5, 4.5, 9.65, 1, 0.92),\n       (2, 324, 107, 4, 4. , 4.5, 8.87, 1, 0.76)],\n      dtype=[('Serial_No', '<i8'), ('GRE_Score', '<i8'), ('TOEFL_Score', '<i8'), ('University_Rating', '<i8'), ('SOP', '<f8'), ('LOR', '<f8'), ('CGPA', '<f8'), ('Research', '<i8'), ('Chance_of_Admit', '<f8')])\n\n\nNotice that the resulting array is actually a one-dimensional array with 400 tuples:\n\ngraduate_admission.shape\n\n(400,)\n\n\nWe can retrieve a column from the array using the column’s name for example, let’s get the CGPA column and only the first five values.\n\ngraduate_admission['CGPA'][0:5]\n\narray([9.65, 8.87, 8.  , 8.67, 8.21])\n\n\nSince the GPA in the dataset range from 1 to 10, and in the US it’s more common to use a scale of up to 4, a common task might be to convert the GPA by dividing by 10 and then multiplying by 4\n\ngraduate_admission['CGPA'] = graduate_admission['CGPA'] /10 *4\ngraduate_admission['CGPA'][0:20] #let's get 20 values\n\narray([3.86 , 3.548, 3.2  , 3.468, 3.284, 3.736, 3.28 , 3.16 , 3.2  ,\n       3.44 , 3.36 , 3.6  , 3.64 , 3.2  , 3.28 , 3.32 , 3.48 , 3.2  ,\n       3.52 , 3.4  ])\n\n\nRecall boolean masking. We can use this to find out how many students have had research experience by creating a boolean mask and passing it to the array indexing operator\n\nlen(graduate_admission[graduate_admission['Research'] == 1])\n\n219\n\n\nSince we have the data field chance of admission, which ranges from 0 to 1, we can try to see if students with high chance of admission (>0.8) on average have higher GRE score than those with lower chance of admission (<0.4)\nSo first we use boolean masking to pull out only those students we are interested in based on their chance of admission, then we pull out only their GPA scores, then we print the mean values.\n\nprint(graduate_admission[graduate_admission['Chance_of_Admit'] > 0.8]['GRE_Score'].mean())\nprint(graduate_admission[graduate_admission['Chance_of_Admit'] < 0.4]['GRE_Score'].mean())\n\n328.7350427350427\n302.2857142857143\n\n\nTake a moment to reflect here, do you understand what is happening in these calls?\nWhen we do the boolean masking we are left with an array with tuples in it still, and numpy holds underneath this a list of the columns we specified and their name and indexes\n\ngraduate_admission[graduate_admission['Chance_of_Admit'] > 0.8][:2]\n\narray([(1, 337, 118, 4, 4.5, 4.5, 3.86 , 1, 0.92),\n       (6, 330, 115, 5, 4.5, 3. , 3.736, 1, 0.9 )],\n      dtype=[('Serial_No', '<i8'), ('GRE_Score', '<i8'), ('TOEFL_Score', '<i8'), ('University_Rating', '<i8'), ('SOP', '<f8'), ('LOR', '<f8'), ('CGPA', '<f8'), ('Research', '<i8'), ('Chance_of_Admit', '<f8')])\n\n\n\n# Let's also do this with GPA\nprint(graduate_admission[graduate_admission['Chance_of_Admit'] > 0.8]['CGPA'].mean())\nprint(graduate_admission[graduate_admission['Chance_of_Admit'] < 0.4]['CGPA'].mean())\n\n3.7106666666666666\n3.0222857142857142\n\n\nThe GPA and GRE for students who have a higher chance of being admitted, at least based on our cursory look here, seems to be higher."
  },
  {
    "objectID": "code/3_regular_expressions.html",
    "href": "code/3_regular_expressions.html",
    "title": "4  Regex",
    "section": "",
    "text": "In this lecture we’re going to talk about pattern matching in strings using regular expressions.\nRegular expressions, or regexes, are written in a condensed formatting language. In general, you can think of a regular expression as a pattern which you give to a regex processor with some source data. The processor then parses that source data using that pattern, and returns chunks of text back to the a data scientist or programmer for further manipulation.\nThere’s really three main reasons you would want to do this:\nRegexes are not trivial, but they are a foundational technique for data cleaning in data science applications, and a solid understanding of regexs will help you quickly and efficiently manipulate text data for further data science application.\nNow, you could teach a whole course on regular expressions alone, especially if you wanted to demystify how the regex parsing engine works and efficient mechanisms for parsing text.\nBy the end of this lecture, you will understand the basics of regular expressions, how to define patterns for matching, how to apply these patterns to strings, and how to use the results of those patterns in data processing.\nFinally, a note that in order to best learn regexes you need to write regexes. I encourage you to stop the video at any time and try out new patterns or syntax you learn at any time. Also, a good documentation can be found here.\nThere are several main processing functions in re that you might use. The first, match() checks for a match that is at the beginning of the string and returns a boolean. Similarly, search(), checks for a match anywhere in the string, and returns a boolean.\nIn addition to checking for conditionals, we can segment a string. The work that regex does here is called tokenizing, where the string is separated into substrings based on patterns.\nThe findall() and split() functions will parse the string for us and return chunks. Lets try and example\nYou’ll notice that split has returned an empty string, followed by a number of statements about Amy, all as elements of a list. If we wanted to count how many times we have talked about Amy, we could use findall().\nWe’ve seen that .search() looks for some pattern and returns a boolean, that .split() will use a pattern for creating a list of substrings, and that .findall() will look for a pattern and pull out all occurrences.\nNow that we know how the python regex API works, lets talk about more complex patterns. The regex specification standard defines a markup language to describe patterns in text.\nLets start with anchors. Anchors specify the start and/or the end of the string that you are trying to match. The caret character ^ means start and the dollar sign character $ means end.\nIf you put ^ before a string, it means that the text the regex processor retrieves must start with the string you specify. For ending, you have to put the $ character after the string, it means that the text Regex retrieves must end with the string you specify.\nHere’s an example:\nNotice that re.search() actually returned to us a new object, called re.Match object.\nAn re.Match object always has a boolean value of True, as something was found, so you can always evaluate it in an if statement as we did earlier. The rendering of the match object also tells you what pattern was matched, in this case the word Amy, and the location the match was in, as the span."
  },
  {
    "objectID": "code/3_regular_expressions.html#patterns-and-character-classes",
    "href": "code/3_regular_expressions.html#patterns-and-character-classes",
    "title": "4  Regex",
    "section": "4.1 Patterns and character classes",
    "text": "4.1 Patterns and character classes\nLet’s talk more about patterns and start with character classes. Let’s create a string of a single learners’ grades over a semester in one course across all of their assignments.\nIf we want to answer the question “How many B’s were in the grade list?” we would just use B.\n\ngrades=\"ACAAAABCBCBAA\"\n\nre.findall('B', grades)\n\n['B', 'B', 'B']\n\n\nIf we wanted to count the number of A’s or B’s in the list, we can’t use “AB” since this is used to match all A’s followed immediately by a B. Instead, we put the characters A and B inside square brackets.\n\nre.findall('[AB]', grades)\n\n['A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'A', 'A']\n\n\nThis is called the set operator.\nYou can also include a range of characters, which are ordered alphanumerically.\nFor instance, if we want to refer to all lower case letters we could use [a-z] Lets build a simple regex to parse out all instances where this student receive an A followed by a B or a C.\n\nre.findall('[A][B-C]', grades)\n\n['AC', 'AB']\n\n\nNotice how the [AB] pattern describes a set of possible characters which could be either (A OR B), while the [A][B-C] pattern denoted two sets of characters which must have been matched back to back. You can write this pattern by using the pipe operator, which means OR.\n\nre.findall(\"AB|AC\",grades)\n\n['AC', 'AB']\n\n\nWe can use the caret with the set operator to negate our results. For instance, if we want to parse out only the grades which were not A’s:\n\nre.findall('[^A]', grades)\n\n['C', 'B', 'C', 'B', 'C', 'B']\n\n\nNote this carefully - the caret was previously matched to the beginning of a string as an anchor point, but inside of the set operator the caret, and the other special characters we will be talking about, lose their meaning. This can be a bit confusing.\n\nre.findall('^[^A]', grades)\n\n[]\n\n\nThe code above gives an empty list, because the regex says that we want to match any value at the beginning of the string which is not an A. Our string though starts with an A, so there is no match found. And remember when you are using the set operator you are doing character-based matching. So you are matching individual characters in an OR method."
  },
  {
    "objectID": "code/3_regular_expressions.html#quantifiers",
    "href": "code/3_regular_expressions.html#quantifiers",
    "title": "4  Regex",
    "section": "4.2 Quantifiers",
    "text": "4.2 Quantifiers\nQuantifiers are the number of times you want a pattern to be matched in order to match.\nThe most basic quantifier is expressed as e{m,n}, where e is the expression or character we are matching, m is the minimum number of times you want it to matched, and n is the maximum number of times the item could be matched.\nLet’s use these grades as an example. How many times has this student been on a back-to-back A’s streak?\n\n## we'll use 2 as our min, but ten as our max\nre.findall('A{2,10}', grades)\n\n['AAAA', 'AA']\n\n\nSo we see that there were two streaks, one where the student had four A’s, and one where they had only two A’s.\nWe might try and do this using single values and just repeating the pattern\n\nre.findall('A{1,1}A{1,1}', grades)\n\n['AA', 'AA', 'AA']\n\n\nAs you can see, this is different than the first example. The first pattern is looking for any combination of two A’s up to ten A’s in a row. So it sees four A’s as a single streak.\nThe second pattern is looking for two A’s back to back, so it sees two A’s followed immediately by two more A’s. We say that the regex processor begins at the start of the string and consumes variables which match patterns as it does.\nIt’s important to note that the regex quantifier syntax does not allow you to deviate from the {m,n} pattern. In particular, if you have an extra space in between the braces you’ll get an empty result:\n\nre.findall(\"A{2, 2}\",grades)\n\n[]\n\n\nAnd as we have already seen, if we don’t include a quantifier then the default is {1,1}:\n\nre.findall('AA', grades)\n\n['AA', 'AA', 'AA']\n\n\nIf you just have one number in the braces, it’s considered to be both m and n:\n\nre.findall('A{2}', grades)\n\n['AA', 'AA', 'AA']\n\n\nUsing this, we could find a decreasing trend in a student’s grades\n\nre.findall('A{1,10}B{1,10}C{1,10}', grades)\n\n['AAAABC']\n\n\nNow, that’s a bit of a hack, because we included a maximum that was just arbitrarily large. There are three other quantifiers that are used as short hand:\n\nan asterix *  to match 0 or more times\na question mark ? to match one or more times\na + plus sign to match one or more times.\n\nLets look at a more complex example, and load some data scraped from wikipedia\n\nwith open('../data/week1/ferpa.txt', 'r') as file:\n    wiki = file.read()\n\nwiki\n\n'Overview[edit]\\nFERPA gives parents access to their child\\'s education records, an opportunity to seek to have the records amended, and some control over the disclosure of information from the records. With several exceptions, schools must have a student\\'s consent prior to the disclosure of education records after that student is 18 years old. The law applies only to educational agencies and institutions that receive funds under a program administered by the U.S. Department of Education.\\n\\nOther regulations under this act, effective starting January 3, 2012, allow for greater disclosures of personal and directory student identifying information and regulate student IDs and e-mail addresses.[2] For example, schools may provide external companies with a student\\'s personally identifiable information without the student\\'s consent.[2]\\n\\nExamples of situations affected by FERPA include school employees divulging information to anyone other than the student about the student\\'s grades or behavior, and school work posted on a bulletin board with a grade. Generally, schools must have written permission from the parent or eligible student in order to release any information from a student\\'s education record.\\n\\nThis privacy policy also governs how state agencies transmit testing data to federal agencies, such as the Education Data Exchange Network.\\n\\nThis U.S. federal law also gave students 18 years of age or older, or students of any age if enrolled in any post-secondary educational institution, the right of privacy regarding grades, enrollment, and even billing information unless the school has specific permission from the student to share that specific type of information.\\n\\nFERPA also permits a school to disclose personally identifiable information from education records of an \"eligible student\" (a student age 18 or older or enrolled in a postsecondary institution at any age) to his or her parents if the student is a \"dependent student\" as that term is defined in Section 152 of the Internal Revenue Code. Generally, if either parent has claimed the student as a dependent on the parent\\'s most recent income tax statement, the school may non-consensually disclose the student\\'s education records to both parents.[3]\\n\\nThe law allowed students who apply to an educational institution such as graduate school permission to view recommendations submitted by others as part of the application. However, on standard application forms, students are given the option to waive this right.\\n\\nFERPA specifically excludes employees of an educational institution if they are not students.\\n\\nThe act is also referred to as the Buckley Amendment, for one of its proponents, Senator James L. Buckley of New York.\\n\\nAccess to public records[edit]\\nThe citing of FERPA to conceal public records that are not \"educational\" in nature has been widely criticized, including by the act\\'s primary Senate sponsor.[4] For example, in the Owasso Independent School District v. Falvo case, an important part of the debate was determining the relationship between peer-grading and \"education records\" as defined in FERPA. In the Court of Appeals, it was ruled that students placing grades on the work of other students made such work into an \"education record.\" Thus, peer-grading was determined as a violation of FERPA privacy policies because students had access to other students\\' academic performance without full consent.[5] However, when the case went to the Supreme Court, it was officially ruled that peer-grading was not a violation of FERPA. This is because a grade written on a student\\'s work does not become an \"education record\" until the teacher writes the final grade into a grade book.[6]\\n\\nStudent medical records[edit]\\nLegal experts have debated the issue of whether student medical records (for example records of therapy sessions with a therapist at an on-campus counseling center) might be released to the school administration under certain triggering events, such as when a student sued his college or university.[7][8]\\n\\nUsually, student medical treatment records will remain under the protection of FERPA, not the Health Insurance Portability and Accountability Act (HIPAA). This is due to the \"FERPA Exception\" written within HIPAA.[9]'\n\n\nScanning through this document one of the things we notice is that the headers all have the words [edit] behind them, followed by a newline character. So if we wanted to get a list of all of the headers in this article we could do so using re.findall:\n\nre.findall('[a-zA-Z]{1,100}\\[edit\\]', wiki)\n\n['Overview[edit]', 'records[edit]', 'records[edit]']\n\n\nOk, that didn’t quite work. It got all of the headers, but only the last word of the header, and it really was quite clunky. Lets iteratively improve this. First, we can use \\w to match any word character, which usually means alphanumeric (letters, numbers, regardless of case) plus underscore (_).\n\nre.findall(\"[\\w]{1,100}\\[edit\\]\",wiki)\n\n['Overview[edit]', 'records[edit]', 'records[edit]']\n\n\nThis is something new. \\w is a metacharacter, and indicates a special pattern of any letter or digit. There are actually a number of different metacharacters listed in the documentation. For instance, \\s matches any whitespace character.\nNext, there are three other quantifiers we can use which shorten up the curly brace syntax. We can use an asterix * to match 0 or more times, so let’s try that.\n\nre.findall(\"[\\w]*\\[edit\\]\",wiki)\n\n['Overview[edit]', 'records[edit]', 'records[edit]']\n\n\nNow that we have shortened the regex, let’s improve it a little bit. We can add in a spaces using the space character:\n\nre.findall(\"[\\w ]*\\[edit\\]\",wiki)\n\n['Overview[edit]',\n 'Access to public records[edit]',\n 'Student medical records[edit]']\n\n\nOk, so this gets us the list of section titles in the wikipedia page! You can now create a list of titles by iterating through this and applying another regex:\n\nfor title in re.findall('[\\w ]*\\[edit\\]', wiki):\n    ## Now we will take that intermediate result and split on the square bracket [ just taking the first result\n    print(re.split('[\\[]', title)[0])\n\nprint('')\n\nOverview\nAccess to public records\nStudent medical records"
  },
  {
    "objectID": "code/3_regular_expressions.html#groups",
    "href": "code/3_regular_expressions.html#groups",
    "title": "4  Regex",
    "section": "4.3 Groups",
    "text": "4.3 Groups\nOk, this works, but it’s a bit of a pain. To this point we have been talking about a regex as a single pattern which is matched. But, you can actually match different patterns, called groups, at the same time, and then refer to the groups you want.\nTo group patterns together you use parentheses, which is actually pretty natural. Lets rewrite our findall using groups\n\nre.findall('([\\w ]*)(\\[edit\\])', wiki)\n\n[('Overview', '[edit]'),\n ('Access to public records', '[edit]'),\n ('Student medical records', '[edit]')]\n\n\nNice - we see that the python re module breaks out the result by group. We can actually refer to groups by number as well with the match objects that are returned. But, how do we get back a list of match objects?\nThus far we’ve seen that findall() returns strings, and search() and match() return individual Match objects. But what do we do if we want a list of Match objects? In this case, we use the function finditer()\n\nfor item in re.finditer('([\\w ]*)(\\[edit\\])', wiki):\n    print(item.groups())\n\nprint('')\n\n('Overview', '[edit]')\n('Access to public records', '[edit]')\n('Student medical records', '[edit]')\n\n\n\nWe see here that the groups() method returns a tuple of the group. We can get an individual group using group(number), where group(0) is the whole match, and each other number is the portion of the match we are interested in.\n\nfor item in re.finditer('([\\w ]*)(\\[edit\\])', wiki):\n    print(item.group(1))\n\nprint('')\n\nOverview\nAccess to public records\nStudent medical records\n\n\n\nOne more piece to regex groups that I rarely use but is a good idea is labeling or naming groups.\nIn the previous example I showed you how you can use the position of the group. But giving them a label and looking at the results as a dictionary is pretty useful.\nFor that we use the syntax (?P<name>), where :\n\nthe parenthesis starts the group,\nthe ?P indicates that this is an extension to basic regexes\n<name> is the dictionary key we want to use wrapped in <>.\n\n\nfor item in re.finditer(\"(?P<title>[\\w ]*)(?P<edit_link>\\[edit\\])\",wiki):\n    # We can get the dictionary returned for the item with .groupdict()\n    print(item.groupdict()['title'])\n\nprint('')\n\nOverview\nAccess to public records\nStudent medical records\n\n\n\nOf course, we can print out the whole dictionary for the item too, and see that the [edit] string is still in there. Here’s the dictionary kept for the last match:\n\nitem.groupdict()\n\n{'title': 'Student medical records', 'edit_link': '[edit]'}\n\n\nFinally, there are a number of short hands which are used with regexes for different kinds of characters, including:\n\na . for any single character which is not a newline\na \\d for any digit\nand \\s for any whitespace character, like spaces and tabs\n\nThere are more, and a full list can be found in the python documentation for regexes"
  },
  {
    "objectID": "code/3_regular_expressions.html#look-ahead-and-look-behind",
    "href": "code/3_regular_expressions.html#look-ahead-and-look-behind",
    "title": "4  Regex",
    "section": "4.4 Look-ahead and Look-behind",
    "text": "4.4 Look-ahead and Look-behind\nOne more concept to be familiar with is called “look ahead” and “look behind” matching. In this case, the pattern being given to the regex engine is for text either before or after the text we are trying to isolate.\nFor example, in our headers we want to isolate text which comes before the [edit] rendering, but we actually don’t care about the [edit] text itself. Thus far we have been throwing the [edit] away, but if we want to use them to match but don’t want to capture them we could put them in a group and use look ahead instead with ?= syntax:\nWhat the regex below says is match two groups, the first will be named and called title, will have any amount of whitespace or regular word characters, the second will be the characters [edit] but we don’t actually want this edit put in our output match objects:\n\nfor item in re.finditer('(?P<title>[\\w ]+)(?=\\[edit\\])', wiki):\n    print(item)\n\nprint('')\n\n<re.Match object; span=(0, 8), match='Overview'>\n<re.Match object; span=(2715, 2739), match='Access to public records'>\n<re.Match object; span=(3692, 3715), match='Student medical records'>"
  },
  {
    "objectID": "code/3_regular_expressions.html#example-wiki-data",
    "href": "code/3_regular_expressions.html#example-wiki-data",
    "title": "4  Regex",
    "section": "4.5 Example wiki data:",
    "text": "4.5 Example wiki data:\nLet’s look at some more wikipedia data. Here’s some data on universities in the US which are buddhist-based\n\nwith open('../data/week1/buddhist.txt', 'r') as file:\n    wiki = file.read()\n\n#wiki\n\nWe can see that each university follows a fairly similar pattern, with the name followed by an – then the words “located in” followed by the city and state.\nI’ll actually use this example to show you the verbose mode of python regexes. The verbose mode allows you to write multi-line regexes and increases readability. For this mode, we have to explicitly indicate all whitespace characters, either by prepending them with a \\ or by using the \\s special value. However, this means we can write our regex a bit more like code, and can even include comments with #\n\npattern = '''\n(?P<title>.*)       # the uni title\n(–\\ located\\ in\\ )  # an indicator for the location\n(?P<city>\\w*)       #city the uni is in\n(,\\ )               #separator for the state\n(?P<state>\\w*)      #the state the uni is located in\n'''\n\nNow when we call finditer() we just pass the re.VERBOSE flag as the last parameter, this makes it much easier to understand large regexes!\n\nfor item in re.finditer(pattern, wiki, re.VERBOSE):\n    print(item.groupdict())\n\nprint('')\n\n{'title': 'Dhammakaya Open University ', 'city': 'Azusa', 'state': 'California'}\n{'title': 'Dharmakirti College ', 'city': 'Tucson', 'state': 'Arizona'}\n{'title': 'Dharma Realm Buddhist University ', 'city': 'Ukiah', 'state': 'California'}\n{'title': 'Ewam Buddhist Institute ', 'city': 'Arlee', 'state': 'Montana'}\n{'title': 'Institute of Buddhist Studies ', 'city': 'Berkeley', 'state': 'California'}\n{'title': 'Maitripa College ', 'city': 'Portland', 'state': 'Oregon'}\n{'title': 'University of the West ', 'city': 'Rosemead', 'state': 'California'}\n{'title': 'Won Institute of Graduate Studies ', 'city': 'Glenside', 'state': 'Pennsylvania'}"
  },
  {
    "objectID": "code/3_regular_expressions.html#example-new-york-times-and-hashtags",
    "href": "code/3_regular_expressions.html#example-new-york-times-and-hashtags",
    "title": "4  Regex",
    "section": "4.6 Example: New York Times and Hashtags",
    "text": "4.6 Example: New York Times and Hashtags\nHere’s another example from the New York Times which covers health tweets on news items. This data came from the UC Irvine Machine Learning Repository which is a great source of different kinds of data\n\nwith open(\"../data/week1/nytimeshealth.txt\",\"r\") as file:\n    # We'll read everything into a variable and take a look at it\n    health=file.read()\n    \n#health\nprint('')\n\n\n\n\n'548662191340421120|Sat Dec 27 02:10:34 +0000 2014|Risks in Using Social Media to Spot Signs of Mental Distress http://nyti.ms/1rqi9I1\\n548579831169163265|Fri\nSo here we can see there are tweets with fields separated by pipes |.\nLets try and get a list of all of the hashtags that are included in this data. A hashtag begins with a pound sign (or hash mark) and continues until some whitespace is found.\nSo lets create a pattern. We want to include the hash sign first, then any number of alphanumeric characters. And we end when we see some whitespace\n\npattern = '#[\\w\\d]*(?=\\s)'\n\nNotice that the ending is a look ahead. We’re not actually interested in matching whitespace in the return value. Also notice that I use an asterix * instead of the plus + for the matching of alphabetical characters or digits, because a + would require at least one of each\nLets searching and display all of the hashtags:\n\nre.findall(pattern, health)\n\n['#askwell',\n '#pregnancy',\n '#Colorado',\n '#VegetarianThanksgiving',\n '#FallPrevention',\n '#Ebola',\n '#Ebola',\n '#ebola',\n '#Ebola',\n '#Ebola',\n '#EbolaHysteria',\n '#AskNYT',\n '#Ebola',\n '#Ebola',\n '#Liberia',\n '#Excalibur',\n '#ebola',\n '#Ebola',\n '#dallas',\n '#nobelprize2014',\n '#ebola',\n '#ebola',\n '#monrovia',\n '#ebola',\n '#nobelprize2014',\n '#ebola',\n '#nobelprize2014',\n '#Medicine',\n '#Ebola',\n '#Monrovia',\n '#Ebola',\n '#smell',\n '#Ebola',\n '#Ebola',\n '#Ebola',\n '#Monrovia',\n '#Ebola',\n '#ebola',\n '#monrovia',\n '#liberia',\n '#benzos',\n '#ClimateChange',\n '#Whole',\n '#Wheat',\n '#Focaccia',\n '#Tomatoes',\n '#Olives',\n '#Recipes',\n '#Health',\n '#Ebola',\n '#Monrovia',\n '#Liberia',\n '#Ebola',\n '#Ebola',\n '#Liberia',\n '#Ebola',\n '#blood',\n '#Ebola',\n '#organtrafficking',\n '#EbolaOutbreak',\n '#SierraLeone',\n '#Freetown',\n '#SierraLeone',\n '#ebolaoutbreak',\n '#kenema',\n '#ebola',\n '#Ebola',\n '#ebola',\n '#ebola',\n '#Ebola',\n '#ASMR',\n '#AIDS2014',\n '#AIDS',\n '#MH17',\n '#benzos']"
  },
  {
    "objectID": "code/3_regular_expressions.html#other",
    "href": "code/3_regular_expressions.html#other",
    "title": "4  Regex",
    "section": "4.7 Other",
    "text": "4.7 Other"
  },
  {
    "objectID": "code/4_pandas.html",
    "href": "code/4_pandas.html",
    "title": "5  Pandas",
    "section": "",
    "text": "The series is one of the core data structures in pandas. You think of it a cross between a list and a dictionary. The items are all stored in an order and there’s labels with which you can retrieve them. An easy way to visualize this is two columns of data. The first is the special index, a lot like keys in a dictionary. While the second is your actual data. It’s important to note that the data column has a label of its own and can be retrieved using the .name attribute. This is different than with dictionaries and is useful when it comes to merging multiple columns of data.\n\nimport pandas as pd\nimport numpy as np\n\nYou can create a series by passing in a list of values. When you do this, Pandas automatically assigns an index starting with zero and sets the name of the series to None. One of the easiest ways to create a series is to use an array-like object, like a list.\n\nstudents = ['Alice', 'Jack', 'Molly']\n\nNow we just call the Series function in pandas and pass in the students:\n\npd.Series(students)\n\n0    Alice\n1     Jack\n2    Molly\ndtype: object\n\n\nThe result is a Series object which is nicely rendered to the screen.\nWe see here that the pandas has automatically identified the type of data in this Series as “object” and set the dytpe parameter as appropriate. We see that the values are indexed with integers, starting at zero.\nWe don’t have to use strings. If we passed in a list of whole numbers, for instance, we could see that panda sets the type to int64. Underneath panda stores series values in a typed array using the Numpy library. This offers significant speedup when processing data versus traditional python lists.\n\nnumbers = [1,2,3]\npd.Series(numbers)\n\n0    1\n1    2\n2    3\ndtype: int64\n\n\nAnd we see on my architecture that the result is a dtype of int64 objects"
  },
  {
    "objectID": "code/4_pandas.html#missing-data",
    "href": "code/4_pandas.html#missing-data",
    "title": "5  Pandas",
    "section": "5.2 Missing data",
    "text": "5.2 Missing data\nThere’s some other typing details that exist for performance that are important to know. The most important is how Numpy and thus pandas handle missing data.\nIn Python, we have the none type to indicate a lack of data. But what do we do if we want to have a typed list like we do in the series object?\nUnderneath, pandas does some type conversion. If we create a list of strings and we have one element, a None type, pandas inserts it as a None and uses the type object for the underlying array.\n\nstudents = ['Alice', 'Jack', None]\npd.Series(students)\n\n0    Alice\n1     Jack\n2     None\ndtype: object\n\n\nHowever, if we create a list of numbers, integers or floats, and put in the None type, pandas automatically converts this to a special floating point value designated as NaN, which stands for “Not a Number”.\n\nnumbers = [1,2,None]\npd.Series(numbers)\n\n0    1.0\n1    2.0\n2    NaN\ndtype: float64\n\n\nYou’ll notice a couple of things:\n\nFirst, NaN is a different value.\nSecond, pandas set the dytpe of this series to floating point numbers instead of object or ints. That’s maybe a bit of a surprise - why not just leave this as an integer?\n\nUnderneath, pandas represents NaN as a floating point number, and because integers can be typecast to floats, pandas went and converted our integers to floats. So when you’re wondering why the list of integers you put into a Series is not floats, it’s probably because there is some missing data.\nIt is important to stress that None and NaN might be being used by the data scientist in the same way, to denote missing data, but that underneath these are not represented by pandas in the same way.\nNaN is NOT equivilent to None and when we try the equality test, the result is False.\n\nnp.nan == None\n\nFalse\n\n\nIt turns out that you actually can’t do an equality test of NAN to itself. When you do, the answer is always False.\n\nnp.nan == np.nan\n\nFalse\n\n\nInstead, you need to use special functions to test for the presence of not a number, such as the Numpy library isnan().\n\nnp.isnan(np.nan)\n\nTrue\n\n\nSo keep in mind when you see NaN, it’s meaning is similar to None, but it’s a numeric value and treated differently for efficiency reasons."
  },
  {
    "objectID": "code/4_pandas.html#creating-series-from-dictionaries",
    "href": "code/4_pandas.html#creating-series-from-dictionaries",
    "title": "5  Pandas",
    "section": "5.3 Creating Series from dictionaries",
    "text": "5.3 Creating Series from dictionaries\nA series can be created directly from dictionary data. If you do this, the index is automatically assigned to the keys of the dictionary that you provided and not just incrementing integers.\n\nstudents_scores = {'Alice': 'Physics',\n                   'Jack': 'Chemistry',\n                   'Molly': 'English'}\ns = pd.Series(students_scores)\ns\n\nAlice      Physics\nJack     Chemistry\nMolly      English\ndtype: object\n\n\nWe see that, since it was string data, pandas set the data type of the series to “object”. We see that the index, the first column, is also a list of strings.\nOnce the series has been created, we can get the index object using the index attribute.\n\ns.index\n\nIndex(['Alice', 'Jack', 'Molly'], dtype='object')\n\n\nAs you play more with pandas you’ll notice that a lot of things are implemented as numpy arrays, and have the dtype value set. This is true of indicies, and here pandas inferred that we were using objects for the index.\nNow, this is kind of interesting. The dtype of object is not just for strings, but for arbitrary objects. Lets create a more complex type of data, say, a list of tuples.\n\nstudents = [(\"Alice\",\"Brown\"), (\"Jack\", \"White\"), (\"Molly\", \"Green\")]\npd.Series(students)\n\n0    (Alice, Brown)\n1     (Jack, White)\n2    (Molly, Green)\ndtype: object\n\n\nWe see that each of the tuples is stored in the series object, and the type is object.\nYou can also separate your index creation from the data by passing in the index as a list explicitly to the series.\n\ns = pd.Series(['Physics', 'Chemistry', 'English'], index=['Alice', 'Jack', 'Molly'])\ns\n\nAlice      Physics\nJack     Chemistry\nMolly      English\ndtype: object\n\n\nSo what happens if your list of values in the index object are not aligned with the keys in your dictionary for creating the series? Well, pandas overrides the automatic creation to favor only and all of the indices values that you provided. So it will ignore from your dictionary all keys which are not in your index, and pandas will add None or NaN type values for any index value you provide, which is not in your dictionary key list.\n\nstudents_scores = {'Alice': 'Physics',\n                   'Jack': 'Chemistry',\n                   'Molly': 'English'}\n\n# When I create the series object though I'll only ask for an index with three students, and I'll exclude Jack\ns = pd.Series(students_scores, index=['Alice', 'Molly', 'Sam'])\ns\n\nAlice    Physics\nMolly    English\nSam          NaN\ndtype: object"
  },
  {
    "objectID": "code/4_pandas.html#querying-a-series",
    "href": "code/4_pandas.html#querying-a-series",
    "title": "5  Pandas",
    "section": "5.4 Querying a Series",
    "text": "5.4 Querying a Series\nA pandas Series can be queried either by the index position or the index label. If you don’t give an index to the series when querying, the position and the label are effectively the same values.\n\nTo query by numeric location, starting at zero, use the iloc attribute.\nTo query by the index label, you can use the loc attribute.\n\n\nstudents_classes = {'Alice': 'Physics',\n                   'Jack': 'Chemistry',\n                   'Molly': 'English',\n                   'Sam': 'History'}\n\ns = pd.Series(students_classes)\ns\n\nAlice      Physics\nJack     Chemistry\nMolly      English\nSam        History\ndtype: object\n\n\nSo, for this series, if you wanted to see the fourth entry we would we would use the iloc attribute with the parameter 3.\n\ns.iloc[3]\n\n'History'\n\n\nIf you wanted to see what class Molly has, we would use the loc attribute with a parameter of Molly.\n\ns.loc['Molly']\n\n'English'\n\n\nKeep in mind that iloc and loc are not methods, they are attributes. So you don’t use parentheses to query them, but square brackets instead, which is called the indexing operator.\nPandas tries to make our code a bit more readable and provides a sort of smart syntax using the indexing operator directly on the series itself. For instance, if you pass in an integer parameter, the operator will behave as if you want it to query via the iloc attribute\n\ns[3]\n\n'History'\n\n\nIf you pass in an object, it will query as if you wanted to use the label based loc attribute.\n\ns['Molly']\n\n'English'\n\n\nSo what happens if your index is a list of integers? This is a bit complicated and Pandas can’t determine automatically whether you’re intending to query by index position or index label. So you need to be careful when using the indexing operator on the Series itself. The safer option is to be more explicit and use the iloc or loc attributes directly.\n\nclass_code = {99: 'Physics',\n              100: 'Chemistry',\n              101: 'English',\n              102: 'History'}\ns = pd.Series(class_code)\ns\n\n99       Physics\n100    Chemistry\n101      English\n102      History\ndtype: object\n\n\nIf we try and call s[0] we get a key error because there’s no item in the classes list with an index of zero, instead we have to call iloc explicitly if we want the first item.\n\n#s[0]\n\nThe code above will give us a KeyError: 0\n\ns.iloc[0]\n\n'Physics'\n\n\nNow we know how to get data out of the series, let’s talk about working with the data. A common task is to want to consider all of the values inside of a series and do some sort of operation. This could be trying to find a certain number, or summarizing data or transforming the data in some way.\nA typical programmatic approach to this would be to iterate over all the items in the series, and invoke the operation one is interested in. For instance, we could create a Series of integers representing student grades, and just try and get an average grade\n\ngrades = pd.Series([90, 80, 70, 60])\ngrades\n\n0    90\n1    80\n2    70\n3    60\ndtype: int64\n\n\n\ntotal = 0\n\nfor grade in grades:\n    total += grade\n\nprint(total/len(grades))\n\n75.0\n\n\nThis works, but it’s slow. Modern computers can do many tasks simultaneously, especially, but not only, tasks involving mathematics.\nPandas and the underlying numpy libraries support a method of computation called vectorization. Vectorization works with most of the functions in the numpy library, including the sum function.\n\ntotal = np.sum(grades)\nprint(total/len(grades))\n\n75.0\n\n\nNow both of these methods create the same value, but is one actually faster? The Jupyter Notebook has a magic function which can help.\n\nnumbers = pd.Series(np.random.randint(0,1000,10000))\n\n#look at the first 5 items\nnumbers.head()\n\n0     17\n1    515\n2    501\n3    945\n4    671\ndtype: int64\n\n\n\n#control length of series\nlen(numbers)\n\n10000\n\n\nOk, we’re confident now that we have a big series. The ipython interpreter has something called magic functions begin with a percentage sign. If we type this sign and then hit the Tab key, you can see a list of the available magic functions. You could write your own magic functions too, but that’s a little bit outside of the scope of this course.\nHere, we’re actually going to use what’s called a cellular magic function. These start with two percentage signs and wrap the code in the current Jupyter cell. The function we’re going to use is called timeit. This function will run our code a few times to determine, on average, how long it takes.\nLet’s run timeit with our original iterative code. You can give timeit the number of loops that you would like to run. By default, it is 1,000 loops. I’ll ask timeit here to use 100 runs because we’re recording this. Note that in order to use a cellular magic function, it has to be the first line in the cell\n\n%%timeit -n 100\n\ntotal = 0\nfor number in numbers:\n    total += number\n\ntotal/len(numbers)\n\n1.28 ms ± 202 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%%timeit -n 100\ntotal = np.sum(numbers)\ntotal/len(numbers)\n\n58.2 µs ± 10.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\nThis is a pretty shocking difference in the speed and demonstrates why one should be aware of parallel computing features and start thinking in functional programming terms.\nPut more simply, vectorization is the ability for a computer to execute multiple instructions at once, and with high performance chips, especially graphics cards, you can get dramatic speedups. Modern graphics cards can run thousands of instructions in parallel.\nA Related feature in pandas and nummy is called broadcasting. With broadcasting, you can apply an operation to every value in the series, changing the series. For instance, if we wanted to increase every random variable by 2, we could do so quickly using the += operator directly on the Series object.\n\nnumbers.head()\n\n0     17\n1    515\n2    501\n3    945\n4    671\ndtype: int64\n\n\n\nnumbers += 2\nnumbers.head()\n\n0     19\n1    517\n2    503\n3    947\n4    673\ndtype: int64\n\n\nThe procedural way of doing this would be to iterate through all of the items in the series and increase the values directly. Pandas does support iterating through a series much like a dictionary, allowing you to unpack values easily.\nWe can use the iteritems() function which returns a label and value\nPandas.iat(): allows to access a single value for a row/column pair by integer position.\nSelection with .at is nearly identical to .loc but it only selects a single ‘cell’ in your DataFrame/Series. We usually refer to this cell as a scalar value.\n\nloc: label based, only works on index\niloc: position based\nat: label based, gets scalar values. It’s a very fast loc; Cannot operate on array indexers. Can assign new indices and columns\niat: position based, gets scalar values. It’s a very fast iloc, Cannot work in array indexers. Cannot! assign new indices and columns.\n\n\nfor label, value in numbers.iteritems():\n    # in the early version of pandas we would use the set_value() function\n    # in the current version, we use the iat() or at() functions,\n    numbers.iat[label] = value + 2\n    #numbers.iloc[label] = value + 2\n\nnumbers.head()\n\n0     21\n1    519\n2    505\n3    949\n4    675\ndtype: int64\n\n\nLet’s compare the speed:\n\n%%timeit -n 10\n\n# we'll create a blank new series of items to deal with\ns = pd.Series(np.random.randint(0,1000,1000))\n\n# And we'll just rewrite our loop from above.\nfor label, value in s.iteritems():\n    s.loc[label]= value+2\n\n48.1 ms ± 15.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n%%timeit -n 10\n\n# We need to recreate a series\ns = pd.Series(np.random.randint(0,1000,1000))\n\n# And we just broadcast with +=\ns+=2\n\n235 µs ± 76.8 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\nNot only is it significantly faster, but it’s more concise and even easier to read too. The typical mathematical operations you would expect are vectorized, and the nump documentation outlines what it takes to create vectorized functions of your own\nOne last note on using the indexing operators to access series data. **The .loc attribute lets you not only modify data in place, but also add new data as well((. If the value you pass in as the index doesn’t exist, then a new entry is added. And keep in mind, indices can have mixed types. While it’s important to be aware of the typing going on underneath, Pandas will automatically change the underlying NumPy types as appropriate.\n\ns = pd.Series([1, 2, 3])\n\n#add a new value\ns.loc['History'] = 102\n\ns\n\n0            1\n1            2\n2            3\nHistory    102\ndtype: int64\n\n\nWe see that mixed types for data values or index labels are no problem for Pandas. Since “History” is not in the original list of indices, s.loc[‘History’] essentially creates a new element in the series, with the index named “History”, and the value of 102\nUp until now I’ve shown only examples of a series where the index values were unique. I want to end this lecture by showing an example where index values are not unique, and this makes pandas Series a little different conceptually then, for instance, a relational database.\n\n# Lets create a Series with students and the courses which they have taken\nstudents_classes = pd.Series({'Alice': 'Physics',\n                   'Jack': 'Chemistry',\n                   'Molly': 'English',\n                   'Sam': 'History'})\nstudents_classes\n\nAlice      Physics\nJack     Chemistry\nMolly      English\nSam        History\ndtype: object\n\n\n\n# Now lets create a Series just for some new student Kelly, which lists all of the courses she has taken.\n#We'll set the index to Kelly, and the data to be the names of courses.\nkelly_classes = pd.Series(['Philosophy', 'Arts', 'Math'], index=['Kelly', 'Kelly', 'Kelly'])\nkelly_classes\n\nKelly    Philosophy\nKelly          Arts\nKelly          Math\ndtype: object"
  },
  {
    "objectID": "code/4_pandas.html#appending-series",
    "href": "code/4_pandas.html#appending-series",
    "title": "5  Pandas",
    "section": "5.5 Appending Series",
    "text": "5.5 Appending Series\nFinally, we can append all of the data in this new Series to the first using the .append() function.\n\nall_students_classes = students_classes.append(kelly_classes)\nall_students_classes\n\nAlice       Physics\nJack      Chemistry\nMolly       English\nSam         History\nKelly    Philosophy\nKelly          Arts\nKelly          Math\ndtype: object\n\n\nThere are a couple of important considerations when using append.\n\nFirst, Pandas will take the series and try to infer the best data types to use. In this example, everything is a string, so there’s no problems here.\nSecond, the append method doesn’t actually change the underlying Series objects, it instead returns a new series which is made up of the two appended together. This is a common pattern in pandas - by default returning a new object instead of modifying in place - and one you should come to expect. By printing the original series we can see that that series hasn’t changed.\n\n\nstudents_classes\n\nAlice      Physics\nJack     Chemistry\nMolly      English\nSam        History\ndtype: object\n\n\nFinally, we see that when we query the appended series for Kelly, we don’t get a single value, but a series itself.\n\nall_students_classes['Kelly']\n\nKelly    Philosophy\nKelly          Arts\nKelly          Math\ndtype: object"
  }
]